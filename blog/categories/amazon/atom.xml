<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>atodorov.org</title><link href="http://atodorov.org/" rel="alternate"></link><link href="http://atodorov.org/blog/categories/amazon/atom.xml" rel="self"></link><id>http://atodorov.org/</id><updated>2014-03-07T17:14:00+02:00</updated><entry><title>Reducing AWS Cloud Costs - Real Money Example</title><link href="http://atodorov.org/blog/2014/03/07/reducing-aws-cloud-costs-real-money-example/" rel="alternate"></link><updated>2014-03-07T17:14:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2014-03-07:blog/2014/03/07/reducing-aws-cloud-costs-real-money-example/</id><summary type="html">&lt;p&gt;&lt;a href="http://aws.amazon.com/ebs/pricing/effective-february-2014/"&gt;Last month&lt;/a&gt; Amazon
reduced by 50% prices for EBS storage. This, combined with 
&lt;a href="/blog/2014/02/07/aws-tip-shrinking-ebs-root-volume-size/"&gt;shrinking EBS root volume size&lt;/a&gt; and
&lt;a href="/blog/2014/02/10/moving-tmp-from-ebs-to-instance-storage/"&gt;moving /tmp to instance storage&lt;/a&gt;
allowed me to reduce EBS related costs behind &lt;a href="http://www.dif.io"&gt;Difio&lt;/a&gt; by around 50%.
Following are the real figures from my AWS Bill.&lt;/p&gt;
&lt;p&gt;EBS costs for Difio were gradually rising up with every new node added to the cluster and
increased package processing (resulting in more I/O):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;November 2013 - $7.38&lt;/li&gt;
&lt;li&gt;December 2013 - $10.55&lt;/li&gt;
&lt;li&gt;January 2014 - $11.97&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;January 2014:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;EBS
$0.095 per GB-Month of snapshot data stored     9.052 GB-Mo     $0.86
$0.10  per GB-month of provisioned storage      101.656 GB-Mo  $10.17
$0.10  per 1 million I/O requests               9,405,243 IOs   $0.94
                                                        Total: $11.97
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In February there was one new system added to process additional requests
(cluster nodes run as spot instances) and an increased number of temporary
instances (although I haven't counted them) while I was restructuring AMI
internals to accommodate the &lt;a href="https://github.com/difio/difio"&gt;open source&lt;/a&gt;
version of Difio. My assumption (based on historical data) is this would
have driven the costs up in the region of $15 per month only for EBS.&lt;/p&gt;
&lt;p&gt;After implementing the stated minimal improvements and having Amazon reduced the prices by
half the bill looks like this:&lt;/p&gt;
&lt;p&gt;February 2014:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;EBS
$0.095 per GB-Month of snapshot data stored     8.668 GB-Mo     $0.82
$0.05  per GB-month of provisioned storage      58.012 GB-Mo    $2.90
$0.05  per 1 million I/O requests               5,704,482 IOs   $0.29
                                                        Total:  $4.01
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Explanation&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Snapshot data stored&lt;/em&gt; is the volume of snapshots (AMIs, backups, etc) which
I have. This is fairly constant.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Provisioned storage&lt;/em&gt; is the volume of EBS storage provisioned for running
instances (e.g. root file system, data partitions, etc.). This was reduced
mainly because of shrinking the root volumes. (Previously I've used larger
root volumes for a bigger /tmp).&lt;/p&gt;
&lt;p&gt;&lt;em&gt;I/O requests&lt;/em&gt; is the number of I/O requests associated with your EBS volumes.
As far as I understand Amazon doesn't charge for I/O related to ephemeral storage.
Moving /tmp from EBS to instance storage is the reason this was reduced roughly by half.&lt;/p&gt;
&lt;h2&gt;Where To Next&lt;/h2&gt;
&lt;p&gt;I've reduced the root volumes back to the 8GB defaults but this has still room for
improvement b/c the AMI is quite minimal. This will bring the largest improvements.
Another thing is the still relatively high I/O rate that touches EBS volumes.
I haven't investigated where this comes from though.&lt;/p&gt;</summary><category term="Amazon"></category><category term="cloud"></category></entry><entry><title>Moving /tmp from EBS to Instance Storage</title><link href="http://atodorov.org/blog/2014/02/10/moving-tmp-from-ebs-to-instance-storage/" rel="alternate"></link><updated>2014-02-10T13:48:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2014-02-10:blog/2014/02/10/moving-tmp-from-ebs-to-instance-storage/</id><summary type="html">&lt;p&gt;I've seen a fair amount of stories about moving away from Amazon's EBS volumes
to ephemeral instance storage. I've decided to give it a try starting with &lt;code&gt;/tmp&lt;/code&gt;
directory where &lt;a href="http://www.dif.io"&gt;Difio&lt;/a&gt; operates.&lt;/p&gt;
&lt;p&gt;It should be noted that although instance storage may be available for some instance
types it may not be attached by default. Use this command to check:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;curl http://169.254.169.254/latest/meta-data/block-device-mapping/
ami
root
swap
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In the above example there is no instance storage present. &lt;/p&gt;
&lt;p&gt;You can attach one either when launching the EC2 instance or when creating a customized AMI
(instance storage devices are pre-defined in the AMI). When creating an AMI you can attach more ephemeral devices
but they will not available when instance is launched. The maximum number of available
instance storage devices can be found in the
&lt;a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#StorageOnInstanceTypes"&gt;docs&lt;/a&gt;.
That is to say if you have an AMI which defines 2 ephemeral devices and launch a
standard m1.small instance there will be only one ephemeral device present.&lt;/p&gt;
&lt;p&gt;Also note that for M3 instances, you must specify instance store volumes in the
block device mapping for the instance. When you launch an M3 instance, Amazon ignores
any instance store volumes specified in the block device mapping for the AMI.&lt;/p&gt;
&lt;p&gt;As far as I can see the AWS Console doesn't indicate if instance storage is attached
or not. For instance with 1 ephemeral volume:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;curl http://169.254.169.254/latest/meta-data/block-device-mapping/
ami
ephemeral0
root
swap

&lt;span class="nv"&gt;$ &lt;/span&gt;curl http://169.254.169.254/latest/meta-data/block-device-mapping/ephemeral0
sdb
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ephemeral devices can be mounted in &lt;code&gt;/media/ephemeralX/&lt;/code&gt;, but not all volumes.
I've found that usually only &lt;code&gt;ephemeral0&lt;/code&gt; is mounted automatically.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;curl http://169.254.169.254/latest/meta-data/block-device-mapping/
ami
ephemeral0
ephemeral1
root

&lt;span class="nv"&gt;$ &lt;/span&gt;ls -l /media/
drwxr-xr-x &lt;span class="m"&gt;3&lt;/span&gt; root root &lt;span class="m"&gt;4096&lt;/span&gt; &lt;span class="m"&gt;21&lt;/span&gt; ное  &lt;span class="m"&gt;2009&lt;/span&gt; ephemeral0
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;For Difio I have an init.d script which executes when the system
boots. To enable &lt;code&gt;/tmp&lt;/code&gt; on ephemeral storage I just added the following snippet:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;$&amp;quot;Mounting /tmp on ephemeral storage:&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; ef in &lt;span class="sb"&gt;`&lt;/span&gt;curl http://169.254.169.254/latest/meta-data/block-device-mapping/ 2&amp;gt;/dev/null &lt;span class="p"&gt;|&lt;/span&gt; grep ephemeral&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
    &lt;span class="nv"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;curl http://169.254.169.254/latest/meta-data/block-device-mapping/&lt;span class="nv"&gt;$ef&lt;/span&gt; 2&amp;gt;/dev/null&lt;span class="sb"&gt;`&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$&amp;quot;&lt;/span&gt;Unmounting /dev/&lt;span class="nv"&gt;$disk&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="s2"&gt;    umount /dev/&lt;/span&gt;&lt;span class="nv"&gt;$disk&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;

&lt;span class="s2"&gt;    echo &lt;/span&gt;&lt;span class="nv"&gt;$&amp;quot;&lt;/span&gt;&lt;span class="s2"&gt;mkfs /dev/&lt;/span&gt;&lt;span class="nv"&gt;$disk&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
    mkfs.ext4 -q /dev/&lt;span class="nv"&gt;$disk&lt;/span&gt;

    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$&amp;quot;&lt;/span&gt;Mounting /dev/&lt;span class="nv"&gt;$disk&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="s2"&gt;    mount -t ext4 /dev/&lt;/span&gt;&lt;span class="nv"&gt;$disk&lt;/span&gt;&lt;span class="s2"&gt; /tmp &amp;amp;&amp;amp; chmod 1777 /tmp &amp;amp;&amp;amp; success || failure&lt;/span&gt;
&lt;span class="s2"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;NB:&lt;/strong&gt; success and failure are from &lt;code&gt;/etc/rc.d/init.d/functions&lt;/code&gt;.
If you are using LVM or RAID you need to reconstruct your block devices
accordingly!&lt;/p&gt;
&lt;p&gt;If everything goes right I should be able to reduce my AWS costs by saving on
provisioned storage and I/O requests. I'll keep you posted on this after a month or two.&lt;/p&gt;</summary><category term="cloud"></category><category term="Amazon"></category></entry><entry><title>AWS Tip: Shrinking EBS Root Volume Size</title><link href="http://atodorov.org/blog/2014/02/07/aws-tip-shrinking-ebs-root-volume-size/" rel="alternate"></link><updated>2014-02-07T00:23:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2014-02-07:blog/2014/02/07/aws-tip-shrinking-ebs-root-volume-size/</id><summary type="html">&lt;p&gt;Amazon's Elastic Block Store volumes are easy to use and expand but notoriously
hard to shrink once their size has grown. Here is my tip for shrinking EBS size
and saving some money from over-provisioned storage. I'm assuming that you want to
shrink the root volume which is on EBS. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Write down the block device name for the root volume (/dev/sda1) - &lt;em&gt;from AWS console:
Instances; Select instance; Look at Details tab; See Root device or Block devices&lt;/em&gt;;&lt;/li&gt;
&lt;li&gt;Write down the availability zone of your instance - &lt;em&gt;from AWS console: Instances;
column Availability Zone&lt;/em&gt;;&lt;/li&gt;
&lt;li&gt;Stop instance;&lt;/li&gt;
&lt;li&gt;Create snapshot of the root volume;&lt;/li&gt;
&lt;li&gt;From the snapshot, create a second volume, in the &lt;strong&gt;same availability zone&lt;/strong&gt; as
your instance (you will have to attach it later). This will be your pristine source;&lt;/li&gt;
&lt;li&gt;Create new empty EBS volume (not based on a snapshot), with smaller size,
in the same availability zone - &lt;em&gt;from AWS console: Volumes; Create Volume;
Snapshot == No Snapshot&lt;/em&gt;; &lt;strong&gt;IMPORTANT&lt;/strong&gt; - size should be large enough to hold
all the files from the source file system (try &lt;code&gt;df -h&lt;/code&gt; on the source first);&lt;/li&gt;
&lt;li&gt;Attach both volumes to instance while taking note of the block devices names
you assign for them in the AWS console;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For example: In my case &lt;code&gt;/dev/sdc1&lt;/code&gt; is the source snapshot and &lt;code&gt;/dev/sdd1&lt;/code&gt; is the
empty target.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Start instance;&lt;/li&gt;
&lt;li&gt;Optionally check the source file system with &lt;code&gt;e2fsck -f /dev/sdc1&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;Create a file system for the empty volume - &lt;code&gt;mkfs.ext4 /dev/sdd1&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;Mount volumes at &lt;code&gt;/source&lt;/code&gt; and &lt;code&gt;/target&lt;/code&gt; respectively;&lt;/li&gt;
&lt;li&gt;Now sync the files: &lt;code&gt;rsync -aHAXxSP /source/ /target&lt;/code&gt;. &lt;strong&gt;Note the missing slash (/)
after &lt;code&gt;/target&lt;/code&gt;&lt;/strong&gt;. If you add it you will end up with files inside &lt;code&gt;/target/source/&lt;/code&gt;
which you don't want;&lt;/li&gt;
&lt;li&gt;Quickly verify the new directory structure with &lt;code&gt;ls -l /target&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;Unmount &lt;code&gt;/target&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;Optionally check the new file system for consistency &lt;code&gt;e2fsck -f /dev/sdd1&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IMPORTANT&lt;/strong&gt; - check how &lt;code&gt;/boot/grub/grub.conf&lt;/code&gt; specifies the root volume - 
by UUID, by LABEL, by device name, etc. You will have to duplicate the same for the
new smaller volume or update &lt;code&gt;/target/boot/grub/grub.conf&lt;/code&gt; to match the new volume.
Check &lt;code&gt;/target/etc/fstab&lt;/code&gt; as well!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In my case I had to &lt;code&gt;e2label /dev/sdd1 /&lt;/code&gt; because both &lt;code&gt;grub.conf&lt;/code&gt; and &lt;code&gt;fstab&lt;/code&gt; were
using the device label.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Shutdown the instance;&lt;/li&gt;
&lt;li&gt;Detach all volumes;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IMPORTANT&lt;/strong&gt; - attach the new smaller volume to the instance using the same block device
name from the first step (e.g. &lt;code&gt;/dev/sda1&lt;/code&gt;);&lt;/li&gt;
&lt;li&gt;Start the instance and verify it is working correctly;&lt;/li&gt;
&lt;li&gt;DELETE auxiliary volumes and snapshots so they don't take space and accumulate costs!&lt;/li&gt;
&lt;/ul&gt;</summary><category term="tips"></category><category term="Amazon"></category><category term="cloud"></category></entry><entry><title>Idempotent Django Email Sender with Amazon SQS and Memcache</title><link href="http://atodorov.org/blog/2013/12/11/idempotent-django-email-sender-with-amazon-sqs-and-memcache/" rel="alternate"></link><updated>2013-12-11T23:29:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-12-11:blog/2013/12/11/idempotent-django-email-sender-with-amazon-sqs-and-memcache/</id><summary type="html">&lt;p&gt;Recently I wrote about my problem with
&lt;a href="/blog/2013/12/06/duplicate-amazon-sqs-messages-cause-multiple-emails/"&gt;duplicate Amazon SQS messages causing multiple emails&lt;/a&gt;
for &lt;a href="http://www.dif.io"&gt;Difio&lt;/a&gt;. After considering several options and
feedback from 
&lt;a href="https://twitter.com/atodorov_/status/409429840820199424"&gt;@Answers4AWS&lt;/a&gt;
I wrote a small decorator to fix this.&lt;/p&gt;
&lt;p&gt;It uses the cache backend to prevent the task from executing twice
during the specified time frame. The code is available at
&lt;a href="https://djangosnippets.org/snippets/3010/"&gt;https://djangosnippets.org/snippets/3010/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As stated on Twitter you should use Memcache (or ElastiCache) for this.
If using Amazon S3 with my
&lt;a href="https://github.com/atodorov/django-s3-cache"&gt;django-s3-cache&lt;/a&gt; don't use the
&lt;code&gt;us-east-1&lt;/code&gt; region because it is eventually consistent.&lt;/p&gt;
&lt;p&gt;The solution is fast and simple on the development side and uses my existing
cache infrastructure so it doesn't cost anything more!&lt;/p&gt;
&lt;p&gt;There is still a race condition between marking the message as processed
and the second check but nevertheless this should minimize the possibility of
receiving duplicate emails to an accepted level. Only time will tell though!&lt;/p&gt;</summary><category term="cloud"></category><category term="Amazon"></category><category term="SQS"></category><category term="Django"></category><category term="Python"></category></entry><entry><title>Duplicate Amazon SQS Messages Cause Multiple Emails</title><link href="http://atodorov.org/blog/2013/12/06/duplicate-amazon-sqs-messages-cause-multiple-emails/" rel="alternate"></link><updated>2013-12-06T22:47:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-12-06:blog/2013/12/06/duplicate-amazon-sqs-messages-cause-multiple-emails/</id><summary type="html">&lt;p&gt;Beware if using Amazon Simple Queue Service to send email messages!
Sometime SQS messages are duplicated which results in multiple copies of
the messages being sent. This happened today at &lt;a href="http://www.dif.io"&gt;Difio&lt;/a&gt;
and is really annoying to users. In this post I will explain why there is no easy
way of fixing it.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Q: Can a deleted message be received again?&lt;/p&gt;
&lt;p&gt;Yes, under rare circumstances you might receive a previously deleted message again.
This can occur in the rare situation in which a DeleteMessage operation doesn't
delete all copies of a message because one of the servers in the distributed
Amazon SQS system isn't available at the time of the deletion. That message copy
can then be delivered again. You should design your application so that no errors
or inconsistencies occur if you receive a deleted message again.&lt;/p&gt;
&lt;p&gt;Amazon FAQ&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In my case the cron scheduler logs say:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&amp;gt;&amp;gt;&amp;gt; &amp;lt;AsyncResult: a9e5a73a-4d4a-4995-a91c-90295e27100a&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;While on the worker nodes the logs say:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;[2013-12-06 10:13:06,229: INFO/MainProcess] Got task from broker: tasks.cron_monthly_email_reminder[a9e5a73a-4d4a-4995-a91c-90295e27100a]&lt;/span&gt;
&lt;span class="k"&gt;[2013-12-06 10:18:09,456: INFO/MainProcess] Got task from broker: tasks.cron_monthly_email_reminder[a9e5a73a-4d4a-4995-a91c-90295e27100a]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This clearly shows the same message (see the UUID) has been processed twice!
This resulted in hundreds of duplicate emails :(.&lt;/p&gt;
&lt;h2&gt;Why This Is Hard To Fix&lt;/h2&gt;
&lt;p&gt;There are two basic approaches to solve this issue:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Check some log files or database for previous record of the message having
been processed;&lt;/li&gt;
&lt;li&gt;Use idempotent operations that if you process the message again, you
get the same results, and that those results don't create duplicate files/records.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The problem with checking for duplicate messages is: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There is a race condition between marking the message as processed and the
second check;&lt;/li&gt;
&lt;li&gt;You need to use some sort of locking mechanism to safe-guard against the race condition;&lt;/li&gt;
&lt;li&gt;In the event of an eventual consistency of the log/DB you can't guarantee that
the previous attempt will show up and so can't guarantee that you won't process
the message twice.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All of the above don't seem to work well for distributed applications not to mention
Difio processes millions of messages per month, per node and the logs are quite big.&lt;/p&gt;
&lt;p&gt;The second option is to have control of the Message-Id or some other email header
so that the second message will be discarded either at the server (Amazon SES in my case)
or at the receiving MUA. I like this better but I don't think it is technically possible
with the current environment. Need to check though. &lt;/p&gt;
&lt;p&gt;I've asked AWS support to look into
&lt;a href="https://forums.aws.amazon.com/thread.jspa?threadID=140782"&gt;this thread&lt;/a&gt; and hopefully
they will have some more hints. If you have any other ideas please post in the comments!
Thanks!&lt;/p&gt;</summary><category term="cloud"></category><category term="Amazon"></category><category term="SQS"></category><category term="SES"></category></entry><entry><title>How I Created a Website In Two Days Without Coding</title><link href="http://atodorov.org/blog/2013/07/31/how-i-created-a-website-in-two-days-without-coding/" rel="alternate"></link><updated>2013-07-31T21:55:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-07-31:blog/2013/07/31/how-i-created-a-website-in-two-days-without-coding/</id><summary type="html">&lt;p&gt;&lt;img alt="header image" src="/images/logos/obuvki41plus_header.png" title="header image" /&gt;&lt;/p&gt;
&lt;p&gt;This is a simple story about a website I helped create without using any
programming at all. It took me two days because of the images and the logo
design which I've commissioned to a friend.&lt;/p&gt;
&lt;p&gt;The website is &lt;a href="http://obuvki41plus.com/"&gt;obuvki41plus.com&lt;/a&gt; which is a
re-seller business my spouse runs. It specializes in large size, elegant
ladies shoes - Europe size 41 plus (hard to find in Bulgaria),
hence the name.&lt;/p&gt;
&lt;h2&gt;Required Functionality&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Display a catalog of items for sale with detailed information about
each item;&lt;/li&gt;
&lt;li&gt;Make it possible for people to comment and share the items;&lt;/li&gt;
&lt;li&gt;Very basic shopping cart which stores the selected items and then
redirects to a page with order instructions. Actual order is made via
phone for several reasons which I will explain in
&lt;a href="/blog/2013/08/01/why-taking-orders-by-phone-works-for-my-start-up/"&gt;another post&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;Add a feedback/contact form;&lt;/li&gt;
&lt;li&gt;Look nice on mobile devices.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Technology&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The website is static, all pages are simple HTML and is hosted in
Amazon S3;&lt;/li&gt;
&lt;li&gt;Comments are provided by Facebook's
&lt;a href="https://developers.facebook.com/docs/reference/plugins/comments/"&gt;Comments Box&lt;/a&gt;
plug-in;&lt;/li&gt;
&lt;li&gt;Social media buttons and tracking are provided by
&lt;a href="https://www.addthis.com/"&gt;AddThis&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;Visitors analytics is standard and is from
&lt;a href="http://www.google.com/analytics/"&gt;Google Analytics&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;Template is from &lt;a href="http://pages.github.com/"&gt;GitHub Pages&lt;/a&gt; with slight
modifications; Works on mobile too;&lt;/li&gt;
&lt;li&gt;Logo is custom designed by my friend
&lt;a href="https://www.facebook.com/aluinpoli"&gt;Polina Valerieva&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;Feedback/contact form is by &lt;a href="https://www.uservoice.com/"&gt;UserVoice&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;Shopping cart is by &lt;a href="http://simplecartjs.org/"&gt;simpleCart(js)&lt;/a&gt;.
I've created a simple animation effect when pressing the "ADD TO CART"
link to visually alert the user. This is done with jQuery.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I could have used some JavaScript templating engine like
&lt;a href="http://handlebarsjs.com/"&gt;Handlebars&lt;/a&gt; but at the time I didn't know about
it and I prefer not to write JavaScript if possible :).&lt;/p&gt;
&lt;h2&gt;Colophon&lt;/h2&gt;
&lt;p&gt;I did some coding after the initial release eventually. 
I've transformed the website to a Django
based site which is exported as static HTML. &lt;/p&gt;
&lt;p&gt;This helps me with faster deployment/management as everything is stored
in git, allows templates inheritance and also makes the site ready to
add more functionality if required.&lt;/p&gt;</summary><category term="Amazon"></category><category term="S3"></category></entry><entry><title>What Runs Your Start-up - Imagga</title><link href="http://atodorov.org/blog/2013/07/29/what-runs-your-startup-imagga/" rel="alternate"></link><updated>2013-07-29T12:32:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-07-29:blog/2013/07/29/what-runs-your-startup-imagga/</id><summary type="html">&lt;p&gt;&lt;img src="/images/startup/imagga.png" alt="Imagga" style="float:left; margin-right:10px;" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://imagga.com/"&gt;Imagga&lt;/a&gt; is a cloud platform that helps businesses and 
individuals organize their images in a fast and cost-effective way. They 
develop a range of advanced proprietary image recognition and image processing
technologies, which are built into several services such as smart image
cropping, color extraction and multi-color search, visual similarity search and
auto-tagging.&lt;/p&gt;
&lt;p&gt;During 
&lt;a href="/blog/2013/05/23/balkan-venture-forum-sofia-post-mortem/"&gt;Balkan Venture Forum&lt;/a&gt;
in Sofia I sat down with Georgi Kadrev to talk about technology.
Surprisingly this hi-tech service is built on top of standard low-tech components
and lots of hard work.&lt;/p&gt;
&lt;h2&gt;Main Technologies&lt;/h2&gt;
&lt;p&gt;Core functionality is developed in C and C++ with the OpenCV library. 
Imagga relies heavily on own image processing algorithms for their core
features. These were built as a combination of their own research activities
and publications from other researchers.&lt;/p&gt;
&lt;p&gt;Image processing is executed by worker nodes configured with their own
software stack. Nodes are distributed among Amazon EC2 and other data centers.&lt;/p&gt;
&lt;p&gt;Client libraries to access Imagga API are available in PHP, Ruby and Java.&lt;/p&gt;
&lt;p&gt;Imagga has built several websites to showcase their technology.
&lt;a href="http://cropp.me/"&gt;Cropp.me&lt;/a&gt;, &lt;a href="http://colorslike.me/"&gt;ColorsLike.me&lt;/a&gt;,
&lt;a href="http://www.stockpodium.com"&gt;StockPodium&lt;/a&gt; and &lt;a href="http://autotag.me/"&gt;AutoTag.me&lt;/a&gt;
were built with PHP, JavaScript and jQuery above a standard LAMP stack.&lt;/p&gt;
&lt;p&gt;Recently Imagga also started using GPU computing with nVidia Tesla cards.
They use C++ and Python bindings for
&lt;a href="https://developer.nvidia.com/what-cuda"&gt;CUDA&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Why Not Something Else?&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;As an initially bootstrapping start-up we chose something that is basically free,
reliable and popular - that's why started with the LAMP stack. It proved to be
stable and convenient for our web needs and we preserved it.
The use of C++ is a natural choice for computational intensive tasks that we
need to perform for the purpose of our core expertise - image processing. 
Though we initially wrote the whole core technology code from scratch, we later
switched to OpenCV for some of the building blocks as it is very well optimized
and continuously extended image processing library.&lt;/p&gt;
&lt;p&gt;With the raise of affordable high-performance GPU processors and their availability
in server instances, we decided it's time to take advantage of this highly parallel
architecture, perfectly suitable for image processing tasks.&lt;/p&gt;
&lt;p&gt;Georgi Kadrev&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Want More Info?&lt;/h2&gt;
&lt;p&gt;If you’d like to hear more from Imagga please comment below.
I will ask them to follow this thread and reply to your questions.&lt;/p&gt;</summary><category term="what runs"></category><category term="start-up"></category><category term="Amazon"></category><category term="EC2"></category></entry><entry><title>Performance test: Amazon ElastiCache vs Amazon S3</title><link href="http://atodorov.org/blog/2013/06/26/performance-test-amazon-elasticache-vs-amazon-s3/" rel="alternate"></link><updated>2013-06-26T21:22:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-06-26:blog/2013/06/26/performance-test-amazon-elasticache-vs-amazon-s3/</id><summary type="html">&lt;p&gt;Which Django cache backend is faster? Amazon ElastiCache or Amazon S3 ?&lt;/p&gt;
&lt;p&gt;Previously I've mentioned about
&lt;a href="/blog/2013/06/19/django-tips-using-cache-for-stateful-http/"&gt;using Django's cache to keep state between HTTP requests&lt;/a&gt;.
In my demo described there I was using &lt;a href="http://github.com/atodorov/django-s3-cache"&gt;django-s3-cache&lt;/a&gt;.
It is time to move to production so I decided to measure the performance difference between the two
cache options available at Amazon Web Services.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update 2013-07-01&lt;/strong&gt;: my initial test may have been false since I had not configured
ElastiCache access properly. I saw no errors but discovered the issue today on another
system which was failing to store the cache keys but didn't show any errors either. 
I've re-run the tests and updated times are shown below.&lt;/p&gt;
&lt;h2&gt;Test infrastructure&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;One Amazon S3 bucket, located in US Standard (aka US East) region;&lt;/li&gt;
&lt;li&gt;One Amazon ElastiCache cluster with one Small Cache Node (cache.m1.small) with Moderate I/O capacity;&lt;/li&gt;
&lt;li&gt;One Amazon Elasticache cluster with one Large Cache Node (cache.m1.large) with High I/O Capacity;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Update:&lt;/strong&gt; I've tested both &lt;code&gt;python-memcached&lt;/code&gt; and &lt;code&gt;pylibmc&lt;/code&gt; client libraries for Django;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Update:&lt;/strong&gt; Test is executed from an EC2 node in the us-east-1a availability zone;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Update:&lt;/strong&gt; Cache clusters are in the us-east-1a availability zone.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Test Scenario&lt;/h2&gt;
&lt;p&gt;The test platform is Django. I've created a
&lt;a href="https://github.com/atodorov/Amazon-ElastiCache-vs-Amazon-S3-Django"&gt;skeleton project&lt;/a&gt;
with only &lt;code&gt;CACHES&lt;/code&gt; settings
defined and necessary dependencies installed. A file called &lt;code&gt;test.py&lt;/code&gt; holds the
test cases, which use the standard timeit module. The object which is stored in cache
is very small - it holds a phone/address identifiers and couple of user made selections.
The code looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;timeit&lt;/span&gt;

&lt;span class="n"&gt;s3_set&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;timeit&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Timer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;for i in range(1000):&lt;/span&gt;
&lt;span class="sd"&gt;    my_cache.set(i, MyObject)&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;from django.core import cache&lt;/span&gt;

&lt;span class="sd"&gt;my_cache = cache.get_cache(&amp;#39;default&amp;#39;)&lt;/span&gt;

&lt;span class="sd"&gt;MyObject = {&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;from&amp;#39; : &amp;#39;359123456789&amp;#39;,&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;address&amp;#39; : &amp;#39;6afce9f7-acff-49c5-9fbe-14e238f73190&amp;#39;,&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;hour&amp;#39; : &amp;#39;12:30&amp;#39;,&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;weight&amp;#39; : 5,&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;type&amp;#39; : 1,&lt;/span&gt;
&lt;span class="sd"&gt;}&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;s3_get&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;timeit&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Timer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;for i in range(1000):&lt;/span&gt;
&lt;span class="sd"&gt;    MyObject = my_cache.get(i)&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;from django.core import cache&lt;/span&gt;

&lt;span class="sd"&gt;my_cache = cache.get_cache(&amp;#39;default&amp;#39;)&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Tests were executed from the Django shell &lt;del&gt;on my laptop&lt;/del&gt;
on an EC2 instance in the us-east-1a availability zone. ElastiCache nodes
were freshly created/rebooted before test execution. S3 bucket had no objects.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="err"&gt;$&lt;/span&gt; &lt;span class="o"&gt;./&lt;/span&gt;&lt;span class="n"&gt;manage&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="n"&gt;shell&lt;/span&gt;
&lt;span class="n"&gt;Python&lt;/span&gt; &lt;span class="mf"&gt;2.6&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;unknown&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Mar&lt;/span&gt; &lt;span class="mi"&gt;14&lt;/span&gt; &lt;span class="mi"&gt;2013&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;31&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;GCC&lt;/span&gt; &lt;span class="mf"&gt;4.6&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;20111027&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Red&lt;/span&gt; &lt;span class="n"&gt;Hat&lt;/span&gt; &lt;span class="mf"&gt;4.6&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;linux2&lt;/span&gt;
&lt;span class="n"&gt;Type&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;help&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;copyright&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;credits&amp;quot;&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;license&amp;quot;&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;more&lt;/span&gt; &lt;span class="n"&gt;information&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;InteractiveConsole&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;test&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;s3_set&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;68.089607000350952&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;70.806712865829468&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;72.49261999130249&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;s3_get&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;43.778793096542358&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;43.054368019104004&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;36.19232702255249&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;pymc_set&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.40637087821960449&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.3568730354309082&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.35815882682800293&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;pymc_get&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.35759496688842773&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.35180497169494629&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.39198613166809082&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;libmc_set&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.3902890682220459&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.30157709121704102&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.30596804618835449&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;libmc_get&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.28874802589416504&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.30520200729370117&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.29050207138061523&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;libmc_large_set&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;1.0291709899902344&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.31709098815917969&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.32010698318481445&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;libmc_large_get&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.2957158088684082&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.29067802429199219&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.29692888259887695&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Results&lt;/h2&gt;
&lt;p&gt;As expected ElastiCache is much faster (10x) compared to S3. However the difference
between the two ElastiCache node types is subtle. I will stay with the smallest
possible node to minimize costs. Also as seen, pylibmc is a bit faster compared to
the pure Python implementation. &lt;/p&gt;
&lt;p&gt;Depending on your objects size or how many set/get operations you perform per
second you may need to go with the larger nodes. Just test it!&lt;/p&gt;
&lt;p&gt;&lt;del&gt;It surprised me how slow django-s3-cache is.&lt;/del&gt;
The false test showed django-s3-cache to be 100x slower but new results are better.
10x decrease in performance sounds about right for a filesystem backed cache.&lt;/p&gt;
&lt;p&gt;A quick look at the code
of the two backends shows some differences. The one I immediately see is that
for every cache key django-s3-cache creates an sha1 hash which is used as the
storage file name. This was modeled after the filesystem backend but I think the
design is wrong - the memcached backends don't do this.&lt;/p&gt;
&lt;p&gt;Another one is that django-s3-cache time-stamps all objects and uses pickle to serialize them. 
I wonder if it can't just write them as binary blobs directly. There's definitely lots
of room for improvement of django-s3-cache. I will let you know my findings once I
get to it. &lt;/p&gt;</summary><category term="Amazon"></category><category term="S3"></category><category term="ElastiCache"></category><category term="QA"></category><category term="performance testing"></category><category term="cloud"></category></entry><entry><title>Twilio is Located in Amazon Web Services US East</title><link href="http://atodorov.org/blog/2013/06/24/twilio-is-located-in-amazon-web-services-us-east/" rel="alternate"></link><updated>2013-06-24T23:43:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-06-24:blog/2013/06/24/twilio-is-located-in-amazon-web-services-us-east/</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;Where do I store my audio files in order to minimize download and call wait time?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Twilio is a cloud vendor that provides telephony services. 
It can download and &lt;code&gt;&amp;lt;Play&amp;gt;&lt;/code&gt; arbitrary audio files and will cache the files
for better performance.&lt;/p&gt;
&lt;p&gt;Twilio support told me they are not disclosing the location of their servers,
so from my web application hosted in AWS US East:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;[&lt;/span&gt;ivr-otb.rhcloud.com logs&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="se"&gt;\&amp;gt;&lt;/span&gt; grep TwilioProxy access_log-* &lt;span class="p"&gt;|&lt;/span&gt; cut -f &lt;span class="m"&gt;1&lt;/span&gt; -d &lt;span class="s1"&gt;&amp;#39;-&amp;#39;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; sort &lt;span class="p"&gt;|&lt;/span&gt; uniq 
10.125.90.172 
10.214.183.239 
10.215.187.220 
10.245.155.18 
10.255.119.159 
10.31.197.102
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now let's map these addresses to host names. From another EC2 system, also in Amazon US East:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;[&lt;/span&gt;ec2-user@ip-10-29-206-86 ~&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;dig -x 10.125.90.172 -x 10.214.183.239 -x 10.215.187.220 -x 10.245.155.18 -x 10.255.119.159 -x 10.31.197.102

&lt;span class="p"&gt;;&lt;/span&gt; &amp;lt;&amp;lt;&amp;gt;&amp;gt; DiG 9.8.2rc1-RedHat-9.8.2-0.17.rc1.29.amzn1 &amp;lt;&amp;lt;&amp;gt;&amp;gt; -x 10.125.90.172 -x 10.214.183.239 -x 10.215.187.220 -x 10.245.155.18 -x 10.255.119.159 -x 10.31.197.102
&lt;span class="p"&gt;;;&lt;/span&gt; global options: +cmd
&lt;span class="p"&gt;;;&lt;/span&gt; Got answer:
&lt;span class="p"&gt;;;&lt;/span&gt; -&amp;gt;&amp;gt;HEADER&lt;span class="s"&gt;&amp;lt;&amp;lt;- opcode: QUERY, status: NOERROR, id: 43245&lt;/span&gt;
&lt;span class="s"&gt;;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0&lt;/span&gt;

&lt;span class="s"&gt;;; QUESTION SECTION:&lt;/span&gt;
&lt;span class="s"&gt;;172.90.125.10.in-addr.arpa.    IN      PTR&lt;/span&gt;

&lt;span class="s"&gt;;; ANSWER SECTION:&lt;/span&gt;
&lt;span class="s"&gt;172.90.125.10.in-addr.arpa. 113 IN      PTR     ip-10-125-90-172.ec2.internal.&lt;/span&gt;

&lt;span class="s"&gt;;; Query time: 1 msec&lt;/span&gt;
&lt;span class="s"&gt;;; SERVER: 172.16.0.23#53(172.16.0.23)&lt;/span&gt;
&lt;span class="s"&gt;;; WHEN: Mon Jun 24 20:48:21 2013&lt;/span&gt;
&lt;span class="s"&gt;;; MSG SIZE  rcvd: 87&lt;/span&gt;

&lt;span class="s"&gt;;; Got answer:&lt;/span&gt;
&lt;span class="s"&gt;;; -&amp;gt;&amp;gt;HEADER&amp;lt;&amp;lt;- opcode&lt;/span&gt;: QUERY, status: NOERROR, id: 52693
&lt;span class="p"&gt;;;&lt;/span&gt; flags: qr rd ra&lt;span class="p"&gt;;&lt;/span&gt; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0

&lt;span class="p"&gt;;;&lt;/span&gt; QUESTION SECTION:
&lt;span class="p"&gt;;&lt;/span&gt;239.183.214.10.in-addr.arpa.   IN      PTR

&lt;span class="p"&gt;;;&lt;/span&gt; ANSWER SECTION:
239.183.214.10.in-addr.arpa. &lt;span class="m"&gt;42619&lt;/span&gt; IN   PTR     domU-12-31-39-0B-B0-01.compute-1.internal.

&lt;span class="p"&gt;;;&lt;/span&gt; Query &lt;span class="nb"&gt;time&lt;/span&gt;: &lt;span class="m"&gt;0&lt;/span&gt; msec
&lt;span class="p"&gt;;;&lt;/span&gt; SERVER: 172.16.0.23#53&lt;span class="o"&gt;(&lt;/span&gt;172.16.0.23&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;;;&lt;/span&gt; WHEN: Mon Jun &lt;span class="m"&gt;24&lt;/span&gt; 20:48:21 2013
&lt;span class="p"&gt;;;&lt;/span&gt; MSG SIZE  rcvd: 100

&lt;span class="p"&gt;;;&lt;/span&gt; Got answer:
&lt;span class="p"&gt;;;&lt;/span&gt; -&amp;gt;&amp;gt;HEADER&lt;span class="s"&gt;&amp;lt;&amp;lt;- opcode: QUERY, status: NOERROR, id: 25255&lt;/span&gt;
&lt;span class="s"&gt;;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0&lt;/span&gt;

&lt;span class="s"&gt;;; QUESTION SECTION:&lt;/span&gt;
&lt;span class="s"&gt;;220.187.215.10.in-addr.arpa.   IN      PTR&lt;/span&gt;

&lt;span class="s"&gt;;; ANSWER SECTION:&lt;/span&gt;
&lt;span class="s"&gt;220.187.215.10.in-addr.arpa. 43140 IN   PTR     domU-12-31-39-0C-B8-2E.compute-1.internal.&lt;/span&gt;

&lt;span class="s"&gt;;; Query time: 0 msec&lt;/span&gt;
&lt;span class="s"&gt;;; SERVER: 172.16.0.23#53(172.16.0.23)&lt;/span&gt;
&lt;span class="s"&gt;;; WHEN: Mon Jun 24 20:48:21 2013&lt;/span&gt;
&lt;span class="s"&gt;;; MSG SIZE  rcvd: 100&lt;/span&gt;

&lt;span class="s"&gt;;; Got answer:&lt;/span&gt;
&lt;span class="s"&gt;;; -&amp;gt;&amp;gt;HEADER&amp;lt;&amp;lt;- opcode&lt;/span&gt;: QUERY, status: NOERROR, id: 15099
&lt;span class="p"&gt;;;&lt;/span&gt; flags: qr rd ra&lt;span class="p"&gt;;&lt;/span&gt; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0

&lt;span class="p"&gt;;;&lt;/span&gt; QUESTION SECTION:
&lt;span class="p"&gt;;&lt;/span&gt;18.155.245.10.in-addr.arpa.    IN      PTR

&lt;span class="p"&gt;;;&lt;/span&gt; ANSWER SECTION:
18.155.245.10.in-addr.arpa. &lt;span class="m"&gt;840&lt;/span&gt; IN      PTR     ip-10-245-155-18.ec2.internal.

&lt;span class="p"&gt;;;&lt;/span&gt; Query &lt;span class="nb"&gt;time&lt;/span&gt;: &lt;span class="m"&gt;0&lt;/span&gt; msec
&lt;span class="p"&gt;;;&lt;/span&gt; SERVER: 172.16.0.23#53&lt;span class="o"&gt;(&lt;/span&gt;172.16.0.23&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;;;&lt;/span&gt; WHEN: Mon Jun &lt;span class="m"&gt;24&lt;/span&gt; 20:48:21 2013
&lt;span class="p"&gt;;;&lt;/span&gt; MSG SIZE  rcvd: 87

&lt;span class="p"&gt;;;&lt;/span&gt; Got answer:
&lt;span class="p"&gt;;;&lt;/span&gt; -&amp;gt;&amp;gt;HEADER&lt;span class="s"&gt;&amp;lt;&amp;lt;- opcode: QUERY, status: NOERROR, id: 28878&lt;/span&gt;
&lt;span class="s"&gt;;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0&lt;/span&gt;

&lt;span class="s"&gt;;; QUESTION SECTION:&lt;/span&gt;
&lt;span class="s"&gt;;159.119.255.10.in-addr.arpa.   IN      PTR&lt;/span&gt;

&lt;span class="s"&gt;;; ANSWER SECTION:&lt;/span&gt;
&lt;span class="s"&gt;159.119.255.10.in-addr.arpa. 43140 IN   PTR     domU-12-31-39-01-70-51.compute-1.internal.&lt;/span&gt;

&lt;span class="s"&gt;;; Query time: 0 msec&lt;/span&gt;
&lt;span class="s"&gt;;; SERVER: 172.16.0.23#53(172.16.0.23)&lt;/span&gt;
&lt;span class="s"&gt;;; WHEN: Mon Jun 24 20:48:21 2013&lt;/span&gt;
&lt;span class="s"&gt;;; MSG SIZE  rcvd: 100&lt;/span&gt;

&lt;span class="s"&gt;;; Got answer:&lt;/span&gt;
&lt;span class="s"&gt;;; -&amp;gt;&amp;gt;HEADER&amp;lt;&amp;lt;- opcode&lt;/span&gt;: QUERY, status: NOERROR, id: 28727
&lt;span class="p"&gt;;;&lt;/span&gt; flags: qr rd ra&lt;span class="p"&gt;;&lt;/span&gt; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0

&lt;span class="p"&gt;;;&lt;/span&gt; QUESTION SECTION:
&lt;span class="p"&gt;;&lt;/span&gt;102.197.31.10.in-addr.arpa.    IN      PTR

&lt;span class="p"&gt;;;&lt;/span&gt; ANSWER SECTION:
102.197.31.10.in-addr.arpa. &lt;span class="m"&gt;840&lt;/span&gt; IN      PTR     ip-10-31-197-102.ec2.internal.

&lt;span class="p"&gt;;;&lt;/span&gt; Query &lt;span class="nb"&gt;time&lt;/span&gt;: &lt;span class="m"&gt;0&lt;/span&gt; msec
&lt;span class="p"&gt;;;&lt;/span&gt; SERVER: 172.16.0.23#53&lt;span class="o"&gt;(&lt;/span&gt;172.16.0.23&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;;;&lt;/span&gt; WHEN: Mon Jun &lt;span class="m"&gt;24&lt;/span&gt; 20:48:21 2013
&lt;span class="p"&gt;;;&lt;/span&gt; MSG SIZE  rcvd: 87
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In short:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;ip-10-125-90-172.ec2.internal.
ip-10-245-155-18.ec2.internal.
ip-10-31-197-102.ec2.internal.
domU-12-31-39-01-70-51.compute-1.internal.
domU-12-31-39-0B-B0-01.compute-1.internal.
domU-12-31-39-0C-B8-2E.compute-1.internal.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;ip-*.ec2.internal&lt;/code&gt; are clearly in US East. The &lt;code&gt;domU-*.computer-1.internal&lt;/code&gt; also
look like US East although I'm not 100% sure what is the difference between the two.
The later ones look like HVM guests while the former ones are para-virtualized.&lt;/p&gt;
&lt;p&gt;For comparison here are some internal addresses from my own EC2 systems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ip-10-228-237-207.eu-west-1.compute.internal - EU Ireland&lt;/li&gt;
&lt;li&gt;ip-10-248-19-46.us-west-2.compute.internal - US West Oregon&lt;/li&gt;
&lt;li&gt;ip-10-160-58-141.us-west-1.compute.internal - US West N. California&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After relocating my audio files to an S3 bucket in US East the average call length
dropped from 2:30 min to 2:00 min for the same IVR choices. This also minimizes
the costs since Twilio charges per minute of incoming/outgoing calls.
I think the audio quality has improved as well.&lt;/p&gt;</summary><category term="Twilio"></category><category term="Amazon"></category><category term="cloud"></category></entry><entry><title>Tip: Caching Large Objects for Celery and Amazon SQS</title><link href="http://atodorov.org/blog/2013/06/19/tip-caching-large-objects-for-celery-and-amazon-sqs/" rel="alternate"></link><updated>2013-06-19T14:29:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-06-19:blog/2013/06/19/tip-caching-large-objects-for-celery-and-amazon-sqs/</id><summary type="html">&lt;p&gt;Some time ago a guy called Matt
&lt;a href="https://groups.google.com/forum/?fromgroups=#!topic/celery-users/RFAuGjZwtmg"&gt;asked&lt;/a&gt;
about passing large objects through their messaging queue. They were switching from
RabbitMQ to Amazon SQS which has a limit of 64K total message size.&lt;/p&gt;
&lt;p&gt;Recently I've made some changes in &lt;a href="http://www.dif.io"&gt;Difio&lt;/a&gt; which require passing
larger objects as parameters to a Celery task. Since Difio is also using SQS I faced the
same problem. Here is the solution using a cache back-end: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;celery.task&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;task&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;django.core&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;cache&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;cache_module&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;some_method&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt; &lt;span class="n"&gt;skip&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;

    &lt;span class="n"&gt;task_cache&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cache_module&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_cache&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;taskq&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;task_cache&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uuid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3600&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;handle_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;delay&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uuid&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="o"&gt;...&lt;/span&gt; &lt;span class="n"&gt;skip&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;

&lt;span class="nd"&gt;@task&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;handle_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uuid&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;task_cache&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cache_module&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_cache&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;taskq&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;task_cache&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uuid&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt;

    &lt;span class="o"&gt;...&lt;/span&gt; &lt;span class="n"&gt;do&lt;/span&gt; &lt;span class="n"&gt;stuff&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Objects are persisted in a secondary cache back-end, not the default one, to avoid
accidental destruction. &lt;code&gt;uuid&lt;/code&gt; parameter is a string.&lt;/p&gt;
&lt;p&gt;Although the objects passed are smaller than 64K I haven't seen any issues
with this solution so far. Let me know if you are using something similar in your code
and how it works for you. &lt;/p&gt;</summary><category term="tips"></category><category term="Amazon"></category><category term="SQS"></category><category term="cloud"></category></entry><entry><title>What Runs Your Start-up - Useful at Night</title><link href="http://atodorov.org/blog/2013/03/27/what-runs-your-startup-useful-at-night/" rel="alternate"></link><updated>2013-03-27T12:00:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-03-27:blog/2013/03/27/what-runs-your-startup-useful-at-night/</id><summary type="html">&lt;p&gt;&lt;img style="float: left; margin-right: 10px;" src="/images/startup/usefulatnight.png" alt="Useful at Night logo" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://usefulatnight.com/"&gt;Useful at Night&lt;/a&gt; is a mobile guide for nightlife
empowering real time discovery of cool locations, allowing nightlife players
to identify opinion leaders. Through geo-location and data aggregation
capabilities, the application allows useful exploration of cities, places and
parties.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://about.me/velev"&gt;Evelin Velev&lt;/a&gt; was kind enough to share what technologies
his team uses to run their star-up.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h2&gt;Main Technologies&lt;/h2&gt;
&lt;p&gt;Main technologies used are Node.js, HTML 5 and NoSQL.&lt;/p&gt;
&lt;p&gt;Back-end application servers are written in Node.js and hosted at Heroku,
coupled with &lt;a href="http://www.redistogo.com/"&gt;RedisToGo&lt;/a&gt; for caching and
CouchDB served by &lt;a href="https://cloudant.com/"&gt;Cloudant&lt;/a&gt; for storage.&lt;/p&gt;
&lt;p&gt;Their mobile front-end supports both iOS and Android platforms and is built using
HTML5 and a homemade UI framework called RAPID. There are some native parts developed
in Objective-C and Java respectively.&lt;/p&gt;
&lt;p&gt;In addition &lt;em&gt;Useful at Night&lt;/em&gt; uses MongoDB for metrics data with a custom metrics solution
written in Node.js; Amazon S3 for storing different assets; and a custom storage solution
called Divan (simple CouchDB like).&lt;/p&gt;
&lt;h2&gt;Why Not Something Else?&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;We chose Node.js for our application servers, because it enables us to build efficient
distributed systems while sharing significant amounts of code between client and server.
Things get really interesting when you couple Node.js with Redis for data structure
sharing and message passing, as the two technologies play very well together.&lt;/p&gt;
&lt;p&gt;We chose CouchDB as our main back-end because it is the most schema-less data-store that
supports secondary indexing. Once you get fluent with its map-reduce views, you can
compute an index out of practically anything. For comparison, even MongoDB requires
that you design your documents as to enable certain indexing patterns. Put otherwise,
we'd say CouchDB is a data-store that enables truly lean engineering - we have never had
to re-bake or migrate our data since day one, while we're constantly experimenting with
new ways to index, aggregate and query it.&lt;/p&gt;
&lt;p&gt;We chose HTML5 as our front-end technology, because it's cross-platform and because we
believe it's ... almost ready. Things are still really problematic on Android, but iOS
boasts a gorgeous web presentation platform, and Windows 8 is also joining the game with
a very good web engine. Obviously we're constantly running into issues and limitations,
mostly related to the unfortunate fact that in spite of some recent developments,
a web app is still mostly single threaded. However, we're getting there, and we're proud
to say we're running a pretty graphically complex hybrid app with near-native GUI performance
on the iPhone 4S and above.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Want More Info?&lt;/h2&gt;
&lt;p&gt;If you'd like to hear more from &lt;em&gt;Useful at Night&lt;/em&gt; please comment below. I will ask them
to follow this thread and reply to your questions.&lt;/p&gt;</summary><category term="start-up"></category><category term="what runs"></category><category term="Node.js"></category><category term="HTML5"></category><category term="CouchDB"></category><category term="Redis"></category><category term="MongoDB"></category><category term="Amazon"></category><category term="S3"></category><category term="Heroku"></category><category term="iOS"></category><category term="Android"></category></entry><entry><title>Email Logging for Django on RedHat OpenShift with Amazon SES</title><link href="http://atodorov.org/blog/2013/02/28/email-logging-django-redhat-openshift-amazon-ses/" rel="alternate"></link><updated>2013-02-28T23:19:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-02-28:blog/2013/02/28/email-logging-django-redhat-openshift-amazon-ses/</id><summary type="html">&lt;p&gt;Sending email in the cloud can be tricky. IPs of cloud providers are blacklisted
because of frequent abuse. For that reason I use
&lt;a href="http://aws.amazon.com/ses/"&gt;Amazon SES&lt;/a&gt; as my email backend. Here is how to
configure &lt;a href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt; to send emails to site admins
when something goes wrong.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;span class="filename"&gt;settings.py&lt;/span&gt;&lt;pre&gt;&lt;span class="c"&gt;# Valid addresses only.&lt;/span&gt;
&lt;span class="n"&gt;ADMINS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Alexander Todorov&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;atodorov@example.com&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;LOGGING&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s"&gt;&amp;#39;version&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s"&gt;&amp;#39;disable_existing_loggers&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s"&gt;&amp;#39;handlers&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="s"&gt;&amp;#39;mail_admins&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="s"&gt;&amp;#39;level&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;ERROR&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="s"&gt;&amp;#39;class&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;django.utils.log.AdminEmailHandler&amp;#39;&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="s"&gt;&amp;#39;loggers&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="s"&gt;&amp;#39;django.request&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="s"&gt;&amp;#39;handlers&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;mail_admins&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
            &lt;span class="s"&gt;&amp;#39;level&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;ERROR&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="s"&gt;&amp;#39;propagate&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
 
&lt;span class="c"&gt;# Used as the From: address when reporting errors to admins&lt;/span&gt;
&lt;span class="c"&gt;# Needs to be verified in Amazon SES as a valid sender&lt;/span&gt;
&lt;span class="n"&gt;SERVER_EMAIL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;django@example.com&amp;#39;&lt;/span&gt;

&lt;span class="c"&gt;# Amazon Simple Email Service settings&lt;/span&gt;
&lt;span class="n"&gt;AWS_SES_ACCESS_KEY_ID&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;xxxxxxxxxxxx&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;AWS_SES_SECRET_ACCESS_KEY&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;xxxxxxxx&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;EMAIL_BACKEND&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;django_ses.SESBackend&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You also need the &lt;a href="https://github.com/hmarr/django-ses"&gt;django-ses&lt;/a&gt;
dependency.&lt;/p&gt;
&lt;p&gt;See &lt;a href="http://docs.djangoproject.com/en/dev/topics/logging"&gt;http://docs.djangoproject.com/en/dev/topics/logging&lt;/a&gt; for
more details on how to customize your logging configuration.&lt;/p&gt;
&lt;p&gt;I am using this configuration successfully at RedHat's OpenShift PaaS environment.
Other users have
&lt;a href="https://openshift.redhat.com/community/forums/express/missing-email-on-500-ise-w-django"&gt;reported&lt;/a&gt;
it works for them too. Should work with any other PaaS provider.&lt;/p&gt;</summary><category term="tips"></category><category term="Django"></category><category term="Amazon"></category><category term="SES"></category><category term="OpenShift"></category><category term="cloud"></category></entry><entry><title>Performance Test: Amazon EBS vs. Instance Storage, Pt.1</title><link href="http://atodorov.org/blog/2013/02/26/performance-test-amazon-ebs-vs-instance-storage-pt1/" rel="alternate"></link><updated>2013-02-26T23:02:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-02-26:blog/2013/02/26/performance-test-amazon-ebs-vs-instance-storage-pt1/</id><summary type="html">&lt;p&gt;I'm exploring the possibility to speed-up my cloud database so I've run some
basic tests against storage options available to Amazon EC2 instances.
The instance was &lt;a href="http://aws.amazon.com/ec2/instance-types/"&gt;m1.large&lt;/a&gt;
with High I/O performance and two additional disks with the same size:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;/dev/xvdb - type EBS&lt;/li&gt;
&lt;li&gt;/dev/xvdc - type instance storage&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Both are Xen para-virtual disks. The difference is that EBS is persistent
across reboots while instance storage is ephemeral.&lt;/p&gt;
&lt;h2&gt;hdparm&lt;/h2&gt;
&lt;p&gt;For a quick test I used &lt;code&gt;hdparm&lt;/code&gt;. The manual says:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;-T  Perform timings of cache reads for benchmark and comparison purposes.
    This displays the speed of reading directly from the Linux buffer cache
    without disk access. This measurement is essentially an indication of
    the throughput of the processor, cache, and memory of the system under test.

-t  Perform timings of device reads for benchmark and comparison purposes.
    This displays the speed of reading through the buffer cache to the disk
    without any prior caching of data. This measurement is an indication of how
    fast the drive can sustain sequential data reads under Linux, without any
    filesystem overhead.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The results of 3 runs of hdparm are shown below:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;# hdparm -tT /dev/xvdb /dev/xvdc

/dev/xvdb:
 Timing cached reads:   11984 MB in  1.98 seconds = 6038.36 MB/sec
 Timing buffered disk reads:  158 MB in  3.01 seconds =  52.52 MB/sec

/dev/xvdc:
 Timing cached reads:   11988 MB in  1.98 seconds = 6040.01 MB/sec
 Timing buffered disk reads:  1810 MB in  3.00 seconds = 603.12 MB/sec


# hdparm -tT /dev/xvdb /dev/xvdc

/dev/xvdb:
 Timing cached reads:   11892 MB in  1.98 seconds = 5991.51 MB/sec
 Timing buffered disk reads:  172 MB in  3.00 seconds =  57.33 MB/sec

/dev/xvdc:
 Timing cached reads:   12056 MB in  1.98 seconds = 6075.29 MB/sec
 Timing buffered disk reads:  1972 MB in  3.00 seconds = 657.11 MB/sec


# hdparm -tT /dev/xvdb /dev/xvdc

/dev/xvdb:
 Timing cached reads:   11994 MB in  1.98 seconds = 6042.39 MB/sec
 Timing buffered disk reads:  254 MB in  3.02 seconds =  84.14 MB/sec

/dev/xvdc:
 Timing cached reads:   11890 MB in  1.99 seconds = 5989.70 MB/sec
 Timing buffered disk reads:  1962 MB in  3.00 seconds = 653.65 MB/sec
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Result:&lt;/strong&gt;
Sequential reads from instance storage are 10x faster compared to EBS on average.&lt;/p&gt;
&lt;h2&gt;IOzone&lt;/h2&gt;
&lt;p&gt;I'm running MySQL and sequential data reads are probably over idealistic scenario.
So I found another benchmark suite, called &lt;a href="http://iozone.org"&gt;IOzone&lt;/a&gt;.
I used the 3-414 version built from the official SRPM.&lt;/p&gt;
&lt;p&gt;IOzone performs multiple tests. I'm interested in read/re-read, random-read/write,
read-backwards and stride-read.&lt;/p&gt;
&lt;p&gt;For this round of testing I've tested with ext4 filesystem with and without journal
on both types of disks. I also experimented running Iozone inside a ramfs mounted
directory. However I didn't have the time to run the test suite multiple times.&lt;/p&gt;
&lt;p&gt;Then I used
&lt;a href="http://code.google.com/p/iozone-results-comparator/"&gt;iozone-results-comparator&lt;/a&gt; to
visualize the results. (I had to do a minor fix to the code to run inside virtualenv
and install all missing dependencies).&lt;/p&gt;
&lt;p&gt;Raw IOzone output, data visualization and the modified tools are available in the
&lt;a href="http://s3.amazonaws.com/atodorov/blog/aws_disk_benchmark_w_iozone.tar.bz2"&gt;aws_disk_benchmark_w_iozone.tar.bz2&lt;/a&gt;
file (size 51M).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Graphics&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;EBS without journal(Baseline) vs. Instance Storage without journal(Set1)
&lt;img alt="EBS vs. Instance Storage" src="/images/aws_iozone/ebs_woj_vs_is_woj.png" title="EBS vs. Instance Storage" /&gt;&lt;/p&gt;
&lt;p&gt;Instance Storage without journal(Baseline) vs. Ramfs(Set1)
&lt;img alt="IS vs. Ramfs" src="/images/aws_iozone/is_woj_vs_ramfs.png" title="IS vs. Ramfs" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Results&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ext4 journal has no effect on reads, causes slow down when writing to disk. This
is expected;&lt;/li&gt;
&lt;li&gt;Instance storage is faster compared to EBS but not much.
If I understand the results correctly, read performance is similar in some cases;&lt;/li&gt;
&lt;li&gt;Ramfs is definitely the fastest but read performance compared to instance storage
is not two-fold (or more) as I expected;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Instance storage appears to be faster (and this is expected) but I'm still not sure if
my application will gain any speed improvement or how much if migrated to read from
instance storage (or ramfs) instead of EBS. I will be performing more real-world
test next time, by comparing execution time for some of my largest SQL queries.&lt;/p&gt;
&lt;p&gt;If you have other ideas how to adequately measure I/O performance in the AWS cloud,
please use the comments below.&lt;/p&gt;</summary><category term="performance testing"></category><category term="QA"></category><category term="Amazon"></category><category term="EC2"></category><category term="cloud"></category></entry><entry><title>How Large Are My MySQL Tables</title><link href="http://atodorov.org/blog/2013/02/20/how-large-are-my-mysql-tables/" rel="alternate"></link><updated>2013-02-20T12:03:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-02-20:blog/2013/02/20/how-large-are-my-mysql-tables/</id><summary type="html">&lt;p&gt;&lt;img src="/images/database.jpg" alt="database" style="display:block;clear:both;"/&gt;
Image CC-BY-SA, &lt;a href="http://www.flickr.com/photos/theredproject/3332644561/"&gt;Michael Mandiberg&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I found two good blog posts about investigating MySQL internals: 
&lt;a href="http://www.mysqlperformanceblog.com/2008/03/17/researching-your-mysql-table-sizes/"&gt;Researching your MySQL table sizes&lt;/a&gt; and
&lt;a href="http://www.mysqlperformanceblog.com/2008/02/04/finding-out-largest-tables-on-mysql-server/"&gt;Finding out largest tables on MySQL Server&lt;/a&gt;.
Using the queries against my site &lt;a href="http://www.dif.io"&gt;Difio&lt;/a&gt; showed:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;mysql&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="n"&gt;CONCAT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;table_schema&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;table_name&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;        &lt;span class="n"&gt;CONCAT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ROUND&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;table_rows&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;1000000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;M&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                                    &lt;span class="k"&gt;rows&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;        &lt;span class="n"&gt;CONCAT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ROUND&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data_length&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt; &lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;G&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                    &lt;span class="k"&gt;DATA&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;        &lt;span class="n"&gt;CONCAT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ROUND&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;index_length&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt; &lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;G&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                   &lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;        &lt;span class="n"&gt;CONCAT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ROUND&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt; &lt;span class="n"&gt;data_length&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;index_length&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt; &lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;G&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;total_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;        &lt;span class="n"&gt;ROUND&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;index_length&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;data_length&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                                           &lt;span class="n"&gt;idxfrac&lt;/span&gt;
    &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;FROM&lt;/span&gt;   &lt;span class="n"&gt;information_schema&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TABLES&lt;/span&gt;
    &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;ORDER&lt;/span&gt;  &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="n"&gt;data_length&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;index_length&lt;/span&gt; &lt;span class="k"&gt;DESC&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;----------------------------------------+-------+-------+-------+------------+---------+&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;CONCAT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;table_schema&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;table_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="k"&gt;rows&lt;/span&gt;  &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="k"&gt;DATA&lt;/span&gt;  &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt;   &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;total_size&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;idxfrac&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;----------------------------------------+-------+-------+-------+------------+---------+&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;difio&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;difio_advisory&lt;/span&gt;                   &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;04&lt;/span&gt;&lt;span class="n"&gt;M&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="k"&gt;G&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt;&lt;span class="k"&gt;G&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="k"&gt;G&lt;/span&gt;      &lt;span class="o"&gt;|&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;----------------------------------------+-------+-------+-------+------------+---------+&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The table of interest is &lt;code&gt;difio_advisory&lt;/code&gt; which had 5 &lt;code&gt;longtext&lt;/code&gt; fields. Those fields were
not used for filtering or indexing the rest of the information.
They were just storage fields - a `nice' side effect of using Django's ORM.&lt;/p&gt;
&lt;p&gt;I have migrated the data to Amazon S3 and stored it in JSON format there. After dropping these
fields the table was considerably smaller:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;----------------------------------------+-------+-------+-------+------------+---------+&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;CONCAT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;table_schema&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;table_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="k"&gt;rows&lt;/span&gt;  &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="k"&gt;DATA&lt;/span&gt;  &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt;   &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;total_size&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;idxfrac&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;----------------------------------------+-------+-------+-------+------------+---------+&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;difio&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;difio_advisory&lt;/span&gt;                   &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;01&lt;/span&gt;&lt;span class="n"&gt;M&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt;&lt;span class="k"&gt;G&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt;&lt;span class="k"&gt;G&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt;&lt;span class="k"&gt;G&lt;/span&gt;      &lt;span class="o"&gt;|&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;90&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;----------------------------------------+-------+-------+-------+------------+---------+&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;For those interested I'm using &lt;a href="https://github.com/e-loue/django-storages"&gt;django-storages&lt;/a&gt;
on the back-end to save the data in S3 when generated. On the front-end I'm using
&lt;a href="http://dojotoolkit.com"&gt;dojo.xhrGet&lt;/a&gt; to load the information directly into the browser.&lt;/p&gt;
&lt;p&gt;I'd love to hear your feedback in the comments section below. Let me know 
what you found for your own databases. Were there any issues? How did you deal
with them? &lt;/p&gt;</summary><category term="MySQL"></category><category term="Amazon"></category><category term="S3"></category></entry><entry><title>Tip: Save Money on Amazon - Buy Used Books</title><link href="http://atodorov.org/blog/2013/01/31/tip-save-money-on-amazon-buy-used-books/" rel="alternate"></link><updated>2013-01-31T22:41:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-01-31:blog/2013/01/31/tip-save-money-on-amazon-buy-used-books/</id><summary type="html">&lt;p&gt;I like to buy books, the real ones, printed on paper. This however comes at
a certain price when buying from Amazon. The book price itself is
usually bearable but many times shipping costs to Bulgaria
will double the price. Especially if you are making a single book order.&lt;/p&gt;
&lt;p&gt;To save money I started buying used books when available. For books that are
not so popular I look for items that have been owned by a library.&lt;/p&gt;
&lt;p&gt;This is how I got a hardcover 1984 edition of
&lt;a href="http://www.amazon.com/gp/product/190676820X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=190676820X&amp;linkCode=as2&amp;tag=atodorovorg-20"&gt;The Gentlemen's Clubs of London&lt;/a&gt;&lt;img src="http://www.assoc-amazon.com/e/ir?t=atodorovorg-20&amp;l=as2&amp;o=1&amp;a=190676820X" width="1" height="1" border="0"  style="border:none !important; margin:0px !important;" /&gt;
by Anthony Lejeune for $10. This is my best deal so far.
The book was brand new I dare to say. There was no edge wear, no damaged pages,
with nice and vibrant colors. The second page had the library sign and no other marks.&lt;/p&gt;
&lt;p&gt;Let me know if you had an experience buying used books online? Did you score a great
deal like I did?&lt;/p&gt;</summary><category term="tips"></category><category term="Amazon"></category><category term="books"></category></entry><entry><title>Click Tracking without MailChimp</title><link href="http://atodorov.org/blog/2013/01/31/click-tracking-without-mailchimp/" rel="alternate"></link><updated>2013-01-31T21:23:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-01-31:blog/2013/01/31/click-tracking-without-mailchimp/</id><summary type="html">&lt;p&gt;Here is a standard notification message that users at &lt;a href="http://www.dif.io"&gt;Difio&lt;/a&gt;
receive. It is plain text, no HTML crap, short and URLs are clean and
descriptive. As the project lead developer I wanted to track when people click on
these links and visit the website but also keep existing functionality.&lt;/p&gt;
&lt;p&gt;&lt;img alt="&amp;quot;Email with links&amp;quot;" src="/images/email_w_links.png" title="Email with links" /&gt;&lt;/p&gt;
&lt;h2&gt;Standard approach&lt;/h2&gt;
&lt;p&gt;A pretty common approach when sending huge volumes of email is to use an external
service, such as MailChimp. This is one of many email
marketing services which comes with a lot of features. The most important to me
was analytics and reports.&lt;/p&gt;
&lt;p&gt;The downside is that MailChimp (and I guess others) use HTML formatted emails
extensively. I don't like that and I'm sure my users will not like it as well. 
They are all developers. Not to mention that MailChimp is much more expensive
than &lt;a href="http://aws.amazon.com/ses/"&gt;Amazon SES&lt;/a&gt; which I use currently.
No MailChimp for me!&lt;/p&gt;
&lt;p&gt;Another common approach, used by Feedburner by the way,
is to use shortened URLs which redirect to the original ones and measure clicks
in between. I also didn't like this for two reasons: 1) the shortened URLs look
ugly and they are not at all descriptive and 2) I need to generate them automatically
and maintain all the mappings. Why bother ?&lt;/p&gt;
&lt;h2&gt;How I did it?&lt;/h2&gt;
&lt;p&gt;So I needed something which will do a redirect to a predefined URL, measure how many
redirects were there (essentially clicks on the link) and look nice. The solution is
very simple, if you have not recognized it by now from the picture above. &lt;/p&gt;
&lt;p&gt;I opted for a custom redirect engine, which will add tracking information to the
destination URL so I can track it in Google Analytics.&lt;/p&gt;
&lt;p&gt;Previous URLs were of the form &lt;code&gt;http://www.dif.io/updates/haml-3.1.2/haml-3.2.0.rc.3/11765/&lt;/code&gt;.
I've added the humble &lt;code&gt;/daily/?&lt;/code&gt; prefix before the URL path so it becomes
&lt;code&gt;http://www.dif.io/daily/?/updates/haml-3.1.2/haml-3.2.0.rc.3/11765/&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Now &lt;code&gt;/updates/haml-3.1.2/haml-3.2.0.rc.3/11765/&lt;/code&gt; becomes a query string parameter which
the &lt;code&gt;/daily/index.html&lt;/code&gt; page uses as its destination. Before doing the redirect
a script adds tracking parameters so that Google Analytics will properly
report this visit. Here is the code: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nt"&gt;&amp;lt;html&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;head&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;script &lt;/span&gt;&lt;span class="na"&gt;type=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;text/javascript&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;uri&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;window&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;location&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;toString&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;question&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;uri&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;indexOf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;?&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;param&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;uri&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;substring&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;question&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;uri&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;length&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;question&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nb"&gt;window&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;location&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;href&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;param&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;?utm_source=email&amp;amp;utm_medium=email&amp;amp;utm_campaign=Daily_Notification&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/head&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;body&amp;gt;&amp;lt;/body&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/html&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Previously Google Analytics was reporting these visits as direct hits while now it lists them under
campaigns like so:&lt;/p&gt;
&lt;p&gt;&lt;img alt="&amp;quot;Difio Analytics&amp;quot;" src="/images/analytics_difio_campaigns.png" title="Difio Analytics" /&gt;&lt;/p&gt;
&lt;p&gt;Because all visitors of &lt;a href="http://www.dif.io"&gt;Difio&lt;/a&gt; use JavaScript enabled browsers
I combined this approach with another one, to
&lt;a href="/blog/2013/01/28/remove-query-string-with-javascript-and-html5/"&gt;remove query string with JavaScript&lt;/a&gt;
and present clean URLs to the visitor.&lt;/p&gt;
&lt;h2&gt;Why JavaScript?&lt;/h2&gt;
&lt;p&gt;You may be asking why the hell I am using JavaScript and not Apache's wonderful mod_rewrite module? 
This is because the destination URLs are hosted in &lt;a href="http://aws.amazon.com/s3/"&gt;Amazon S3&lt;/a&gt; and I'm
planning to integrate with &lt;a href="http://aws.amazon.com/cloudfront/"&gt;Amazon CloudFront&lt;/a&gt;. Both of them
don't support .htaccess rules nor anything else similar to mod_rewrite.&lt;/p&gt;
&lt;p&gt;As always I'd love to hear your thoughts and feedback. Please use the comment form below.&lt;/p&gt;</summary><category term="JavaScript"></category><category term="Amazon"></category><category term="S3"></category><category term="SES"></category><category term="cloud"></category></entry><entry><title>Cross-domain AJAX Served From CDN</title><link href="http://atodorov.org/blog/2012/05/19/cross-domain-ajax-served-from-cdn/" rel="alternate"></link><updated>2012-05-19T16:58:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2012-05-19:blog/2012/05/19/cross-domain-ajax-served-from-cdn/</id><summary type="html">&lt;p&gt;This week Amazon &lt;a href="http://aws.typepad.com/aws/2012/05/amazon-cloudfront-support-for-dynamic-content.html"&gt;announced&lt;/a&gt;
support for dynamic content in their CDN solution &lt;a href="http://aws.amazon.com/cloudfront/"&gt;&lt;em&gt;Amazon CloudFront&lt;/em&gt;&lt;/a&gt;.
The announce coincided with my efforts to migrate more pieces of &lt;em&gt;Difio&lt;/em&gt;'s &lt;a href="http://www.dif.io"&gt;website&lt;/a&gt; to &lt;em&gt;CloudFront&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In this article I will not talk about hosting static files on CDN. This is easy and I've already written
about it &lt;a href="/blog/2012/04/17/using-openshift-as-amazon-cloudfront-origin-server/"&gt;here&lt;/a&gt;. I will show how to
cache AJAX(JSONP actually) responses and serve them directly from &lt;em&gt;Amazon CloudFront&lt;/em&gt;.&lt;/p&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;For those of you who may not be familiar (are there any) CDN stands for
&lt;a href="https://en.wikipedia.org/wiki/Content_delivery_network"&gt;Content Delivery Network&lt;/a&gt;. In short
this employs numerous servers with identical content. The requests from the browser are served
from the location which gives best performance for the user. This is used by all major websites
to speed-up static content like images, video, CSS and JavaScript files.&lt;/p&gt;
&lt;p&gt;AJAX means &lt;a href="https://en.wikipedia.org/wiki/Ajax_%28programming%29"&gt;Asynchronous JavaScript and XML&lt;/a&gt;.
This is what Google uses to create dynamic user interface which doesn't require to reload the page.&lt;/p&gt;
&lt;h2&gt;Architecture&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Difio&lt;/em&gt; has two web interfaces. The primary one is a static HTML website
which employs JavaScript for the dynamic areas. It is hosted on the dif.io domain.
The other one is powered by Django and provides the same interface plus the
&lt;a href="https://difio-otb.rhcloud.com/dashboard/"&gt;applications dashboard&lt;/a&gt; and several API functions
which don't have a visible user interface. This is under the *.rhcloud.com domain b/c it is hosted on
&lt;a href="http://openshift.redhat.com"&gt;&lt;em&gt;OpenShift&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The present state of the website is the result of rapid development using conventional methods - 
HTML templates and server-side processing. This is migrating to modern web technology like static HTML
and JavaScript while the server side will remain pure API service.&lt;/p&gt;
&lt;p&gt;For this migration to happen I need the HTML pages at dif.io to execute JavaScript and load information
which comes from the rhcloud.com domain. Unfortunately this is not easily doable with AJAX because
of the &lt;a href="https://en.wikipedia.org/wiki/Same_origin_policy"&gt;Same origin policy&lt;/a&gt; in browsers.&lt;/p&gt;
&lt;p&gt;I'm using the &lt;a href="http://dojotoolkit.org/"&gt;&lt;em&gt;Dojo Toolkit&lt;/em&gt;&lt;/a&gt; JavaScript framework which has a solution.
It's called &lt;a href="https://en.wikipedia.org/wiki/JSONP"&gt;JSONP&lt;/a&gt;. Here's how it works:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;     dif.io ------ JSONP request --&amp;gt; abc.rhcloud.com --v
        ^                                              |
        |                                              |
    JavaScript processing                              |
        |                                              |
        +------------------ JSONP response ------------+
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is pretty standard configuration for a web service.&lt;/p&gt;
&lt;h2&gt;Going to the clouds&lt;/h2&gt;
&lt;p&gt;The way &lt;em&gt;Dojo&lt;/em&gt; implements JSONP is through the
&lt;a href="http://dojotoolkit.org/reference-guide/1.7/dojo/io/script.html"&gt;dojo.io.script&lt;/a&gt; module.
It works by appending a query string parameter of the form &lt;em&gt;?callback=funcName&lt;/em&gt; which the server uses
to generate the JSONP response. This callback name is dynamically generated by &lt;em&gt;Dojo&lt;/em&gt; based on the order
in which your call to &lt;em&gt;dojo.io.script&lt;/em&gt; is executed.&lt;/p&gt;
&lt;p&gt;Until recently &lt;em&gt;Amazon CloudFront&lt;/em&gt; ignored all query string parameters when requesting the content from
the origin server. Without the query string it was not possible to generate the JSONP response.
Luckily Amazon resolved the issue only one day after I asked about it on their forums.&lt;/p&gt;
&lt;p&gt;Now &lt;em&gt;Amazon CloudFront&lt;/em&gt; will use the URL path and the query string parameters to identify the objects in cache.
To enable this edit the CloudFront distribution &lt;em&gt;behavior(s)&lt;/em&gt; and set &lt;em&gt;Forward Query Strings&lt;/em&gt; to Yes.&lt;/p&gt;
&lt;p&gt;When a visitor of the website requests the data &lt;em&gt;Amazon CloudFront&lt;/em&gt; will use exactly the same url path and query strings
to fetch the content from the origin server. All that I had to do is switch the domain of the JSONP service
to point to the cloudfront.net domain. It became like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;                                                        | Everything on this side is handled by Amazon.
                                                        | No code required!
                                                        |
     dif.io ------ JSONP request --&amp;gt; xyz.cloudfront.net -- JSONP request if cache miss --&amp;gt; abc.rhcloud.com --v
        ^                              |                ^                                                    |
        |                              |                |                                                    |
    JavaScript processing              |                +---------- JSONP response --------------------------+
        |                              |
        +---- cached JSONP response ---+
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As you can see the website structure and code didn't change at all. All that changed was a single domain name.&lt;/p&gt;
&lt;h2&gt;Controlling the cache&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Amazon CloudFront&lt;/em&gt; will keep the contents in cache based on the origin headers if present or the manual configuration
from the AWS Console. To work around frequent requests to the origin server it is considered best practice to set the
Expires header to a value far in the future, like 1 year.
However if the content changes you need some way to tell &lt;em&gt;CloudFront&lt;/em&gt; about it. The most commonly used method is through
using different URLs to access the same content. This will cause &lt;em&gt;CloudFront&lt;/em&gt; to cache the content under the new location
while keeping the old content until it expires.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Dojo&lt;/em&gt; makes this very easy:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;dojo/io/script&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
    &lt;span class="kd"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;script&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="nx"&gt;script&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;get&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;
                &lt;span class="nx"&gt;url&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;https://xyz.cloudfront.net/api/json/updates/1234&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="nx"&gt;callbackParamName&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;callback&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="nx"&gt;content&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;t&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;timeStamp&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
                &lt;span class="nx"&gt;load&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;jsonData&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
                    &lt;span class="p"&gt;....&lt;/span&gt;
                &lt;span class="p"&gt;},&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;em&gt;content&lt;/em&gt; property allows additional key/value pairs to be sent in the query string. The
&lt;em&gt;timeStamp&lt;/em&gt; parameter serves only to control &lt;em&gt;Amazon CloudFront&lt;/em&gt; cache. It's not processed server side.&lt;/p&gt;
&lt;p&gt;On the server-side we have:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Cache-Control&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;max-age=31536000&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Expires&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;now&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;timedelta&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seconds&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;31536000&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strftime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;%a, &lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s"&gt; %b %Y %H:%M:%S GMT&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Benefits&lt;/h2&gt;
&lt;p&gt;There were two immediate benefits:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reduced page load time. Combined with serving static files from CDN this greatly improves the user experience;&lt;/li&gt;
&lt;li&gt;Reduced server load. Content is requested only once if it is missing from the cache and then served from CloudFront.
The server isn't so busy serving content so it can be used to do more computations or simply reduce the bill.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The presented method works well for &lt;em&gt;Difio&lt;/em&gt; because of two things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The content which &lt;em&gt;Difio&lt;/em&gt; serves usually doesn't change at all once made public. In rare occasions, for example an error
has been published, we have to regenerate new content and publish it under the same URL.&lt;/li&gt;
&lt;li&gt;Before content is made public it is inspected for errors and this also preseeds the cache.&lt;/li&gt;
&lt;/ul&gt;</summary><category term="Amazon"></category><category term="CloudFront"></category><category term="cloud"></category></entry><entry><title>Using OpenShift as Amazon CloudFront Origin Server</title><link href="http://atodorov.org/blog/2012/04/17/using-openshift-as-amazon-cloudfront-origin-server/" rel="alternate"></link><updated>2012-04-17T17:30:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2012-04-17:blog/2012/04/17/using-openshift-as-amazon-cloudfront-origin-server/</id><summary type="html">&lt;p&gt;It's been several months after the start of &lt;a href="http://www.dif.io"&gt;&lt;em&gt;Difio&lt;/em&gt;&lt;/a&gt; and I started
migrating various parts of the platform to CDN. The first to go are static files like
CSS, JavaScript, images and such. In this article I will show you how to get started with 
&lt;em&gt;Amazon CloudFront&lt;/em&gt; and &lt;em&gt;OpenShift&lt;/em&gt;. It is very easy once you understand how it works.&lt;/p&gt;
&lt;h2&gt;Why CloudFront and OpenShift&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Amazon CloudFront&lt;/em&gt; is cheap and easy to setup with virtually no maintenance.
The most important feature is that it can fetch content from any public website.
Integrating it together with &lt;em&gt;OpenShift&lt;/em&gt; gives some nice benefits:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;All static assets are managed with Git and stored in the same place where the application
code and HTML is - easy to develop and deploy;&lt;/li&gt;
&lt;li&gt;No need for external service to host the static files;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;CloudFront&lt;/em&gt; will be serving the files so network load on &lt;em&gt;OpenShift&lt;/em&gt; is minimal;&lt;/li&gt;
&lt;li&gt;Easy to manage versioned URLs because HTML and static assets are in the same repo - more on this later;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Object expiration&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;CloudFront&lt;/em&gt; will cache your objects for a certain period and then expire them. Frequently
used objects are expired less often. Depending on the content you may want to update the cache
more or less frequently. In my case CSS and JavaScript files change rarely so I wanted to tell
CloudFront to not expire the files quickly. I did this by telling &lt;em&gt;Apache&lt;/em&gt; to send a custom value for
the Expires header.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;    $ curl http://d71ktrt2emu2j.cloudfront.net/static/v1/css/style.css -D headers.txt
    $ cat headers.txt 
    HTTP/1.0 200 OK
    Date: Mon, 16 Apr 2012 19:02:16 GMT
    Server: Apache/2.2.15 (Red Hat)
    Last-Modified: Mon, 16 Apr 2012 19:00:33 GMT
    ETag: &amp;quot;120577-1b2d-4bdd06fc6f640&amp;quot;
    Accept-Ranges: bytes
    Content-Length: 6957
    Cache-Control: max-age=31536000
    Expires: Tue, 16 Apr 2013 19:02:16 GMT
    Content-Type: text/css
    Strict-Transport-Security: max-age=15768000, includeSubDomains
    Age: 73090
    X-Cache: Hit from cloudfront
    X-Amz-Cf-Id: X558vcEOsQkVQn5V9fbrWNTdo543v8VStxdb7LXIcUWAIbLKuIvp-w==,e8Dipk5FSNej3e0Y7c5ro-9mmn7OK8kWfbaRGwi1ww8ihwVzSab24A==
    Via: 1.0 d6343f267c91f2f0e78ef0a7d0b7921d.cloudfront.net (CloudFront)
    Connection: close
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;All headers before Strict-Transport-Security come from the origin server.&lt;/p&gt;
&lt;h2&gt;Versioning&lt;/h2&gt;
&lt;p&gt;Sometimes however you need to update the files and force &lt;em&gt;CloudFront&lt;/em&gt; to update the content. 
The recommended way to do this is to use URL versioning and update the path to the files
which changed. This will force &lt;em&gt;CloudFront&lt;/em&gt; to cache and serve the content under the new path
while keeping the old content available until it expires. This way your visitors will not be
viewing your site with the new CSS and old JavaScript. &lt;/p&gt;
&lt;p&gt;There are many ways to do this and there are some nice frameworks as well. For Python there is &lt;em&gt;webassets&lt;/em&gt;.
I don't have many static files so I opted for no additional dependencies. Instead I will be updating the
versions by hand.&lt;/p&gt;
&lt;p&gt;What comes to mind is using &lt;em&gt;mod_rewrite&lt;/em&gt; to redirect the versioned URLs back to non versioned ones.
However there's a catch. If you do this &lt;em&gt;CloudFront&lt;/em&gt; will cache the redirect itself, not the content.
The next time visitors hit &lt;em&gt;CloudFront&lt;/em&gt; they will receive the cached redirect and follow it back to your
origin server, which is defeating the purpose of having CDN.&lt;/p&gt;
&lt;p&gt;To do it properly you have to rewrite the URLs but still return a 200 response code and the
content which needs to be cached. This is done with &lt;em&gt;mod_proxy&lt;/em&gt;: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;    RewriteEngine on
    RewriteRule ^VERSION-(\d+)/(.*)$ http://%{ENV:OPENSHIFT_INTERNAL_IP}:%{ENV:OPENSHIFT_INTERNAL_PORT}/static/$2 [P,L]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This .htaccess trick doesn't work on &lt;em&gt;OpenShift&lt;/em&gt; though. &lt;em&gt;mod_proxy&lt;/em&gt; is not enabled at the moment.
See &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=812389"&gt;bug 812389&lt;/a&gt; for more info.&lt;/p&gt;
&lt;p&gt;Luckily I was able to use symlinks to point to the content. Here's how it looks:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="x"&gt;    $ pwd&lt;/span&gt;
&lt;span class="x"&gt;    /home/atodorov/difio/wsgi/static&lt;/span&gt;
&lt;span class="x"&gt;    &lt;/span&gt;
&lt;span class="x"&gt;    $ cat .htaccess&lt;/span&gt;
&lt;span class="x"&gt;    ExpiresActive On&lt;/span&gt;
&lt;span class="x"&gt;    ExpiresDefault &amp;quot;access plus 1 year&amp;quot;&lt;/span&gt;
&lt;span class="x"&gt;    &lt;/span&gt;
&lt;span class="x"&gt;    $ ls -l&lt;/span&gt;
&lt;span class="x"&gt;    drwxrwxr-x. 6 atodorov atodorov 4096 16 Apr 21,31 o&lt;/span&gt;
&lt;span class="x"&gt;    lrwxrwxrwx. 1 atodorov atodorov    1 16 Apr 21,47 v1 -&amp;gt; o&lt;/span&gt;
&lt;span class="x"&gt;    &lt;/span&gt;
&lt;span class="x"&gt;    settings.py:&lt;/span&gt;
&lt;span class="x"&gt;    STATIC_URL = &amp;#39;//d71ktrt2emu2j.cloudfront.net/static/v1/&amp;#39;&lt;/span&gt;
&lt;span class="x"&gt;    &lt;/span&gt;
&lt;span class="x"&gt;    HTML template:&lt;/span&gt;
&lt;span class="x"&gt;    &amp;lt;link type=&amp;quot;text/css&amp;quot; rel=&amp;quot;stylesheet&amp;quot; media=&amp;quot;screen&amp;quot; href=&amp;quot;&lt;/span&gt;&lt;span class="cp"&gt;{{&lt;/span&gt; &lt;span class="nv"&gt;STATIC_URL&lt;/span&gt; &lt;span class="cp"&gt;}}&lt;/span&gt;&lt;span class="x"&gt;css/style.css&amp;quot; /&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;How to implement it&lt;/h2&gt;
&lt;p&gt;First you need to split all CSS and JavaScript from your HTML if you haven't done so already. &lt;/p&gt;
&lt;p&gt;Then place everything under your git repo so that &lt;em&gt;OpenShift&lt;/em&gt; will serve the files. For Python applications
place the files under wsgi/static/ directory in your git repo.&lt;/p&gt;
&lt;p&gt;Point all of your HTML templates to the static location on &lt;em&gt;OpenShift&lt;/em&gt; and test if everything works as expected. 
This is best done if you're using some sort of template language and store the location
in a single variable which you can change later.
&lt;em&gt;Difio&lt;/em&gt; uses &lt;em&gt;Django&lt;/em&gt; and the &lt;em&gt;STATIC_URL&lt;/em&gt; variable of course.&lt;/p&gt;
&lt;p&gt;Create your &lt;em&gt;CloudFront&lt;/em&gt; distribution - don't use &lt;em&gt;Amazon S3&lt;/em&gt;, instead configure a custom origin server. Write down
your &lt;em&gt;CloudFront&lt;/em&gt; URL. It will be something like &lt;strong&gt;1234xyz.cludfront.net&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Every time a request hits &lt;em&gt;CloudFront&lt;/em&gt; it will check if the object is present in the cache. If not present
&lt;em&gt;CloudFront&lt;/em&gt; will fetch the object from the origin server and populate the cache. Then the object is sent
to the user.&lt;/p&gt;
&lt;p&gt;Update your templates to point to the new cloudfront.net URL and redeploy your website!&lt;/p&gt;</summary><category term="OpenShift"></category><category term="Amazon"></category><category term="cloud"></category></entry></feed>