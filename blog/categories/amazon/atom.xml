<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Amazon | atodorov.org - you can logoff, but you can never leave]]></title>
  <link href="http://atodorov.org/blog/categories/amazon/atom.xml" rel="self"/>
  <link href="http://atodorov.org/"/>
  <updated>2015-11-24T13:48:05+02:00</updated>
  <id>http://atodorov.org/</id>
  <author>
    <name><![CDATA[Alexander Todorov]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Reducing AWS Cloud Costs - Real Money Example]]></title>
    <link href="http://atodorov.org/blog/2014/03/07/reducing-aws-cloud-costs-real-money-example/"/>
    <updated>2014-03-07T17:14:00+02:00</updated>
    <id>http://atodorov.org/blog/2014/03/07/reducing-aws-cloud-costs-real-money-example</id>
    <content type="html"><![CDATA[<p><a href="http://aws.amazon.com/ebs/pricing/effective-february-2014/">Last month</a> Amazon
reduced by 50% prices for EBS storage. This, combined with
<a href="/blog/2014/02/07/aws-tip-shrinking-ebs-root-volume-size/">shrinking EBS root volume size</a> and
<a href="/blog/2014/02/10/moving-tmp-from-ebs-to-instance-storage/">moving /tmp to instance storage</a>
allowed me to reduce EBS related costs behind <a href="http://www.dif.io">Difio</a> by around 50%.
Following are the real figures from my AWS Bill.</p>

<p>EBS costs for Difio were gradually rising up with every new node added to the cluster and
increased package processing (resulting in more I/O):</p>

<ul>
<li>November 2013 - $7.38</li>
<li>December 2013 - $10.55</li>
<li>January 2014 - $11.97</li>
</ul>


<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>January 2014 </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>EBS
</span><span class='line'>$0.095 per GB-Month of snapshot data stored     9.052 GB-Mo     $0.86
</span><span class='line'>$0.10  per GB-month of provisioned storage      101.656 GB-Mo  $10.17
</span><span class='line'>$0.10  per 1 million I/O requests               9,405,243 IOs   $0.94&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;pre>&lt;code>                                                    Total: $11.97
</span><span class='line'>&lt;/code>&lt;/pre>
</span><span class='line'>
</span><span class='line'>&lt;p></span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>In February there was one new system added to process additional requests
(cluster nodes run as spot instances) and an increased number of temporary
instances (although I haven't counted them) while I was restructuring AMI
internals to accommodate the <a href="https://github.com/difio/difio">open source</a>
version of Difio. My assumption (based on historical data) is this would
have driven the costs up in the region of $15 per month only for EBS.</p>

<p>After implementing the stated minimal improvements and having Amazon reduced the prices by
half the bill looks like this:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>February 2014 </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>EBS
</span><span class='line'>$0.095 per GB-Month of snapshot data stored     8.668 GB-Mo     $0.82
</span><span class='line'>$0.05  per GB-month of provisioned storage      58.012 GB-Mo    $2.90
</span><span class='line'>$0.05  per 1 million I/O requests               5,704,482 IOs   $0.29&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;pre>&lt;code>                                                    Total:  $4.01
</span><span class='line'>&lt;/code>&lt;/pre>
</span><span class='line'>
</span><span class='line'>&lt;p></span></code></pre></td></tr></table></div></figure></notextile></div></p>

<h2>Explanation</h2>

<p><em>Snapshot data stored</em> is the volume of snapshots (AMIs, backups, etc) which
I have. This is fairly constant.</p>

<p><em>Provisioned storage</em> is the volume of EBS storage provisioned for running
instances (e.g. root file system, data partitions, etc.). This was reduced
mainly because of shrinking the root volumes. (Previously I've used larger
root volumes for a bigger /tmp).</p>

<p><em>I/O requests</em> is the number of I/O requests associated with your EBS volumes.
As far as I understand Amazon doesn't charge for I/O related to ephemeral storage.
Moving /tmp from EBS to instance storage is the reason this was reduced roughly by half.</p>

<h2>Where To Next</h2>

<p>I've reduced the root volumes back to the 8GB defaults but this has still room for
improvement b/c the AMI is quite minimal. This will bring the largest improvements.
Another thing is the still relatively high I/O rate that touches EBS volumes.
I haven't investigated where this comes from though.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Moving /tmp from EBS to Instance Storage]]></title>
    <link href="http://atodorov.org/blog/2014/02/10/moving-tmp-from-ebs-to-instance-storage/"/>
    <updated>2014-02-10T13:48:00+02:00</updated>
    <id>http://atodorov.org/blog/2014/02/10/moving-tmp-from-ebs-to-instance-storage</id>
    <content type="html"><![CDATA[<p>I've seen a fair amount of stories about moving away from Amazon's EBS volumes
to ephemeral instance storage. I've decided to give it a try starting with <code>/tmp</code>
directory where <a href="http://www.dif.io">Difio</a> operates.</p>

<p>It should be noted that although instance storage may be available for some instance
types it may not be attached by default. Use this command to check:
<div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>curl http://169.254.169.254/latest/meta-data/block-device-mapping/
</span><span class='line'>ami
</span><span class='line'>root
</span><span class='line'>swap
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>In the above example there is no instance storage present.</p>

<p>You can attach one either when launching the EC2 instance or when creating a customized AMI
(instance storage devices are pre-defined in the AMI). When creating an AMI you can attach more ephemeral devices
but they will not available when instance is launched. The maximum number of available
instance storage devices can be found in the
<a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#StorageOnInstanceTypes">docs</a>.
That is to say if you have an AMI which defines 2 ephemeral devices and launch a
standard m1.small instance there will be only one ephemeral device present.</p>

<p>Also note that for M3 instances, you must specify instance store volumes in the
block device mapping for the instance. When you launch an M3 instance, Amazon ignores
any instance store volumes specified in the block device mapping for the AMI.</p>

<p>As far as I can see the AWS Console doesn't indicate if instance storage is attached
or not. For instance with 1 ephemeral volume:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>curl http://169.254.169.254/latest/meta-data/block-device-mapping/
</span><span class='line'>ami
</span><span class='line'>ephemeral0
</span><span class='line'>root
</span><span class='line'>swap&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;<span class="nv">$ </span>curl http://169.254.169.254/latest/meta-data/block-device-mapping/ephemeral0
</span><span class='line'>sdb
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Ephemeral devices can be mounted in <code>/media/ephemeralX/</code>, but not all volumes.
I've found that usually only <code>ephemeral0</code> is mounted automatically.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>curl http://169.254.169.254/latest/meta-data/block-device-mapping/
</span><span class='line'>ami
</span><span class='line'>ephemeral0
</span><span class='line'>ephemeral1
</span><span class='line'>root&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;<span class="nv">$ </span>ls -l /media/
</span><span class='line'>drwxr-xr-x 3 root root 4096 21 ное  2009 ephemeral0
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>For Difio I have an init.d script which executes when the system
boots. To enable <code>/tmp</code> on ephemeral storage I just added the following snippet:
<div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nb">echo</span> <span class="s2">$&quot;Mounting /tmp on ephemeral storage:&quot;</span>
</span><span class='line'><span class="k">for </span>ef in &lt;code&gt;curl http://169.254.169.254/latest/meta-data/block-device-mapping/ 2&amp;gt;/dev/null | grep ephemeral&lt;/code&gt;; <span class="k">do</span>&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;disk<span class="o">=</span><span class="sb">`</span>curl http://169.254.169.254/latest/meta-data/block-device-mapping/<span class="nv">$ef</span> 2&amp;gt;/dev/null<span class="sb">`</span>
</span><span class='line'><span class="nb">echo</span> <span class="s2">$&quot;Unmounting /dev/$disk&quot;</span>
</span><span class='line'>umount /dev/<span class="nv">$disk</span>
</span><span class='line'>
</span><span class='line'><span class="nb">echo</span> <span class="s2">$&quot;mkfs /dev/$disk&quot;</span>
</span><span class='line'>mkfs.ext4 -q /dev/<span class="nv">$disk</span>
</span><span class='line'>
</span><span class='line'><span class="nb">echo</span> <span class="s2">$&quot;Mounting /dev/$disk&quot;</span>
</span><span class='line'>mount -t ext4 /dev/<span class="nv">$disk</span> /tmp &amp;amp;&amp;amp; chmod 1777 /tmp &amp;amp;&amp;amp; success <span class="o">||</span> failure
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;done
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p><strong>NB:</strong> success and failure are from <code>/etc/rc.d/init.d/functions</code>.
If you are using LVM or RAID you need to reconstruct your block devices
accordingly!</p>

<p>If everything goes right I should be able to reduce my AWS costs by saving on
provisioned storage and I/O requests. I'll keep you posted on this after a month or two.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS Tip: Shrinking EBS Root Volume Size]]></title>
    <link href="http://atodorov.org/blog/2014/02/07/aws-tip-shrinking-ebs-root-volume-size/"/>
    <updated>2014-02-07T00:23:00+02:00</updated>
    <id>http://atodorov.org/blog/2014/02/07/aws-tip-shrinking-ebs-root-volume-size</id>
    <content type="html"><![CDATA[<p>Amazon's Elastic Block Store volumes are easy to use and expand but notoriously
hard to shrink once their size has grown. Here is my tip for shrinking EBS size
and saving some money from over-provisioned storage. I'm assuming that you want to
shrink the root volume which is on EBS.</p>

<ul>
<li>Write down the block device name for the root volume (/dev/sda1) - <em>from AWS console:
Instances; Select instance; Look at Details tab; See Root device or Block devices</em>;</li>
<li>Write down the availability zone of your instance - <em>from AWS console: Instances;
column Availability Zone</em>;</li>
<li>Stop instance;</li>
<li>Create snapshot of the root volume;</li>
<li>From the snapshot, create a second volume, in the <strong>same availability zone</strong> as
your instance (you will have to attach it later). This will be your pristine source;</li>
<li>Create new empty EBS volume (not based on a snapshot), with smaller size,
in the same availability zone - <em>from AWS console: Volumes; Create Volume;
Snapshot == No Snapshot</em>; <strong>IMPORTANT</strong> - size should be large enough to hold
all the files from the source file system (try <code>df -h</code> on the source first);</li>
<li>Attach both volumes to instance while taking note of the block devices names
you assign for them in the AWS console;</li>
</ul>


<p>For example: In my case <code>/dev/sdc1</code> is the source snapshot and <code>/dev/sdd1</code> is the
empty target.</p>

<ul>
<li>Start instance;</li>
<li>Optionally check the source file system with <code>e2fsck -f /dev/sdc1</code>;</li>
<li>Create a file system for the empty volume - <code>mkfs.ext4 /dev/sdd1</code>;</li>
<li>Mount volumes at <code>/source</code> and <code>/target</code> respectively;</li>
<li>Now sync the files: <code>rsync -aHAXxSP /source/ /target</code>. <strong>Note the missing slash (/)
after <code>/target</code></strong>. If you add it you will end up with files inside <code>/target/source/</code>
which you don't want;</li>
<li>Quickly verify the new directory structure with <code>ls -l /target</code>;</li>
<li>Unmount <code>/target</code>;</li>
<li>Optionally check the new file system for consistency <code>e2fsck -f /dev/sdd1</code>;</li>
<li><strong>IMPORTANT</strong> - check how <code>/boot/grub/grub.conf</code> specifies the root volume -
by UUID, by LABEL, by device name, etc. You will have to duplicate the same for the
new smaller volume or update <code>/target/boot/grub/grub.conf</code> to match the new volume.
Check <code>/target/etc/fstab</code> as well!</li>
</ul>


<p>In my case I had to <code>e2label /dev/sdd1 /</code> because both <code>grub.conf</code> and <code>fstab</code> were
using the device label.</p>

<ul>
<li>Shutdown the instance;</li>
<li>Detach all volumes;</li>
<li><strong>IMPORTANT</strong> - attach the new smaller volume to the instance using the same block device
name from the first step (e.g. <code>/dev/sda1</code>);</li>
<li>Start the instance and verify it is working correctly;</li>
<li>DELETE auxiliary volumes and snapshots so they don't take space and accumulate costs!</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Idempotent Django Email Sender with Amazon SQS and Memcache]]></title>
    <link href="http://atodorov.org/blog/2013/12/11/idempotent-django-email-sender-with-amazon-sqs-and-memcache/"/>
    <updated>2013-12-11T23:29:00+02:00</updated>
    <id>http://atodorov.org/blog/2013/12/11/idempotent-django-email-sender-with-amazon-sqs-and-memcache</id>
    <content type="html"><![CDATA[<p>Recently I wrote about my problem with
<a href="/blog/2013/12/06/duplicate-amazon-sqs-messages-cause-multiple-emails/">duplicate Amazon SQS messages causing multiple emails</a>
for <a href="http://www.dif.io">Difio</a>. After considering several options and
feedback from
<a href="https://twitter.com/atodorov_/status/409429840820199424">@Answers4AWS</a>
I wrote a small decorator to fix this.</p>

<p>It uses the cache backend to prevent the task from executing twice
during the specified time frame. The code is available at
<a href="https://djangosnippets.org/snippets/3010/">https://djangosnippets.org/snippets/3010/</a>.</p>

<p>As stated on Twitter you should use Memcache (or ElastiCache) for this.
If using Amazon S3 with my
<a href="https://github.com/atodorov/django-s3-cache">django-s3-cache</a> don't use the
<code>us-east-1</code> region because it is eventually consistent.</p>

<p>The solution is fast and simple on the development side and uses my existing
cache infrastructure so it doesn't cost anything more!</p>

<p>There is still a race condition between marking the message as processed
and the second check but nevertheless this should minimize the possibility of
receiving duplicate emails to an accepted level. Only time will tell though!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Duplicate Amazon SQS Messages Cause Multiple Emails]]></title>
    <link href="http://atodorov.org/blog/2013/12/06/duplicate-amazon-sqs-messages-cause-multiple-emails/"/>
    <updated>2013-12-06T22:47:00+02:00</updated>
    <id>http://atodorov.org/blog/2013/12/06/duplicate-amazon-sqs-messages-cause-multiple-emails</id>
    <content type="html"><![CDATA[<p>Beware if using Amazon Simple Queue Service to send email messages!
Sometime SQS messages are duplicated which results in multiple copies of
the messages being sent. This happened today at <a href="http://www.dif.io">Difio</a>
and is really annoying to users. In this post I will explain why there is no easy
way of fixing it.</p>

<p><blockquote><p>Q: Can a deleted message be received again?</p></p><p><p>Yes, under rare circumstances you might receive a previously deleted message again.<br/>This can occur in the rare situation in which a DeleteMessage operation doesn't<br/>delete all copies of a message because one of the servers in the distributed<br/>Amazon SQS system isn't available at the time of the deletion. That message copy<br/>can then be delivered again. You should design your application so that no errors<br/>or inconsistencies occur if you receive a deleted message again.</p><footer><strong>Amazon FAQ</strong></footer></blockquote></p>

<p>In my case the cron scheduler logs say:</p>

<pre><code>&gt;&gt;&gt; &lt;AsyncResult: a9e5a73a-4d4a-4995-a91c-90295e27100a&gt;
</code></pre>

<p>While on the worker nodes the logs say:</p>

<pre><code>[2013-12-06 10:13:06,229: INFO/MainProcess] Got task from broker: tasks.cron_monthly_email_reminder[a9e5a73a-4d4a-4995-a91c-90295e27100a]
[2013-12-06 10:18:09,456: INFO/MainProcess] Got task from broker: tasks.cron_monthly_email_reminder[a9e5a73a-4d4a-4995-a91c-90295e27100a]
</code></pre>

<p>This clearly shows the same message (see the UUID) has been processed twice!
This resulted in hundreds of duplicate emails :(.</p>

<h2>Why This Is Hard To Fix</h2>

<p>There are two basic approaches to solve this issue:</p>

<ul>
<li>Check some log files or database for previous record of the message having
been processed;</li>
<li>Use idempotent operations that if you process the message again, you
get the same results, and that those results don't create duplicate files/records.</li>
</ul>


<p>The problem with checking for duplicate messages is:</p>

<ul>
<li>There is a race condition between marking the message as processed and the
second check;</li>
<li>You need to use some sort of locking mechanism to safe-guard against the race condition;</li>
<li>In the event of an eventual consistency of the log/DB you can't guarantee that
the previous attempt will show up and so can't guarantee that you won't process
the message twice.</li>
</ul>


<p>All of the above don't seem to work well for distributed applications not to mention
Difio processes millions of messages per month, per node and the logs are quite big.</p>

<p>The second option is to have control of the Message-Id or some other email header
so that the second message will be discarded either at the server (Amazon SES in my case)
or at the receiving MUA. I like this better but I don't think it is technically possible
with the current environment. Need to check though.</p>

<p>I've asked AWS support to look into
<a href="https://forums.aws.amazon.com/thread.jspa?threadID=140782">this thread</a> and hopefully
they will have some more hints. If you have any other ideas please post in the comments!
Thanks!</p>
]]></content>
  </entry>
  
</feed>
