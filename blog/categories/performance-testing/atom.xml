<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: performance testing | atodorov.org]]></title>
  <link href="http://atodorov.org/blog/categories/performance-testing/atom.xml" rel="self"/>
  <link href="http://atodorov.org/"/>
  <updated>2013-05-27T21:44:33+03:00</updated>
  <id>http://atodorov.org/</id>
  <author>
    <name><![CDATA[Alexander Todorov]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Performance Test: Amazon EBS vs. Instance Storage, Pt.1]]></title>
    <link href="http://atodorov.org/blog/2013/02/26/performance-test-amazon-ebs-vs-instance-storage-pt1/"/>
    <updated>2013-02-26T23:02:00+02:00</updated>
    <id>http://atodorov.org/blog/2013/02/26/performance-test-amazon-ebs-vs-instance-storage-pt1</id>
    <content type="html"><![CDATA[<p>I'm exploring the possibility to speed-up my cloud database so I've run some
basic tests against storage options available to Amazon EC2 instances.
The instance was <a href="http://aws.amazon.com/ec2/instance-types/">m1.large</a>
with High I/O performance and two additional disks with the same size:</p>

<ul>
<li>/dev/xvdb - type EBS</li>
<li>/dev/xvdc - type instance storage</li>
</ul>


<p>Both are Xen para-virtual disks. The difference is that EBS is persistent
across reboots while instance storage is ephemeral.</p>

<h2>hdparm</h2>

<p>For a quick test I used <code>hdparm</code>. The manual says:</p>

<pre><code>-T  Perform timings of cache reads for benchmark and comparison purposes.
    This displays the speed of reading directly from the Linux buffer cache
    without disk access. This measurement is essentially an indication of
    the throughput of the processor, cache, and memory of the system under test.

-t  Perform timings of device reads for benchmark and comparison purposes.
    This displays the speed of reading through the buffer cache to the disk
    without any prior caching of data. This measurement is an indication of how
    fast the drive can sustain sequential data reads under Linux, without any
    filesystem overhead.
</code></pre>

<p>The results of 3 runs of hdparm are shown below:</p>

<pre><code># hdparm -tT /dev/xvdb /dev/xvdc

/dev/xvdb:
 Timing cached reads:   11984 MB in  1.98 seconds = 6038.36 MB/sec
 Timing buffered disk reads:  158 MB in  3.01 seconds =  52.52 MB/sec

/dev/xvdc:
 Timing cached reads:   11988 MB in  1.98 seconds = 6040.01 MB/sec
 Timing buffered disk reads:  1810 MB in  3.00 seconds = 603.12 MB/sec


# hdparm -tT /dev/xvdb /dev/xvdc

/dev/xvdb:
 Timing cached reads:   11892 MB in  1.98 seconds = 5991.51 MB/sec
 Timing buffered disk reads:  172 MB in  3.00 seconds =  57.33 MB/sec

/dev/xvdc:
 Timing cached reads:   12056 MB in  1.98 seconds = 6075.29 MB/sec
 Timing buffered disk reads:  1972 MB in  3.00 seconds = 657.11 MB/sec


# hdparm -tT /dev/xvdb /dev/xvdc

/dev/xvdb:
 Timing cached reads:   11994 MB in  1.98 seconds = 6042.39 MB/sec
 Timing buffered disk reads:  254 MB in  3.02 seconds =  84.14 MB/sec

/dev/xvdc:
 Timing cached reads:   11890 MB in  1.99 seconds = 5989.70 MB/sec
 Timing buffered disk reads:  1962 MB in  3.00 seconds = 653.65 MB/sec
</code></pre>

<p><strong>Result:</strong>
Sequential reads from instance storage are 10x faster compared to EBS on average.</p>

<h2>IOzone</h2>

<p>I'm running MySQL and sequential data reads are probably over idealistic scenario.
So I found another benchmark suite, called <a href="http://iozone.org">IOzone</a>.
I used the 3-414 version built from the official SRPM.</p>

<p>IOzone performs multiple tests. I'm interested in read/re-read, random-read/write,
read-backwards and stride-read.</p>

<p>For this round of testing I've tested with ext4 filesystem with and without journal
on both types of disks. I also experimented running Iozone inside a ramfs mounted
directory. However I didn't have the time to run the test suite multiple times.</p>

<p>Then I used
<a href="http://code.google.com/p/iozone-results-comparator/">iozone-results-comparator</a> to
visualize the results. (I had to do a minor fix to the code to run inside virtualenv
and install all missing dependencies).</p>

<p>Raw IOzone output, data visualization and the modified tools are available in the
<a href="http://s3.amazonaws.com/atodorov/blog/aws_disk_benchmark_w_iozone.tar.bz2">aws_disk_benchmark_w_iozone.tar.bz2</a>
file (size 51M).</p>

<p><strong>Graphics</strong></p>

<p>EBS without journal(Baseline) vs. Instance Storage without journal(Set1)
<img src="/images/aws_iozone/ebs_woj_vs_is_woj.png" title="EBS vs. Instance Storage" alt="EBS vs. Instance Storage" /></p>

<p>Instance Storage without journal(Baseline) vs. Ramfs(Set1)
<img src="/images/aws_iozone/ebs_woj_vs_is_woj.png" title="IS vs. Ramfs" alt="IS vs. Ramfs" /></p>

<p><strong>Results</strong></p>

<ul>
<li>ext4 journal has no effect on reads, causes slow down when writing to disk. This
is expected;</li>
<li>Instance storage is faster compared to EBS but not much.
If I understand the results correctly, read performance is similar in some cases;</li>
<li>Ramfs is definitely the fastest but read performance compared to instance storage
is not two-fold (or more) as I expected;</li>
</ul>


<p><strong>Conclusion</strong></p>

<p>Instance storage appears to be faster (and this is expected) but I'm still not sure if
my application will gain any speed improvement or how much if migrated to read from
instance storage (or ramfs) instead of EBS. I will be performing more real-world
test next time, by comparing execution time for some of my largest SQL queries.</p>

<p>If you have other ideas how to adequately measure I/O performance in the AWS cloud,
please use the comments below.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Performance test of MD5, SHA1, SHA256 and SHA512]]></title>
    <link href="http://atodorov.org/blog/2013/02/05/performance-test-md5-sha1-sha256-sha512/"/>
    <updated>2013-02-05T10:33:00+02:00</updated>
    <id>http://atodorov.org/blog/2013/02/05/performance-test-md5-sha1-sha256-sha512</id>
    <content type="html"><![CDATA[<p>A few months ago I wrote
<a href="https://github.com/atodorov/django-s3-cache">django-s3-cache</a>.
This is Amazon Simple Storage Service (S3) cache backend for Django
which uses hashed file names.
django-s3-cache uses <code>sha1</code> instead of <code>md5</code> which appeared to be
faster at the time. I recall that my testing wasn't very robust so I did another
round.</p>

<h2>Test Data</h2>

<p>The file <a href="http://s3.amazonaws.com/atodorov/blog/urls.txt.gz">urls.txt</a>
contains 10000 unique paths from the <a href="http://www.dif.io">dif.io</a>
website and looks like this:</p>

<pre><code>/updates/Django-1.3.1/Django-1.3.4/7858/
/updates/delayed_paperclip-2.4.5.2 c23a537/delayed_paperclip-2.4.5.2/8085/
/updates/libv8-3.3.10.4 x86_64-darwin-10/libv8-3.3.10.4/8087/
/updates/Data::Compare-1.22/Data::Compare-Type/8313/
/updates/Fabric-1.4.0/Fabric-1.4.4/8652/
</code></pre>

<h2>Test Automation</h2>

<p>I used the standard <a href="http://docs.python.org/2/library/timeit.html">timeit</a>
module in Python.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>test.py  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">h1</span><span class="o">&gt;</span><span class="err">!</span><span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python</span><span class="o">&lt;/</span><span class="n">h1</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">h1</span><span class="o">&gt;</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="mi">2013</span> <span class="o">-</span> <span class="n">Alexander</span> <span class="n">Todorov</span><span class="p">,</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">atodorov</span><span class="o">.</span><span class="n">org</span><span class="o">&lt;/</span><span class="n">h1</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">h1</span><span class="o">&gt;</span><span class="n">Published</span> <span class="n">under</span> <span class="n">GNU</span> <span class="n">GPLv3</span><span class="o">&lt;/</span><span class="n">h1</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="kn">import</span> <span class="nn">timeit</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">t</span> <span class="o">=</span> <span class="n">timeit</span><span class="o">.</span><span class="n">Timer</span><span class="p">(</span>
</span><span class='line'><span class="sd">&quot;&quot;&quot;</span>
</span><span class='line'><span class="sd">import hashlib</span>
</span><span class='line'><span class="sd">for line in url_paths:&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="sd">&lt;pre&gt;&lt;code&gt;h = hashlib.md5(line).hexdigest()</span>
</span><span class='line'><span class="sd">&lt;/code&gt;&lt;/pre&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="sd">&lt;h1&gt;h = hashlib.sha1(line).hexdigest()&lt;/h1&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="sd">&lt;h1&gt;h = hashlib.sha256(line).hexdigest()&lt;/h1&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="sd">&lt;h1&gt;h = hashlib.sha512(line).hexdigest()&lt;/h1&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="sd">&lt;p&gt;&quot;&quot;&quot;</span>
</span><span class='line'><span class="p">,</span>
</span><span class='line'><span class="sd">&quot;&quot;&quot;</span>
</span><span class='line'><span class="sd">url_paths = []</span>
</span><span class='line'><span class="sd">f = open(&#39;urls.txt&#39;, &#39;r&#39;)</span>
</span><span class='line'><span class="sd">for l in f.readlines():&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="sd">&lt;pre&gt;&lt;code&gt;url_paths.append(l)</span>
</span><span class='line'><span class="sd">&lt;/code&gt;&lt;/pre&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="sd">&lt;p&gt;f.close()</span>
</span><span class='line'><span class="sd">&quot;&quot;&quot;</span>
</span><span class='line'><span class="p">)</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="k">print</span> <span class="n">t</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">repeat</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<h2>Test Results</h2>

<p>The main statement hashes all 10000 entries one by one. This statement is
executed 1000 times in a loop, which is repeated 3 times. I have Python 2.6.6
on my system. After every test run the system was rebooted.
Execution time in seconds is available below.</p>

<pre><code>MD5     10.275190830230713, 10.155328989028931, 10.250311136245728
SHA1    11.985718965530396, 11.976419925689697, 11.86873197555542
SHA256  16.662450075149536, 21.551337003707886, 17.016510963439941
SHA512  18.339390993118286, 18.11187481880188,  18.085782051086426
</code></pre>

<p>Looks like I was wrong the first time! MD5 is still faster but not that much.
I will stick with SHA1 for the time being.</p>

<p>As always Iâ€™d love to hear your thoughts and feedback. Please use the comment form below.</p>
]]></content>
  </entry>
  
</feed>
