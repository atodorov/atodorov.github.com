<!DOCTYPE html>
<html lang="en">

<head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">

            <meta name="google-site-verification" content="XynqZtldWNBbmsynVQZremIxaaO8Wgs6AGR8UZ7KIkM">

        <title>atodorov.org - Tag QA</title>

        <link href="http://feeds.feedburner.com/atodorov" type="application/atom+xml" rel="alternate" title="atodorov.org Full Atom Feed" />
        <!-- Bootstrap Core CSS -->
        <link href="http://atodorov.org/theme/css/bootstrap.min.css" rel="stylesheet">

        <!-- Custom CSS -->
        <link href="http://atodorov.org/theme/css/clean-blog.min.css" rel="stylesheet">

        <!-- Code highlight color scheme -->
            <link href="http://atodorov.org/theme/css/code_blocks/github.css" rel="stylesheet">

            <!-- CSS specified by the user -->
            <link href="http://atodorov.org/override.css" rel="stylesheet">

        <!-- Custom Fonts -->
        <link href="http://atodorov.org/theme/css/font-awesome.min.css" rel="stylesheet" type="text/css">
        <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
        <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

        <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
        <![endif]-->

                <meta property="fb:admins" content="1616937247" >
                <meta property="og:locale" content="en_US">
		<meta property="og:site_name" content="atodorov.org">
            <meta name="twitter:card" content="summary_large_image">
            <meta name="twitter:site" content="@atodorov_">
            <meta name="twitter:title" content="atodorov.org">
            <meta name="twitter:description" content="you can logoff, but you can never leave">
                <meta name="twitter:image" content="http://atodorov.org//images/header_02.jpg">
</head>

<body>

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-custom navbar-fixed-top">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="http://atodorov.org/">atodorov.org</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                        <li><a href="http://mrsenko.com/?utm_source=atodorov.org&utm_medium=blog&utm_campaign=menu">Mr. Senko</a></li>

                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

        <header class="intro-header" style="background-image: url('/images/header_02.jpg')">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <div class="page-heading">
                        <h1>Tag QA</h1>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- Main Content -->
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2015/10/15/anaconda-coverage.py-details/" rel="bookmark" title="Permalink to Anaconda & coverage.py - Pt.2 - Details">
                <h2 class="post-title">
                    Anaconda &amp; coverage.py - Pt.2 - Details
                </h2>
            </a>
                <p>My <a href="/blog/2015/10/14/anaconda-coverage.py-introduction/">previous post</a>
was an introduction to testing installation related components. Now I'm going to
talk more about anaconda and how it is tested.</p>
<p>There are two primary ways to test anaconda. You can execute <code>make check</code> in the
source directory which will trigger the package test suite. The other possibility
is to perform an actual installation, on bare meta or virtual machine, using the
<a href="https://kojipkgs.fedoraproject.org/mash/">latest Rawhide snapshots</a> which also
include the latest anaconda. For both of these methods we can collect code
coverage information. In live installation mode coverage is enabled via the
<code>inst.debug</code> boot argument. Fedora 23 and earlier use <code>debug=1</code> but that
can lead to <a href="https://github.com/rhinstaller/anaconda/pull/291">problems</a>
sometimes.</p>
<h2>Kickstart Testing</h2>
<p><a href="https://github.com/rhinstaller/pykickstart/blob/master/docs/kickstart-docs.rst">Kickstart</a>
is a method of automating the installation of Fedora by supplying the necessary
configuration into a text file and pointing the installer at this file. There is
the directory <code>tests/kickstart_tests</code>, inside the anaconda source, where each
test is a kickstart file and a shell script. The test runner provisions a virtual
machine using boot.iso and the kickstart file. A shell script then verifies
installation was as expected and copies files of interest to the host system.
Kickstart files are also the basis for testing Fedora installations in
<a href="https://beaker.fedoraproject.org/bkr/jobs/">Beaker</a>.</p>
<p>Naturally some of these in-package kickstart tests are the same as
<a href="https://bitbucket.org/fedoraqa/fedora-beaker-tests/">out-of-band kickstart tests</a>.
Hint: there are more available but not yet public.</p>
<p>The question which I don't have an answer for right now is
"Can we remove some of the duplicates and how this affects devel and QE teams" ?
The pros of in-package testing are that it is faster compared to Beaker. The cons
are that you're not testing the real distro (every snapshot is a possible final
release to the users).</p>
<h2>Dogtail</h2>
<p><a href="https://fedorahosted.org/dogtail/">Dogtail</a> uses accessibility technologies to
communicate with desktop applications. It is written in Python and can be used
as GUI test automation framework. Long time ago I've proposed support for Dogtail
in anaconda which was rejected, then couple of years later it was accepted and
later removed from the code again.</p>
<p>Anaconda has in-package Dogtail tests (<code>tests/gui/</code>). They work by attaching
a second disk image with the test suite to a VM running a LiveCD. Anaconda is
started on the LiveCD and an attempt to install Fedora on disk 1 is made.
Everything is driven by the Dogtail scripts. There are only a few of these
tests available and they are currently disabled.
Red Hat QE has also created another method for running Dogtail tests in anaconda
using an updates.img with the previous functionality.</p>
<p>Even if there are some duplicate tests I'm not convinced we have to drop the
<code>tests/gui/</code> directory from the code because
the framework used to drive the graphical interface of anaconda appears to be very
well written. The code is clean and easy to follow.
Also I don't have metrics of how much these two methods differ or how much they cover
in their testing. IMO they are pretty close and before we can find a way to
reliably execute them on a regular basis there isn't much to be done here.
One idea is to use the <code>--dirinstall</code> or <code>--image</code> options and skip the
LiveCD part entirely.</p>
<h2>How Much is Tested</h2>
<p><code>make ci</code> covers 10% of the entire code base for anaconda. Mind you that
<code>tests/storage</code> and <code>tests/gui</code> are currently disabled.
See <a href="https://github.com/rhinstaller/anaconda/pull/346">PR #346</a>,
<a href="https://github.com/rhinstaller/anaconda/pull/327">PR #327</a> and
<a href="https://github.com/rhinstaller/anaconda/pull/319">PR #319</a>!
There is definitely room for improvement.</p>
<p>On the other hand live installation testing is much
better. Text mode covers around 25% while graphical installations around 40%.
Text and graphical combined cover 50% though. These numbers will drop quite a bit
once anaconda learns to
<a href="https://github.com/rhinstaller/anaconda/pull/397">include all possible files</a>
in its report but it is a good estimate.</p>
<p>The important questions to ask here are:</p>
<ul>
<li>How much can PyUnit tests cover in anaconda?</li>
<li>How much can kickstart tests cover ?</li>
<li>Have we reached a threshold in any of the two primary methods for testing ?</li>
<li>Does UI automation (with Dogtail) improve anything ?</li>
<li>When testing a particular feature (say user creation) how different is the
code execution path between manual (GUI) testing, kickstart and unit testing ?
If not so different can we invest in unit tests instead of higher level tests then ?</li>
<li>How different is the code execution path between different tests (manual or kickstart) ?
In other words how much value are we getting from testing for the resources we're putting in ?</li>
</ul>
<p>In my next post I will talk more about these questions and some rudimentary
analysis against coverage data from the various test methods and test cases!</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Thu 15 October 2015
            </p>
<p>There are <a href="http://atodorov.org/blog/2015/10/15/anaconda-coverage.py-details/#disqus_thread">comments</a>.</p>        </div>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2015/10/14/anaconda-coverage.py-introduction/" rel="bookmark" title="Permalink to Anaconda & coverage.py - Pt.1 - Introduction">
                <h2 class="post-title">
                    Anaconda &amp; coverage.py - Pt.1 - Introduction
                </h2>
            </a>
                <p>Since early 2015 I've been working on testing installation related
components in Rawhide. I'm interested in the code produced by the
<a href="https://github.com/rhinstaller/">Red Hat Installer Engineering Team</a> and in
particular in <em>anaconda</em>, <em>blivet</em>, <em>pyparted</em> and <em>pykickstart</em>. The goal of
this effort is to improve the overall testing of these components and also
have Red Hat QE contribute some of our knowledge back to the community. The benefit
of course will be better software for everyone. In the next
several posts I'll summarize what has been done so far and what's to be expected
in the future.</p>
<h2>Test Documentation Matters</h2>
<p>Do you want others to contribute tests? I certainly do! When I started looking
at the code it was obviously clear there was no documentation related to testing.
Everyone needs to know how to write and execute these tests! Currently we have
basic README files describing how to install necessary dependencies for development
and test execution, how to execute the tests (and what can be tested) and most
importantly what is the test architecture. There is description of how the file
structure is organized and which are the base classes to inherit from when adding
new tests. Most of the times each component goes through a <em>pylint</em> check and
a standard PyUnit test suite.</p>
<p>Test documentation is usually in a <code>tests/README</code> file. For example:</p>
<ul>
<li><a href="https://github.com/rhinstaller/anaconda/blob/master/tests/README.rst">anaconda</a></li>
<li><a href="https://github.com/rhinstaller/blivet/blob/master/tests/README.rst">blivet</a></li>
<li><a href="https://github.com/rhinstaller/pykickstart/blob/master/tests/README.rst">pykickstart</a></li>
<li><a href="https://github.com/rhinstaller/pyparted/blob/master/tests/README.rst">pyparted</a></li>
</ul>
<p>I've tried to explain as much as possible without bloating the files and going into
unnecessary details. If you spot something missing please send a pull request.</p>
<h2>Continuous Integration</h2>
<p>This has been largely an effort driven by Chris Lumens from the devel team.
All the components I'm interested in are tested regularly in a CI environment.
There is a <code>make ci</code> Makefile target for those of you interested in what exactly
gets executed.</p>
<h2>Test Coverage</h2>
<p>In order to <strong>improve</strong> something you need to know where you stand. We'll I didn't.
That's why the first step was to integrate the
<a href="https://bitbucket.org/ned/coveragepy">coverage.py</a> tool with all of these components.</p>
<p>With the exception of blivet (written in C) all of the other
components integrate well with coverage.py and produce good statistics. pykickstart is
the champ here with 90% coverage, while anaconda is somewhere between 10% and 50%.
Full test coverage measurement for anaconda isn't straight forward and will be the
subject of my next post. For the C based code we have to hook up with
<a href="https://gcc.gnu.org/onlinedocs/gcc/Gcov.html">Gcov</a> which shouldn't be too difficult.</p>
<p>At the moment there are several open pull requests to integrate the coverage test
targets with <code>make ci</code> and also report the results in human readable form. I will be
collecting these for historical references.</p>
<h2>Tools</h2>
<p>I've created some basic text-mode
<a href="https://github.com/atodorov/coverage-tools">coverage-tools</a> to help me combine and
compare data from different executions. These are only the start of it and I'm expanding
them as my needs for reporting and analytics evolve. I'm also looking into
<a href="/blog/2015/07/27/call-for-ideas-graphical-test-coverage-reports/">more detailed coverage reports</a>
but I don't have enough data and use cases to work on this front at the moment.</p>
<p>Some ideas currently in mind:</p>
<ul>
<li>map code changes (git commits) to existing test coverage to get a feeling where to
invest in more testing;</li>
<li>map bugs to code areas and to existing test coverage to see if we aren't
missing tests in areas where the bugs are happening;</li>
</ul>
<h2>Bugs</h2>
<p>coverage.py is a very nice tool indeed but I guess most people use it in a very
limited way. Shortly after I started working with it I've found several places which
need improvements. These have to do with combining and reporting on multiple files.</p>
<p>Some of the interesting issues I've found and still open are:</p>
<ul>
<li><a href="https://bitbucket.org/ned/coveragepy/pull-requests/63/">PR #63 - New option --dont-remove when combining coverage data</a></li>
<li><a href="https://bitbucket.org/ned/coveragepy/issues/425">#425 - source parameter not including files which are explicitly specified</a></li>
<li><a href="https://bitbucket.org/ned/coveragepy/issues/426">#426 - Difference between coverage results with source specifies full dir instead of module name</a></li>
</ul>
<p>In my next post I will talk about anaconda code coverage and what I want to do with it.
In the mean time please use the comments to share your feedback.</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Wed 14 October 2015
            </p>
<p>There are <a href="http://atodorov.org/blog/2015/10/14/anaconda-coverage.py-introduction/#disqus_thread">comments</a>.</p>        </div>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2015/09/25/unit-testing-bad-stub-design-in-dnf/" rel="bookmark" title="Permalink to Unit Testing Example - Bad Stub Design in DNF">
                <h2 class="post-title">
                    Unit Testing Example - Bad Stub Design in DNF
                </h2>
            </a>
                <p>In software testing, usually unit testing, test stubs are programs that simulate
the behaviors of external dependencies that a module undergoing the test depends
on. Test stubs provide canned answers to calls made during the test.</p>
<p>I've discovered an improperly written stub method in one of
<a href="http://dnf.baseurl.org/">DNF</a>'s tests:</p>
<div class="highlight"><span class="filename">tests/test_download.py</span><pre><span class="k">class</span> <span class="nc">DownloadCommandTest</span><span class="p">(</span><span class="n">unittest</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">setUp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">stub_fn</span><span class="p">(</span><span class="n">pkg_spec</span><span class="p">):</span>
            <span class="k">if</span> <span class="s">&#39;.src.rpm&#39;</span> <span class="ow">in</span> <span class="n">pkg_spec</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">Query</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">sourcerpm</span><span class="o">=</span><span class="n">pkg_spec</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">q</span> <span class="o">=</span> <span class="n">Query</span><span class="o">.</span><span class="n">latest</span><span class="p">()</span>
                <span class="k">return</span> <span class="p">[</span><span class="n">pkg</span> <span class="k">for</span> <span class="n">pkg</span> <span class="ow">in</span> <span class="n">q</span> <span class="k">if</span> <span class="n">pkg_spec</span> <span class="o">==</span> <span class="n">pkg</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>

        <span class="n">cli</span> <span class="o">=</span> <span class="n">mock</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cmd</span> <span class="o">=</span> <span class="n">download</span><span class="o">.</span><span class="n">DownloadCommand</span><span class="p">(</span><span class="n">cli</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cmd</span><span class="o">.</span><span class="n">cli</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">repos</span> <span class="o">=</span> <span class="n">dnf</span><span class="o">.</span><span class="n">repodict</span><span class="o">.</span><span class="n">RepoDict</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">cmd</span><span class="o">.</span><span class="n">_get_query</span> <span class="o">=</span> <span class="n">stub_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cmd</span><span class="o">.</span><span class="n">_get_query_source</span> <span class="o">=</span> <span class="n">stub_fn</span>
</pre></div>


<p>The replaced methods look like this:</p>
<div class="highlight"><span class="filename">plugins/download.py</span><pre>    <span class="k">def</span> <span class="nf">_get_query</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pkg_spec</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return a query to match a pkg_spec.&quot;&quot;&quot;</span>
        <span class="n">subj</span> <span class="o">=</span> <span class="n">dnf</span><span class="o">.</span><span class="n">subject</span><span class="o">.</span><span class="n">Subject</span><span class="p">(</span><span class="n">pkg_spec</span><span class="p">)</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">subj</span><span class="o">.</span><span class="n">get_best_query</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">sack</span><span class="p">)</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">available</span><span class="p">()</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">latest</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">run</span><span class="p">())</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="n">_</span><span class="p">(</span><span class="s">&quot;No package &quot;</span> <span class="o">+</span> <span class="n">pkg_spec</span> <span class="o">+</span> <span class="s">&quot; available.&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">dnf</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">PackageNotFoundError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">q</span>

    <span class="k">def</span> <span class="nf">_get_query_source</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pkg_spec</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;&quot;Return a query to match a source rpm file name.&quot;&quot;&quot;</span>
        <span class="n">pkg_spec</span> <span class="o">=</span> <span class="n">pkg_spec</span><span class="p">[:</span><span class="o">-</span><span class="mi">4</span><span class="p">]</span>  <span class="c"># skip the .rpm</span>
        <span class="n">nevra</span> <span class="o">=</span> <span class="n">hawkey</span><span class="o">.</span><span class="n">split_nevra</span><span class="p">(</span><span class="n">pkg_spec</span><span class="p">)</span>
        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">sack</span><span class="o">.</span><span class="n">query</span><span class="p">()</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">available</span><span class="p">()</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">latest</span><span class="p">()</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">nevra</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="n">nevra</span><span class="o">.</span><span class="n">version</span><span class="p">,</span>
                     <span class="n">release</span><span class="o">=</span><span class="n">nevra</span><span class="o">.</span><span class="n">release</span><span class="p">,</span> <span class="n">arch</span><span class="o">=</span><span class="n">nevra</span><span class="o">.</span><span class="n">arch</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">run</span><span class="p">())</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="n">_</span><span class="p">(</span><span class="s">&quot;No package &quot;</span> <span class="o">+</span> <span class="n">pkg_spec</span> <span class="o">+</span> <span class="s">&quot; available.&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">dnf</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">PackageNotFoundError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">q</span>
</pre></div>


<p>As seen here <em>stub_fn</em> replaces the <em>_get_query</em> methods from the class under
test. At the time of writing this has probably seemed like a good idea to
speed up writing the tests.</p>
<p>The trouble is we should be replacing the external dependencies of <em>_get_query</em>
(other parts of DNF essentially) and not methods from <em>DownloadCommand</em>. To
understand why this is a bad idea check
<a href="https://github.com/rpm-software-management/dnf-plugins-core/pull/113">PR #113</a>,
which directly modifies <em>_get_query</em>. There's no way to test this patch
with the current state of the test.</p>
<p>So I took a few days to experiment and update the current test stubs. The
result is 
<a href="https://github.com/rpm-software-management/dnf-plugins-core/pull/118">PR #118</a>.
The important bits are the <em>SackStub</em> and <em>SubjectStub</em> classes which hold
information about the available RPM packages on the system. The rest are cosmetics
to fit around the way the query objects are used (q.available(), q.latest(), q.filter()).
The proposed design correctly overrides the external dependencies on
<em>dnf.subject.Subject</em> and <em>self.base.sack</em> which are initialized before our
plugin is loaded by DNF.</p>
<p>I must say this is the first error of this kind I've seen in my QA practice so far.
I have no idea if this was a minor oversight or something which happens more frequently
in open source projects but it's a great example nevertheless.</p>
<p>For those of you who'd like to get started on unit testing I can recommend the book
<a href="http://www.amazon.com/gp/product/1933988274/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=1933988274&linkCode=as2&tag=atodorovorg-20">The Art of Unit Testing: With Examples in .Net</a><img src="http://www.assoc-amazon.com/e/ir?t=atodorovorg-20&l=as2&o=1&a=1933988274" width="1" height="1" border="0"  style="border:none !important; margin:0px !important;" />
by Roy Osherove!</p>
<p><strong>UPDATE</strong>: Part 2 with more practical examples can be found
<a href="/blog/2015/11/23/bad-stub-design-in-dnf/">here</a>.</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Fri 25 September 2015
            </p>
<p>There are <a href="http://atodorov.org/blog/2015/09/25/unit-testing-bad-stub-design-in-dnf/#disqus_thread">comments</a>.</p>        </div>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2015/09/16/4000-bugs-in-fedora-checksec-failures/" rel="bookmark" title="Permalink to 4000+ bugs in Fedora - checksec failures">
                <h2 class="post-title">
                    4000+ bugs in Fedora - checksec failures
                </h2>
            </a>
                <p>In the last week I've been trying to figure out how many packages
conform to the new
<a href="https://fedoraproject.org/wiki/Changes/Harden_All_Packages">Harden All Packages</a>
policy in Fedora!</p>
<p>From 46884 RPMs, 17385 are 'x86_64' meaning they may contain ELF objects.
From them 4489 are reported as failed <code>checksec</code>.</p>
<p>What you should see as the output from <code>checksec is</code></p>
<div class="highlight"><pre>Full RELRO      Canary found      NX enabled    PIE enabled     No RPATH   No RUNPATH
Full RELRO      Canary found      NX enabled    DSO             No RPATH   No RUNPATH
</pre></div>


<p>The first line is for binaries, the second one for libraries b/c
DSOs on x86_64 are always position-independent. Some RPATHs are acceptable,
e.g. <code>%{_libdir}/foo/</code> and I've tried to exclude them unless
other offenses are found. The script which does this is
<a href="https://github.com/atodorov/fedora-scripts/blob/master/checksec-collect">checksec-collect</a>.</p>
<p>Most often I'm seeing <em>Partial RELRO</em>, <em>No canary found</em> and <em>No PIE</em> errors.
Since all packages potentially process untrusted input, it makes sense for all of them
to be hardened and enhance the security of Fedora. That's why all of these errors
should be considered valid bugs.</p>
<h2>Attn package maintainers</h2>
<p>Please see if your package is in the list and try to fix it or let me know
why it should be excluded, for example it's a boot loader and doesn't function
properly with hardening enabled. The full list is available at
<a href="https://github.com/atodorov/fedora-scripts/blob/master/checksec.log">GitHub</a>.</p>
<p>For more information about the different protection mechanisms see the following
links:</p>
<ul>
<li><a href="http://tk-blog.blogspot.bg/2009/02/relro-not-so-well-known-memory.html">Partial vs Full RELRO</a></li>
<li><a href="https://en.wikipedia.org/wiki/Buffer_overflow_protection#Canaries">Stack canaries</a></li>
<li><a href="https://en.wikipedia.org/wiki/NX_bit#Linux">NX memory protection</a></li>
<li><a href="https://securityblog.redhat.com/2012/11/28/position-independent-executables-pie/">Position Independent Executables</a></li>
<li><a href="https://fedoraproject.org/wiki/Packaging:Guidelines#Beware_of_Rpath">RPATH</a></li>
<li><a href="http://blog.tremily.us/posts/rpath/">RUNPATH</a></li>
</ul>
<p><strong>UPDATE 2015-09-17</strong></p>
<p>I've posted my findings on 
<a href="https://lists.fedoraproject.org/pipermail/devel/2015-September/thread.html">fedora-devel</a>
and the comments are more than interesting even revealing an old bug in libtool.</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Wed 16 September 2015
            </p>
<p>There are <a href="http://atodorov.org/blog/2015/09/16/4000-bugs-in-fedora-checksec-failures/#disqus_thread">comments</a>.</p>        </div>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2015/08/20/minor-typo-bug-in-messenger/" rel="bookmark" title="Permalink to Minor Typo Bug in Messenger for bg_BG.UTF-8">
                <h2 class="post-title">
                    Minor Typo Bug in Messenger for bg_BG.UTF-8
                </h2>
            </a>
                <p><img alt="Messenger typo" src="/images/messenger_typo.png" title="Messenger typo" /></p>
<p>There's a typo in the Bulgarian translation of Messenger.com.
It is highlighted by the red dot on the picture.</p>
<p><em>hunspell</em> easily catches it so either Facebook doesn't run their
translations through a spell checker or their spell checker is
borked.</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Thu 20 August 2015
            </p>
<p>There are <a href="http://atodorov.org/blog/2015/08/20/minor-typo-bug-in-messenger/#disqus_thread">comments</a>.</p>        </div>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2015/08/17/pedometer-bug-in-samsung-s-health/" rel="bookmark" title="Permalink to Pedometer Bug in Samsung S Health">
                <h2 class="post-title">
                    Pedometer Bug in Samsung S Health
                </h2>
            </a>
                <p>Do you remember the 
<a href="/blog/2015/01/09/pedometer-bug-in-samsung-gear-fit-smartwatch/">pedometer bug in Samsung Gear Fit</a>
I've discovered earlier ? It turns out that Samsung is a fan of this one
and has the exact same bug in their <em>S Health</em> application.</p>
<p>The application doesn't block pedometer(e.g. steps counting) while
performing other activities such as cycling for example. So in reallity it
reports incorrect value for burned callories. At this time I call it
bad software development practice/architecture on Samsung's part which leads
to this bug being present.</p>
<p>Btw for more interesting bugs see
<a href="http://gearfitbugs.tumblr.com/">Samsung Gear Fit Bug-of-the-Day</a>.</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Mon 17 August 2015
            </p>
<p>There are <a href="http://atodorov.org/blog/2015/08/17/pedometer-bug-in-samsung-s-health/#disqus_thread">comments</a>.</p>        </div>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2015/07/27/call-for-ideas-graphical-test-coverage-reports/" rel="bookmark" title="Permalink to Call for Ideas: Graphical Test Coverage Reports">
                <h2 class="post-title">
                    Call for Ideas: Graphical Test Coverage Reports
                </h2>
            </a>
                <p>If you are working with Python and writing unit tests chances are you are
familiar with the <a href="http://nedbatchelder.com/code/coverage/">coverage</a> reporting
tool. However there are testing scenarios in which we either don't use unit tests
or maybe execute different code paths(test cases) independent of each other.</p>
<p>For example, this is the case with installation testing in Fedora. Because anaconda
- the installer is very complex the easiest way is to test it live, not with unit tests.
Even though we can get a coverage report (anaconda is written in Python) it reflects
only the test case it was collected from.</p>
<p><code>coverage combine</code> can be used to combine several data files and produce an aggregate
report. This can tell you how much test coverage you have across all your tests.</p>
<p>As far as I can tell Python's coverage doesn't tell you how many times a particular
line of code has been executed. It also doesn't tell you which test cases executed
a particular line
(see <a href="https://bitbucket.org/ned/coveragepy/pull-request/59">PR #59</a>).
In the Fedora example, I have the feeling many of our tests are touching the same
code base and not contributing that much to the overall test coverage.
So I started working on these items.</p>
<p>I imagine a script which will read coverage data from several test executions
(preferably in JSON format, 
<a href="https://bitbucket.org/ned/coveragepy/pull-request/60">PR #60</a>) and produce a 
graphical report similar to what GitHub does for your commit activity.</p>
<p>See an example <a href="https://s3.amazonaws.com/atodorov/blog/pykickstart_report.html">here</a>!</p>
<p>The example uses darker colors to indicate more line executions, lighter for less
executions. Check the HTML for the actual numbers b/c there are no hints yet.
The input JSON files are
<a href="https://s3.amazonaws.com/atodorov/blog/coverage_json_reports.tar.gz">here</a> and
the script to generate the above HTML is at 
<a href="https://github.com/atodorov/fedora-scripts/blob/master/coverage-tool">GitHub</a>.</p>
<p>Now I need your ideas and comments!</p>
<p>What kinds of coverage reports are you using in your job ? How do you generate them ?
How do they look like ?</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Mon 27 July 2015
            </p>
<p>There are <a href="http://atodorov.org/blog/2015/07/27/call-for-ideas-graphical-test-coverage-reports/#disqus_thread">comments</a>.</p>        </div>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2015/05/21/bug-in-vmware-open-house-website/" rel="bookmark" title="Permalink to Bug in VMware Open House Website">
                <h2 class="post-title">
                    Bug in VMware Open House Website
                </h2>
            </a>
                <p><img alt="&quot;Open House website bug&quot;" src="/images/vmware_bug.png" title="Bug in VMware Open House website" /></p>
<p>This is a slightly annoying UI bug in
<a href="http://www.openhouse.vmware-bulgaria.com/">VMware's Open House</a> website. I've reported
it and hopefully they will fix it.</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Thu 21 May 2015
            </p>
<p>There are <a href="http://atodorov.org/blog/2015/05/21/bug-in-vmware-open-house-website/#disqus_thread">comments</a>.</p>        </div>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2015/05/20/free-software-testing-books/" rel="bookmark" title="Permalink to Free Software Testing Books">
                <h2 class="post-title">
                    Free Software Testing Books
                </h2>
            </a>
                <p>There's a huge list of 
<a href="https://github.com/ligurio/free-software-testing-books/blob/master/free-software-testing-books.md">free books</a>
on the topic of software testing. This will definitely be my summer reading list.
I hope you find it helpful.</p>
<h2>200 Graduation Theses About Software Testing</h2>
<p>The guys from <a href="http://qahelp.net">QAHelp</a> have compiled a list of 200
graduation theses from various universities which are freely accessible
online. The list can be found
<a href="http://qahelp.net/200-dissertatsij-po-testirovaniyu-v-svobodnoj-dostupe/">here</a>.</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Wed 20 May 2015
            </p>
<p>There are <a href="http://atodorov.org/blog/2015/05/20/free-software-testing-books/#disqus_thread">comments</a>.</p>        </div>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2015/01/09/pedometer-bug-in-samsung-gear-fit-smartwatch/" rel="bookmark" title="Permalink to Pedometer Bug in Samsung Gear Fit Smartwatch">
                <h2 class="post-title">
                    Pedometer Bug in Samsung Gear Fit Smartwatch
                </h2>
            </a>
                <p><a style="float:left;display:inline-block;margin-right:10px;" href="http://www.amazon.com/gp/product/B00J4DY8RU/ref=as_li_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=B00J4DY8RU&linkCode=as2&tag=atodorovorg-20&linkId=RNJGVYUTOOJFGWOU">
<img src="/images/samsung/gear_fit.jpg" />
</a>
<sub>
Image source <a href="http://pocketnow.com/2014/05/02/samsung-gear-fit-review-pre-buttal-video">Pocketnow</a>
<sub></p>
<p>Recently I've been playing around with a
<a href="http://www.amazon.com/gp/product/B00J4DY8RU/ref=as_li_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=B00J4DY8RU&linkCode=as2&tag=atodorovorg-20&linkId=RNJGVYUTOOJFGWOU">Samsung Gear Fit</a><img src="http://ir-na.amazon-adsystem.com/e/ir?t=atodorovorg-20&l=as2&o=1&a=B00J4DY8RU" width="1" height="1" border="0"  style="border:none !important; margin:0px !important;" />
and while the hardware seems good I'm a bit disapointed on the software side.
There is at least one bug which is clearly visible - <strong>pedometer counts calories twice
when it's on and exercise mode is started</strong>.</p>
<p>How to test:</p>
<ul>
<li>Start the <em>Pedometer</em> app and record any initial readings;</li>
<li>Walk a fixed distance and at the end record all readings;</li>
<li>Now go back to the <em>Exercise</em> app and select a <em>Walking</em>
exercise from the menu. Tap <em>Start</em>;</li>
<li>Walk back the same distance/road as before. At the end of the journey
stop the walking exercise and record all readings.</li>
</ul>
<p>Expected results:</p>
<p>At the end of the trip I expect to see roughly the same calories burned
for both directions.</p>
<p>Actual results:</p>
<p>The return trip counted twice as many calories compared to the forward trip.
Here's some actual data to prove it:</p>
<div class="highlight"><pre>+--------------------------+----------+----------------+---------+-------------+---------+
|                          | Initial  | Forward trip   |         | Return trip |         |
|                          | Readings | Pedometer only |  Delta  | Pedometer &amp; |  Delta  |
|                          |          |                |         | Exercise    |         |
+--------------------------+----------+----------------+---------+-------------+---------+
|              Total Steps | 14409 st | 14798 st       | 389 st  | 15246 st    | 448 st  |
+--------------------------+----------+----------------+---------+-------------+---------+
|           Total Distance | 12,19 km | 12,52 km       | 0,33 km | 12,90 km    | 0,38 km |
+--------------------------+----------+----------------+---------+-------------+---------+
| Cal burned via Pedometer |  731 Cal |  751 Cal       | 20 Cal  |  772 Cal    | 21 Cal  |
+--------------------------+----------+----------------+=========+-------------+=========+
| Cal burned via Exercise  |  439 Cal |  439 Cal       | 0       |  460 Cal    | 21 Cal  |
+--------------------------+----------+----------------+---------+-------------+=========+
|    Total calories burned | 1170 Cal | 1190 Cal       | 20 cal  | 1232 Cal    | 42 Cal  |
+--------------------------+----------+----------------+=========+-------------+=========+
</pre></div>


<p><strong>Note:</strong> Data values above were taken from Samsung's <em>S Health</em> app which is easier to work with
instead of the Gear Fit itself.</p>
<p>The problem is that both apps are accessing the sensor simultaneously and not aware of each other.
In theory it should be relatively easy to block access of one app while the other is running but
that may not be so easy to implement on the limited platform the Gear Fit is.</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Fri 09 January 2015
            </p>
<p>There are <a href="http://atodorov.org/blog/2015/01/09/pedometer-bug-in-samsung-gear-fit-smartwatch/#disqus_thread">comments</a>.</p>        </div>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2015/01/07/2-barcode-related-bugs-in-myfitnesspal/" rel="bookmark" title="Permalink to 2 Barcode Related Bugs in MyFitnessPal">
                <h2 class="post-title">
                    2 Barcode Related Bugs in MyFitnessPal
                </h2>
            </a>
                <p><img alt="Barcode that fails to scan" src="/images/barcode/fail.jpg" title="Barcode that fails to scan" /></p>
<p><strong>Did you know that the popular <em>MyFitnessPal</em> application can't scan barcodes
printed on curved surfaces?</strong> The above barcode fails to scan because it is
printed on a metal can full of roasted almonds :). In contrast the
<em>Barcode Scanner</em> from <em>ZXing Team</em> understands it just fine. My bet is
<em>MyFitnessPal</em> uses less advanced barcode scanning library. Judging from
the visual clues in the app the issue is between 6 and 0 where white space is wider.</p>
<p><img alt="Barcode that scans fine" src="/images/barcode/pass.jpg" title="Barcode that scans fine" /></p>
<p>Despite being a bit blurry this second barcode is printed on a flat surface and
is understood by both <em>MyFitnessPal</em> and "ZXing Barcode Scanner".</p>
<p><strong>NOTE</strong> I get the same results regardless if I try to scan the actual barcode
printed on packaging, a picture from a mobile device screen or these two images
from the laptop screen.</p>
<p><strong>MyFitnessPal also has problems with duplicate barcodes!</strong> Barcodes are not unique
and many producers use the same code for multiple products. I've seen this in the
case of two different varieties of salami from the same manufacturer on the good end
and two different products produced across the world (eggs and popcorn) on the
extreme end.</p>
<p>Once the user scans their barcodes and establish that the existing information is
not correct they can <em>Create a Food</em> and update the calories database. This is then
synced back to MyFitnesPal servers and overrides any existing information. When the same
barcode is scanned for the second time only the new DB entry is visible.</p>
<p>How to reproduce:</p>
<ul>
<li>Scan an existing barcode and enter it to MFP database if not already there;</li>
<li>Scan the same barcode one more time and pretend the information is not correct;</li>
<li>Click the <em>Create a Food</em> button and fill-in the fields. For example use a
different food name to distinguish between the two database entries. Save!</li>
<li>From another device with different account (to verify information in DB)
scan the same barcode again. </li>
</ul>
<p>Actual results:
The last entered information is shown.</p>
<p>Expected results:
User is shown both DB records and can select between them.</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Wed 07 January 2015
            </p>
<p>There are <a href="http://atodorov.org/blog/2015/01/07/2-barcode-related-bugs-in-myfitnesspal/#disqus_thread">comments</a>.</p>        </div>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2015/01/05/endless-loop-bug-candy-crush-saga-level-80/" rel="bookmark" title="Permalink to Endless Loop Bug in Candy Crush Saga Level 80">
                <h2 class="post-title">
                    Endless Loop Bug in Candy Crush Saga Level 80
                </h2>
            </a>
                <p>Happy new year everyone. During the holidays I've discovered several interesting
bugs which will be revealed in this blog. Starting today with a bug in the popular
game <em>Candy Crush Saga</em>.</p>
<p>In level 80 one teleport is still open but the chocolates are blocking the rest.
The game has ended but candies keep flowing through the teleport and the level doesn't exit.
My guess is that the game logic is missing a check whether or not it will go into an endless loop.</p>
<iframe width="560" height="315" src="//www.youtube.com/embed/haBepFwyaxY" frameborder="0" allowfullscreen></iframe>

<p>This bug seems to be generic for the entire game. It pops up also on
level 137 in the Owl part of the game (recorded by somebody else):</p>
<iframe width="420" height="315" src="//www.youtube.com/embed/6q1_LIdamqw" frameborder="0" allowfullscreen></iframe>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Mon 05 January 2015
            </p>
<p>There are <a href="http://atodorov.org/blog/2015/01/05/endless-loop-bug-candy-crush-saga-level-80/#disqus_thread">comments</a>.</p>        </div>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2014/12/22/blackberry-z10-is-killing-my-wifi-router/" rel="bookmark" title="Permalink to BlackBerry Z10 is Killing My WiFi Router">
                <h2 class="post-title">
                    BlackBerry Z10 is Killing My WiFi Router
                </h2>
            </a>
                <p>Few days ago I've resurrected my BlackBerry Z10 only to find out that it kills
my WiFi router shortly after connecting to the network.
It looks like many people are having the same problem with BlackBerry but most forum
threads don't offer a meaningful solution so I did some tests. </p>
<p>Everything works fine when WiFi mode is set to either 11bgn mixed or 11n only and
WiFi security is disabled.</p>
<p>When using WPA2/Personal security mode and AES encryption the problem occurs
regardless of which WiFi mode is used. There is another type of encryption called TKIP
but the device itself warns that this is not supported by the 802.11n specification
(all my devices use it anyway).</p>
<p>So to recap:
<strong>BlackBerry Z10 causes my TP-Link router to die if using WPA2/Personal security with
AES Encryption. Switching to open network with MAC address filtering works fine!</strong></p>
<p>I haven't had the time to upgrade the firmware of this router and see if the problem persists.
Most likely I'll just go ahead and flash it with OpenWRT.</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Mon 22 December 2014
            </p>
<p>There are <a href="http://atodorov.org/blog/2014/12/22/blackberry-z10-is-killing-my-wifi-router/#disqus_thread">comments</a>.</p>        </div>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2014/11/19/speed-comparison-of-web-proxies-written-in-python-twisted-and-go/" rel="bookmark" title="Permalink to Speed Comparison of Web Proxies Written in Python Twisted and Go">
                <h2 class="post-title">
                    Speed Comparison of Web Proxies Written in Python Twisted and Go
                </h2>
            </a>
                <p>After I figured out that
<a href="/blog/2014/11/11/speeding-up-celery-backends-part-3/">Celery is rather slow</a>
I moved on to test another part of my environment - a web proxy server.
The test here compares two proxy 
<a href="https://gist.github.com/atodorov/666035d270d97d982cd5">implementations</a>
- one with Python Twisted,
the other in Go. The backend is a simple web server written in Go, which is
probably the fastest thing when it comes to serving HTML.</p>
<p>The test content is a snapshot of the front page of this blog taken few days ago.
The system is a standard Lenovo X220 laptop, with Intel Core i7 CPU, with 4 cores.
The measurement instrument is the popular wrk tool with a
<a href="/blog/2014/11/18/proxy-support-for-wrk-http-benchmarking-tool/">custom Lua script to redirect the requests through the proxy</a>.</p>
<p>All tests were repeated several times, only the best results are shown here.
I've taken time between the tests in order for all open TCP ports to close.
I've also observed the number of open ports (e.g. sockets) using <code>netstat</code>.</p>
<h2>Baseline</h2>
<p>Using wrk against the web server in Go yields around 30000 requests per second
with an average of 2000 TCP ports in use:</p>
<div class="highlight"><pre><span class="nv">$ </span>./wrk -c1000 -t20 -d30s http://127.0.0.1:8000/atodorov.html
Running 30s <span class="nb">test</span> @ http://127.0.0.1:8000/atodorov.html
  <span class="m">20</span> threads and <span class="m">1000</span> connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   304.43ms  518.27ms   1.47s    82.69%
    Req/Sec     1.72k     2.45k   17.63k    88.70%
  <span class="m">1016810</span> requests in 29.97s, 34.73GB <span class="nb">read</span>
<span class="nb">  </span>Non-2xx or 3xx responses: 685544
Requests/sec:  33928.41
Transfer/sec:      1.16GB
</pre></div>


<h2>Python Twisted</h2>
<p>The <a href="https://gist.github.com/atodorov/666035d270d97d982cd5">Twisted implementation</a>
performs at little over 1000 reqs/sec with an average TCP port use between 20000 and 30000:</p>
<div class="highlight"><pre>./wrk -c1000 -t20 -d30s http://127.0.0.1:8080 -s scripts/proxy.lua -- http://127.0.0.1:8000/atodorov.html
Running 30s test @ http://127.0.0.1:8080
  20 threads and 1000 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   335.53ms  117.26ms 707.57ms   64.77%
    Req/Sec   104.14     72.19   335.00     55.94%
  40449 requests in 30.02s, 3.67GB read
  Socket errors: connect 0, read 0, write 0, timeout 8542
  Non-2xx or 3xx responses: 5382
Requests/sec:   1347.55
Transfer/sec:    125.12MB
</pre></div>


<h2>Go proxy</h2>
<p>First I've run several 30 seconds tests and performance was around 8000 req/sec
with around 20000 ports used (most of them remain in TIME_WAIT state for a while).
Then I've modified <code>proxy.go</code> to make use of all available CPUs on the system and let
the test run for 5 minutes.</p>
<div class="highlight"><pre><span class="nv">$ </span>./wrk -c1000 -t20 -d300s http://127.0.0.1:9090 -s scripts/proxy.lua -- http://127.0.0.1:8000/atodorov.html
Running 5m <span class="nb">test</span> @ http://127.0.0.1:9090
  <span class="m">20</span> threads and <span class="m">1000</span> connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   137.22ms  437.95ms   4.45s    97.55%
    Req/Sec   669.54    198.52     1.71k    76.40%
  <span class="m">3423108</span> requests in 5.00m, 58.27GB <span class="nb">read</span>
<span class="nb">  </span>Socket errors: connect 0, <span class="nb">read </span>26, write 181, timeout 24268
  Non-2xx or 3xx responses: 2870522
Requests/sec:  11404.19
Transfer/sec:    198.78MB
</pre></div>


<p>Performance peaked at 10000 req/sec. TCP port usage initially rose to around 30000
but rapidly dropped and stayed around 3000. Both <code>webserver.go</code> and <code>proxy.go</code> were
printing the following messages on the console:</p>
<div class="highlight"><pre><span class="nt">2014</span><span class="o">/</span><span class="nt">11</span><span class="o">/</span><span class="nt">18</span> <span class="nt">21</span><span class="nd">:53:06</span> <span class="nt">http</span><span class="o">:</span> <span class="nt">Accept</span> <span class="nt">error</span><span class="o">:</span> <span class="nt">accept</span> <span class="nt">tcp</span> <span class="cp">[</span><span class="p">::</span><span class="cp">]</span><span class="nd">:9090</span><span class="o">:</span> <span class="nt">too</span> <span class="nt">many</span> <span class="nt">open</span> <span class="nt">files</span><span class="o">;</span> <span class="nt">retrying</span> <span class="nt">in</span> <span class="nt">1s</span>
</pre></div>


<h2>Conclusion</h2>
<p>There's no doubt that Go is blazingly fast compared to Python and I'm most likely to use it
further in my experiments. Still I didn't expect a 3x difference in performance from webserver vs. proxy.</p>
<p>Another thing that worries me is the huge number of open TCP ports which then drops and stays
consistent over time and the error messages from both webserver and proxy (maybe per process sockets limit).</p>
<p>At the moment I'm not aware of the internal workings of neither wrk, nor
Go itself, nor the goproxy library to make conclusion if this is a bad thing or expected.
I'm eager to hear what others think in the comments. Thanks!</p>
<h2>Update 2015-01-27</h2>
<p>I have retested with PyPy but on a different system so I'm giving all the test results
on it as well. <code>/proc/cpuinfo</code> says we have 16 x Intel(R) Xeon(R) CPU E5-2450L 0 @ 1.80GHz
CPUs. </p>
<p>Baseline - Go server:</p>
<div class="highlight"><pre><span class="nv">$ </span>./wrk -c1000 -t20 -d30s http://127.0.0.1:8000/atodorov.html
Running 30s <span class="nb">test</span> @ http://127.0.0.1:8000/atodorov.html
  <span class="m">20</span> threads and <span class="m">1000</span> connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    15.57ms   20.38ms 238.93ms   98.11%
    Req/Sec     3.55k     1.32k   15.91k    82.49%
  <span class="m">1980738</span> requests in 30.00s, 174.53GB <span class="nb">read</span>
<span class="nb">  </span>Socket errors: connect 0, <span class="nb">read </span>0, write 0, timeout 602
  Non-2xx or 3xx responses: 60331
Requests/sec:  66022.87
Transfer/sec:      5.82GB
</pre></div>


<p>Go proxy (30 sec):</p>
<div class="highlight"><pre><span class="nv">$ </span>./wrk -c1000 -t20 -d30s http://127.0.0.1:9090 -s scripts/proxy.lua -- http://127.0.0.1:8000/atodorov.html
Running 30s <span class="nb">test</span> @ http://127.0.0.1:9090
  <span class="m">20</span> threads and <span class="m">1000</span> connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    68.93ms  718.98ms  12.60s    99.58%
    Req/Sec     1.61k   784.01     4.83k    62.50%
  <span class="m">942757</span> requests in 30.00s, 32.16GB <span class="nb">read</span>
<span class="nb">  </span>Socket errors: connect 0, <span class="nb">read </span>26, write 0, timeout 3050
  Non-2xx or 3xx responses: 589940
Requests/sec:  31425.47
Transfer/sec:      1.07GB
</pre></div>


<p>Python proxy with <code>Twisted==14.0.2</code> and <code>pypy-2.2.1-2.el7.x86_64</code>:</p>
<div class="highlight"><pre><span class="nv">$ </span>./wrk -c1000 -t20 -d30s http://127.0.0.1:8080 -s scripts/proxy.lua -- http://127.0.0.1:8000/atodorov.html
Running 30s <span class="nb">test</span> @ http://127.0.0.1:8080
  <span class="m">20</span> threads and <span class="m">1000</span> connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   858.75ms    1.47s    6.00s    88.09%
    Req/Sec   146.39    104.83   341.00     54.18%
  <span class="m">85645</span> requests in 30.00s, 853.54MB <span class="nb">read</span>
<span class="nb">  </span>Socket errors: connect 0, <span class="nb">read </span>289, write 0, timeout 3297
  Non-2xx or 3xx responses: 76567
Requests/sec:   2854.45
Transfer/sec:     28.45MB
</pre></div>


<p><strong>Update 2015-01-27-2</strong></p>
<p>Python proxy with <code>Twisted==14.0.2</code> and <code>python-2.7.5-16.el7.x86_64</code>:</p>
<div class="highlight"><pre><span class="nv">$ </span>./wrk -c1000 -t20 -d30s http://127.0.0.1:8080 -s scripts/proxy.lua -- http://127.0.0.1:8000/atodorov.html
Running 30s <span class="nb">test</span> @ http://127.0.0.1:8080
  <span class="m">20</span> threads and <span class="m">1000</span> connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   739.64ms    1.58s   14.22s    96.18%
    Req/Sec    84.43     36.61   157.00     67.79%
  <span class="m">49173</span> requests in 30.01s, 701.77MB <span class="nb">read</span>
<span class="nb">  </span>Socket errors: connect 0, <span class="nb">read </span>240, write 0, timeout 2463
  Non-2xx or 3xx responses: 41683
Requests/sec:   1638.38
Transfer/sec:     23.38MB
</pre></div>


<p>As seen Go proxy is slower than the Go server by factor of 2.
Python proxy is slower by than the Go server by factor of 20.
These results are similar to previous ones so I don't think PyPy
makes any significant difference.</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Wed 19 November 2014
            </p>
<p>There are <a href="http://atodorov.org/blog/2014/11/19/speed-comparison-of-web-proxies-written-in-python-twisted-and-go/#disqus_thread">comments</a>.</p>        </div>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2014/11/18/proxy-support-for-wrk-http-benchmarking-tool/" rel="bookmark" title="Permalink to Proxy Support for wrk HTTP Benchmarking Tool">
                <h2 class="post-title">
                    Proxy Support for wrk HTTP Benchmarking Tool
                </h2>
            </a>
                <p>Few times recently I've seen people using an HTTP benchmarking tool called
<a href="https://github.com/wg/wrk">wrk</a> and decided to give it a try. It is a very cool
instrument but didn't fit my use case perfectly. What I needed is to be able to
redirect the connection through a web proxy and measure how much the proxy
slows down things compared to hitting the web server directly with wrk.
In other words - how fast is the proxy server.</p>
<h2>How does a proxy work</h2>
<p>I've examined the source code of two proxies (one in Python and another one in Go)
and what happens is this:</p>
<ul>
<li>The proxy server starts listening to a TCP port</li>
<li>A client (e.g. the browser) sends the request using an absolute URL (GET http://example.com/about.html)</li>
<li>Instead of connecting directly to the web server behind example.com the client connects to the proxy</li>
<li>The proxy server does connect to example.com directly, reads the response and delivers it back to 
the client.</li>
</ul>
<h2>Proxy in wrk</h2>
<p>Luckily wrk supports the execution of Lua scripts so we can make a 
<a href="https://github.com/wg/wrk/pull/107">simple script</a> like this:</p>
<div class="highlight"><pre><span class="nx">init</span> <span class="o">=</span> <span class="kd">function</span><span class="p">(</span><span class="nx">args</span><span class="p">)</span>
    <span class="nx">target_url</span> <span class="o">=</span> <span class="nx">args</span><span class="cp">[</span><span class="mi">1</span><span class="cp">]</span> <span class="o">--</span> <span class="nx">proxy</span> <span class="nx">needs</span> <span class="nx">absolute</span> <span class="nx">URL</span>
<span class="nx">end</span>

<span class="nx">request</span> <span class="o">=</span> <span class="kd">function</span><span class="p">()</span>
    <span class="k">return</span> <span class="nx">wrk</span><span class="p">.</span><span class="nx">format</span><span class="p">(</span><span class="s2">&quot;GET&quot;</span><span class="p">,</span> <span class="nx">target_url</span><span class="p">)</span>
<span class="nx">end</span>
</pre></div>


<p>Then update your command line to something like this:
    ./wrk [options] http://proxy:port -s proxy.lua -- http://example.com/about.html</p>
<p>This causes wrk to connect to our proxy server but instead issue GET requests for another URL.
Depending on how your proxy works you may need to add the <code>Host: example.com</code> header as well.
Now let's do some testing.</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Tue 18 November 2014
            </p>
<p>There are <a href="http://atodorov.org/blog/2014/11/18/proxy-support-for-wrk-http-benchmarking-tool/#disqus_thread">comments</a>.</p>        </div>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2014/11/11/speeding-up-celery-backends-part-3/" rel="bookmark" title="Permalink to Speeding Up Celery Backends, Part 3">
                <h2 class="post-title">
                    Speeding Up Celery Backends, Part 3
                </h2>
            </a>
                <p>In the second part of this article we've seen 
<a href="/blog/2014/11/07/speeding-up-celery-backends-part-2/">how slow Celery actually is</a>.
Now let's explore what happens inside and see if we can't speed things up.</p>
<p>I've used <a href="http://pycallgraph.slowchop.com/en/latest/">pycallgraph</a> to create
call graph visualizations of my application. It has the nice feature to also show
execution time and use different colors for fast and slow operations.</p>
<p>Full command line is:</p>
<div class="highlight"><pre>pycallgraph -v --stdlib --include ... graphviz -o calls.png -- ./manage.py celery_load_test
</pre></div>


<p>where the <code>--include</code> is used to limit the graph to a particular Python module(s).</p>
<h2>General findings</h2>
<p><img alt="call graph" src="/images/celery/general.png" title="call graph" /></p>
<ul>
<li>The first four calls is where most of the time is spent as seen on the picture. </li>
<li>As it seems most of the slow down comes from Celery itself, not the underlying messaging
transport Kombu (not shown on picture)</li>
<li><code>celery.app.amqp.TaskProducer.publish_task</code> takes half of the execution time of
<code>celery.app.base.Celery.send_task</code></li>
<li><code>celery.app.task.Task.delay</code> directly executes <code>.apply_async</code> and can be skipped if one
rewrites the code.</li>
</ul>
<h2>More findings</h2>
<p>In <code>celery.app.base.Celery.send_task</code> there is this block of code:</p>
<div class="highlight"><pre>349         with self.producer_or_acquire(producer) as P:
350             self.backend.on_task_call(P, task_id)
351             task_id = P.publish_task(
352                 name, args, kwargs, countdown=countdown, eta=eta,
353                 task_id=task_id, expires=expires,
354                 callbacks=maybe_list(link), errbacks=maybe_list(link_error),
355                 reply_to=reply_to or self.oid, **options
356             )
</pre></div>


<p><code>producer</code> is always None because delay() doesn't pass it as argument.
I've tried passing it explicitly to apply_async() as so:</p>
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">djapp.celery</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c"># app = debug_task._get_app() # if not defined in djapp.celery</span>
<span class="n">producer</span> <span class="o">=</span> <span class="n">app</span><span class="o">.</span><span class="n">amqp</span><span class="o">.</span><span class="n">producer_pool</span><span class="o">.</span><span class="n">acquire</span><span class="p">(</span><span class="n">block</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">debug_task</span><span class="o">.</span><span class="n">apply_async</span><span class="p">(</span><span class="n">producer</span><span class="o">=</span><span class="n">producer</span><span class="p">)</span>
</pre></div>


<p>However this doesn't speedup anything. If we replace the above code block like this:</p>
<div class="highlight"><pre>349         with producer as P:
</pre></div>


<p>it blows up on the second iteration because producer and its channel is already None !?!</p>
<p>If you are unfamiliar with the with statement in Python please read
<a href="http://effbot.org/zone/python-with-statement.htm">this article</a>. In short the with statement is
a compact way of writing try/finally. The underlying <code>kombu.messaging.Producer</code> class does a
<code>self.release()</code> on exit of the with statement.</p>
<p>I also tried killing the with statement and using producer directly but with limited success. While
it was not released(was non None) on subsequent iterations the memory usage grew much more and there
wasn't any performance boost.</p>
<h2>Conclusion</h2>
<p>The with statement is used throughout both Celery and Kombu and I'm not at all sure if
there's a mechanism for keep-alive connections. My time constraints are limited and I'll probably
not spend anymore time on this problem soon.</p>
<p>Since my use case involves task producer and consumers on localhost I'll try to workaround the
current limitations by using Kombu directly 
(see <a href="https://gist.github.com/atodorov/2bc1fcd34531ad260ed7">this gist</a>) with a transport that
uses either a UNIX domain socket or a name pipe (FIFO) file.</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Tue 11 November 2014
            </p>
<p>There are <a href="http://atodorov.org/blog/2014/11/11/speeding-up-celery-backends-part-3/#disqus_thread">comments</a>.</p>        </div>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2014/11/07/speeding-up-celery-backends-part-2/" rel="bookmark" title="Permalink to Speeding up Celery Backends, Part 2">
                <h2 class="post-title">
                    Speeding up Celery Backends, Part 2
                </h2>
            </a>
                <p>In the <a href="/blog/2014/11/05/speeding-up-celery-backends/">first part</a> of this
post I looked at a few celery backends and discovered they didn't meet my needs.
Why is the Celery stack slow? How slow is it actually?</p>
<h2>How slow is Celery in practice</h2>
<ul>
<li>Queue: 500`000 msg/sec</li>
<li>Kombu:  14`000 msg/sec</li>
<li>Celery:  2`000 msg/sec</li>
</ul>
<h2>Detailed test description</h2>
<p>There are three main components of the Celery stack: </p>
<ul>
<li>Celery itself</li>
<li>Kombu which handles the transport layer</li>
<li>Python Queue()'s underlying everything</li>
</ul>
<p>Using the <a href="https://gist.github.com/atodorov/2bc1fcd34531ad260ed7">Queue and Kombu tests</a>
run for 1 000 000 messages I got the following results:</p>
<ul>
<li>Raw Python Queue: Msgs per sec: 500`000</li>
<li>Raw Kombu without Celery where <code>kombu/utils/__init__.py:uuid()</code> is set to return 0<ul>
<li>with json serializer: Msgs per sec: 5`988</li>
<li>with pickle serializer: Msgs per sec: 12`820</li>
<li>with the custom mem_serializer from <a href="/blog/2014/11/05/speeding-up-celery-backends/">part 1</a>:
Msgs per sec: 14`492</li>
</ul>
</li>
</ul>
<p><strong>Note:</strong> when the test is executed with 100K messages mem_serializer yielded
25`000 msg/sec then the performance is saturated. I've observed similar behavior 
with raw Python Queue()'s. I saw some cache buffers being managed internally to avoid OOM
exceptions. This is probably the main reason performance becomes saturated over a longer
execution.</p>
<ul>
<li>Using <a href="https://gist.github.com/atodorov/0156cc41491a5e1ff953">celery_load_test.py</a> modified to
loop 1 000 000 times I got 1908.0 tasks created per sec.</li>
</ul>
<p>Another interesting this worth outlining - in the kombu test there are these lines:</p>
<div class="highlight"><pre>with producers[connection].acquire(block=True) as producer:
    for j in range(1000000):
</pre></div>


<p>If we swap them the performance drops down to 3875 msg/sec which is comparable with the
Celery results. Indeed inside Celery there's the same <code>with producer.acquire(block=True)</code>
construct which is executed every time a new task is published. Next I will be looking 
into this to figure out exactly where the slowliness comes from.</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Fri 07 November 2014
            </p>
<p>There are <a href="http://atodorov.org/blog/2014/11/07/speeding-up-celery-backends-part-2/#disqus_thread">comments</a>.</p>        </div>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2014/11/05/speeding-up-celery-backends/" rel="bookmark" title="Permalink to Speeding up Celery Backends, Part 1">
                <h2 class="post-title">
                    Speeding up Celery Backends, Part 1
                </h2>
            </a>
                <p>I'm working on an application which fires a lot of Celery tasks - the more
the better! Unfortunately Celery backends seem to be rather slow :(.
Using the <a href="https://gist.github.com/atodorov/0156cc41491a5e1ff953">celery_load_test.py</a>
command for Django I was able to capture some metrics:</p>
<ul>
<li>Amazon SQS backend: 2 or 3 tasks/sec</li>
<li>Filesystem backend: 2000 - 2500 tasks/sec</li>
<li>Memory backend: around 3000 tasks/sec</li>
</ul>
<p>Not bad but I need in the order of 10000 tasks created per sec!
The other noticeable thing is that memory backend isn't much faster compared to
the filesystem one! NB: all of these backends actually come from the kombu package.</p>
<h2>Why is Celery slow ?</h2>
<p>Using <code>celery_load_test.py</code> together with 
<a href="/blog/2014/11/05/performance-profiling-in-python-with-cprofile/">cProfile</a> I
was able to pin-point some problematic areas:</p>
<ul>
<li>
<p><code>kombu/transports/virtual/__init__.py</code>: class Channel.basic_publish() - does
self.encode_body() into base64 encoded string. Fixed with custom transport backend
I called fastmemory which redefines the body_encoding property:</p>
<div class="highlight"><pre><span class="nd">@cached_property</span>
<span class="k">def</span> <span class="nf">body_encoding</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">None</span>
</pre></div>


</li>
<li>
<p>Celery uses json or pickle (or other) serializers to serialize the data.
While json yields between 2000-3000 tasks/sec, pickle does around 3500 tasks/sec.
Replacing with a custom serializer which just returns
the objects (since we read/write from/to memory) yields about 4000 tasks/sec tops:</p>
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">kombu.serialization</span> <span class="kn">import</span> <span class="n">register</span>

<span class="k">def</span> <span class="nf">loads</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">s</span>

<span class="k">def</span> <span class="nf">dumps</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">s</span>

<span class="n">register</span><span class="p">(</span><span class="s">&#39;mem_serializer&#39;</span><span class="p">,</span> <span class="n">dumps</span><span class="p">,</span> <span class="n">loads</span><span class="p">,</span>
        <span class="n">content_type</span><span class="o">=</span><span class="s">&#39;application/x-memory&#39;</span><span class="p">,</span>
        <span class="n">content_encoding</span><span class="o">=</span><span class="s">&#39;binary&#39;</span><span class="p">)</span>
</pre></div>


</li>
<li>
<p><code>kombu/utils/__init__.py</code>: def uuid() - generates random unique identifiers
which is a slow operation. Replacing it with <code>return "00000000"</code> boosts performance
to 7000 tasks/sec.</p>
</li>
</ul>
<p>It's clear that a constant UUID is not of any practical use but serves well to illustrate
how much does this function affect performance. </p>
<p><strong>Note:</strong>
Subsequent executions of <code>celery_load_test</code> seem to report degraded performance even with
the most optimized transport backend. I'm not sure why is this. One possibility is the random
UUID usage in other parts of the Celery/Kombu stack which drains entropy on the system and
generating more random numbers becomes slower. If you know better please tell me!</p>
<p>I will be looking for a better understanding
of these IDs in Celery and hope to be able to produce a faster uuid() function. Then I'll be
exploring the transport stack even more in order to reach the goal of 10000 tasks/sec.
If you have any suggestions or pointers please share them in the comments.</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Wed 05 November 2014
            </p>
<p>There are <a href="http://atodorov.org/blog/2014/11/05/speeding-up-celery-backends/#disqus_thread">comments</a>.</p>        </div>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2014/11/05/performance-profiling-in-python-with-cprofile/" rel="bookmark" title="Permalink to Performance Profiling in Python with cProfile">
                <h2 class="post-title">
                    Performance Profiling in Python with cProfile
                </h2>
            </a>
                <p>This is a quick reference on profiling Python applications with
<a href="https://docs.python.org/2/library/profile.html#module-cProfile">cProfile</a>:</p>
<div class="highlight"><pre><span class="nv">$ </span>python -m cProfile -s <span class="nb">time </span>application.py
</pre></div>


<p>The output is sorted by execution time <code>-s time</code></p>
<div class="highlight"><pre>     <span class="mi">9072842</span> <span class="kd">function</span> <span class="nx">calls</span> <span class="p">(</span><span class="mi">8882140</span> <span class="nx">primitive</span> <span class="nx">calls</span><span class="p">)</span> <span class="k">in</span> <span class="mf">9.830</span> <span class="nx">CPU</span> <span class="nx">seconds</span>

   <span class="nx">Ordered</span> <span class="nx">by</span><span class="o">:</span> <span class="nx">internal</span> <span class="nx">time</span>

   <span class="nx">ncalls</span>  <span class="nx">tottime</span>  <span class="nx">percall</span>  <span class="nx">cumtime</span>  <span class="nx">percall</span> <span class="nx">filename</span><span class="o">:</span><span class="nx">lineno</span><span class="p">(</span><span class="kd">function</span><span class="p">)</span>
    <span class="mi">61868</span>    <span class="mf">0.575</span>    <span class="mf">0.000</span>    <span class="mf">0.861</span>    <span class="mf">0.000</span> <span class="kr">abstract</span><span class="p">.</span><span class="nx">py</span><span class="o">:</span><span class="mi">28</span><span class="p">(</span><span class="nx">__init__</span><span class="p">)</span>
    <span class="mi">41250</span>    <span class="mf">0.527</span>    <span class="mf">0.000</span>    <span class="mf">0.660</span>    <span class="mf">0.000</span> <span class="nx">uuid</span><span class="p">.</span><span class="nx">py</span><span class="o">:</span><span class="mi">101</span><span class="p">(</span><span class="nx">__init__</span><span class="p">)</span>
    <span class="mi">61863</span>    <span class="mf">0.405</span>    <span class="mf">0.000</span>    <span class="mf">1.054</span>    <span class="mf">0.000</span> <span class="kr">abstract</span><span class="p">.</span><span class="nx">py</span><span class="o">:</span><span class="mi">40</span><span class="p">(</span><span class="nx">as_dict</span><span class="p">)</span>
    <span class="mi">41243</span>    <span class="mf">0.343</span>    <span class="mf">0.000</span>    <span class="mf">1.131</span>    <span class="mf">0.000</span> <span class="nx">__init__</span><span class="p">.</span><span class="nx">py</span><span class="o">:</span><span class="mi">143</span><span class="p">(</span><span class="nx">uuid4</span><span class="p">)</span>
   <span class="mi">577388</span>    <span class="mf">0.338</span>    <span class="mf">0.000</span>    <span class="mf">0.649</span>    <span class="mf">0.000</span> <span class="kr">abstract</span><span class="p">.</span><span class="nx">py</span><span class="o">:</span><span class="mi">46</span><span class="p">(</span><span class="o">&lt;</span><span class="nx">genexpr</span><span class="o">&gt;</span><span class="p">)</span>
    <span class="mi">20622</span>    <span class="mf">0.289</span>    <span class="mf">0.000</span>    <span class="mf">8.824</span>    <span class="mf">0.000</span> <span class="nx">base</span><span class="p">.</span><span class="nx">py</span><span class="o">:</span><span class="mi">331</span><span class="p">(</span><span class="nx">send_task</span><span class="p">)</span>
    <span class="mi">61907</span>    <span class="mf">0.232</span>    <span class="mf">0.000</span>    <span class="mf">0.477</span>    <span class="mf">0.000</span> <span class="nx">datastructures</span><span class="p">.</span><span class="nx">py</span><span class="o">:</span><span class="mi">467</span><span class="p">(</span><span class="nx">__getitem__</span><span class="p">)</span>
    <span class="mi">20622</span>    <span class="mf">0.225</span>    <span class="mf">0.000</span>    <span class="mf">9.298</span>    <span class="mf">0.000</span> <span class="nx">task</span><span class="p">.</span><span class="nx">py</span><span class="o">:</span><span class="mi">455</span><span class="p">(</span><span class="nx">apply_async</span><span class="p">)</span>
    <span class="mi">61863</span>    <span class="mf">0.218</span>    <span class="mf">0.000</span>    <span class="mf">2.502</span>    <span class="mf">0.000</span> <span class="kr">abstract</span><span class="p">.</span><span class="nx">py</span><span class="o">:</span><span class="mi">52</span><span class="p">(</span><span class="nx">__copy__</span><span class="p">)</span>
    <span class="mi">20621</span>    <span class="mf">0.208</span>    <span class="mf">0.000</span>    <span class="mf">4.766</span>    <span class="mf">0.000</span> <span class="nx">amqp</span><span class="p">.</span><span class="nx">py</span><span class="o">:</span><span class="mi">208</span><span class="p">(</span><span class="nx">publish_task</span><span class="p">)</span>
   <span class="mi">462640</span>    <span class="mf">0.193</span>    <span class="mf">0.000</span>    <span class="mf">0.247</span>    <span class="mf">0.000</span> <span class="p">{</span><span class="nx">isinstance</span><span class="p">}</span>
   <span class="mi">515525</span>    <span class="mf">0.162</span>    <span class="mf">0.000</span>    <span class="mf">0.193</span>    <span class="mf">0.000</span> <span class="kr">abstract</span><span class="p">.</span><span class="nx">py</span><span class="o">:</span><span class="mi">41</span><span class="p">(</span><span class="nx">f</span><span class="p">)</span>
    <span class="mi">41246</span>    <span class="mf">0.153</span>    <span class="mf">0.000</span>    <span class="mf">0.633</span>    <span class="mf">0.000</span> <span class="nx">entity</span><span class="p">.</span><span class="nx">py</span><span class="o">:</span><span class="mi">143</span><span class="p">(</span><span class="nx">__init__</span><span class="p">)</span>
</pre></div>


<p>In the example above (actual application) first line is kombu's
<code>abstract.py: class Object(object).__init__()</code>
and the second one is Python's
<code>uuid.py: class UUID().__init__()</code>.</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Wed 05 November 2014
            </p>
<p>There are <a href="http://atodorov.org/blog/2014/11/05/performance-profiling-in-python-with-cprofile/#disqus_thread">comments</a>.</p>        </div>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2014/07/18/snake-is-no-longer-needed-to-run-installation-tests-in-beaker/" rel="bookmark" title="Permalink to SNAKE is no Longer Needed to Run Installation Tests in Beaker">
                <h2 class="post-title">
                    SNAKE is no Longer Needed to Run Installation Tests in Beaker
                </h2>
            </a>
                <p>This is a quick status update for one of the pieces of
<a href="/blog/2013/11/19/open-source-quality-assurance-infrastructure-for-fedora-qa/">Fedora QA infrastructure</a>
and mostly a self-note.</p>
<p>Previously to control the kickstart configuration used during installation in Beaker one
had to either modify the job XML in Beaker or use SNAKE (<code>bkr workflow-snake</code>) to render
a kickstart configuration from a Python template.</p>
<p>SNAKE presented challenges when deploying and using
<a href="https://beaker.fedoraproject.org">beaker.fedoraproject.org</a> and is
virtually unmaintained.</p>
<p>I present the new <code>bkr workflow-installer-test</code> which uses Jinja2 templates to
generate a kickstart configuration when provisioning the system. This is already
available in beaker-client-0.17.1.</p>
<p>The templates make use of all Jinja2 features (as far as I can tell) so you can create
very complex ones. You can even include snippets from one template into another if required.
The standard context that is passed to the template is:</p>
<ul>
<li><strong>DISTRO</strong> - if specified, the distro name</li>
<li><strong>FAMILY</strong> - as returned by Beaker server, e.g. <em>RedHatEnterpriseLinux6</em></li>
<li><strong>OS_MAJOR</strong> and <strong>OS_MINOR</strong> - also taken from Beaker server. e.g. OS_MAJOR=6 and OS_MINOR=5 for RHEL 6.5</li>
<li><strong>VARIANT</strong> - if specified</li>
<li><strong>ARCH</strong> - CPU architecture like x86_64</li>
<li>any parameters passed to the test job with <code>--taskparam</code>. They are processed last and can override previous values.</li>
</ul>
<p>Installation related tests at <a href="https://bitbucket.org/fedoraqa/fedora-beaker-tests">fedora-beaker-tests</a>
have been updated with a <code>ks.cfg.tmpl</code> templates to use with this new workflow.</p>
<p>This workflow also has the ability to return boot arguments for the installer if needed. 
If any, they should be defined in a <code>{% block kernel_options %}{% endblock %}</code>
block inside the template. A simpler variant is to define a comment line that stars with
<em>## kernel_options:</em></p>
<p>There are still a few issues which need to be fixed before beaker.fedoraproject.org
can be used by the general public though. I will be writing another post about that
so stay tuned.</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Fri 18 July 2014
            </p>
<p>There are <a href="http://atodorov.org/blog/2014/07/18/snake-is-no-longer-needed-to-run-installation-tests-in-beaker/#disqus_thread">comments</a>.</p>        </div>

    <hr>
    <!-- Pager -->
    <ul class="pager">
        <li class="next">
                <a href="http://atodorov.org/blog/categories/qa/index4.html">Older Posts &rarr;</a>
                <a href="http://atodorov.org/blog/categories/qa/index2.html"> &larr; Newest Posts</a>
        </li>
    </ul>
    Page 3 / 5
    <hr>
            </div>
        </div>
    </div>

    <hr>

    <!-- Footer -->
    <footer>
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <ul class="list-inline text-center">
                            <li>
                                <a href="https://twitter.com/atodorov_">
                                    <span class="fa-stack fa-lg">
                                        <i class="fa fa-circle fa-stack-2x"></i>
                                        <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                            <li>
                                <a href="https://github.com/atodorov">
                                    <span class="fa-stack fa-lg">
                                        <i class="fa fa-circle fa-stack-2x"></i>
                                        <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                            <li>
                                <a href="https://bg.linkedin.com/in/alextodorov">
                                    <span class="fa-stack fa-lg">
                                        <i class="fa fa-circle fa-stack-2x"></i>
                                        <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                            <li>
                                <a href="http://feeds.feedburner.com/atodorov">
                                    <span class="fa-stack fa-lg">
                                        <i class="fa fa-circle fa-stack-2x"></i>
                                        <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                            <li>
                                <a href="https://www.youtube.com/playlist?list=PLFjlI7p-h1hxBP3cIjEqePSeoBDHud5Db">
                                    <span class="fa-stack fa-lg">
                                        <i class="fa fa-circle fa-stack-2x"></i>
                                        <i class="fa fa-youtube fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                            <li>
                                <a href="http://amzn.to/1ivu2q4">
                                    <span class="fa-stack fa-lg">
                                        <i class="fa fa-circle fa-stack-2x"></i>
                                        <i class="fa fa-amazon fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                            <li>
                                <a href="http://mrsenko.com/?utm_source=atodorov.org&utm_medium=blog&utm_campaign=social_icon">
                                    <span class="fa-stack fa-lg">
                                        <i class="fa fa-circle fa-stack-2x"></i>
                                        <i class="fa fa-user-secret fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                    </ul>
<section>
    <p>
        I am a Senior QA contractor at Red Hat responsible for finding over
        <a href="/blog/2014/02/19/7-years-1400-bugs-red-hat-qa/">1600 bugs</a>,
        a general purpose open source developer, Red Hat Certified professional,
        cloud hacker and an entrepreneur! My latest start-up is
        <a href="http://mrsenko.com/?utm_source=atodorov.org&utm_medium=blog&utm_campaign=footer">Mr. Senko</a>!
    </p>
    <p>
        I am living in the <a href="http://planet.sofiavalley.com">Sofia Valley</a>
        which is emerging as a busy place for start-up founders and tech enthusiasts
        in Eastern Europe! You can find more about me <a href="/blog/2013/01/25/about-me/">here</a>.
    </p>
    <p>
        <small>
            <em>
                Some of the links contained within this site have my referral id (e.g.,
                <a target="_blank" href="http://www.amazon.com/ref=as_li_ss_tl?_encoding=UTF8&camp=1789&creative=390957&linkCode=ur2&tag=atodorovorg-20&linkId=L6Q34XAXQS5RDMOY">Amazon</a><img src="https://ir-na.amazon-adsystem.com/e/ir?t=atodorovorg-20&l=ur2&o=1" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" />),
                which provides me with a small commission for each sale. Thank you for your support.
            </em>
        </small>
    </p>
</section>

<form action="http://google.com/search" method="get" style="width:300px;margin:0 auto;">
    <fieldset role="search">
        <input type="hidden" name="sitesearch" value="http://atodorov.org" />
        <input class="search" type="text" name="q" placeholder="Search" style="width:100%"/>
    </fieldset>
</form>

<p class="copyright text-muted">
    <a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/deed.en_US">CC-BY-SA</a> &amp;
    <a rel="license" href="http://opensource.org/licenses/MIT">MIT</a>
    2011-2016 &diams; Alexander Todorov &diams;
    <a href="http://planet.sofiavalley.com">SofiaValley Blog</a>
</p>

<script type='text/javascript'>
window.__lo_site_id = 55936;
    (function() {
        var wa = document.createElement('script'); wa.type = 'text/javascript'; wa.async = true;
        wa.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://cdn') + '.luckyorange.com/w.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(wa, s);
      })();
</script>
                </div>
            </div>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="http://atodorov.org/theme/js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="http://atodorov.org/theme/js/bootstrap.min.js"></script>


    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37979549-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>
<script type="text/javascript">
    var disqus_shortname = 'atodorov';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
</body>

</html>