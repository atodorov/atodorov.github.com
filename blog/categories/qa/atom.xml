<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: QA | atodorov.org - you can logoff, but you can never leave]]></title>
  <link href="http://atodorov.org/blog/categories/qa/atom.xml" rel="self"/>
  <link href="http://atodorov.org/"/>
  <updated>2015-10-15T15:21:17+03:00</updated>
  <id>http://atodorov.org/</id>
  <author>
    <name><![CDATA[Alexander Todorov]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Anaconda &amp; coverage.py - Pt.2 - Details]]></title>
    <link href="http://atodorov.org/blog/2015/10/15/anaconda-coverage.py-details/"/>
    <updated>2015-10-15T14:15:00+03:00</updated>
    <id>http://atodorov.org/blog/2015/10/15/anaconda-coverage.py-details</id>
    <content type="html"><![CDATA[<p>My <a href="/blog/2015/10/14/anaconda-coverage.py-introduction/">previous post</a>
was an introduction to testing installation related components. Now I'm going to
talk more about anaconda and how it is tested.</p>

<p>There are two primary ways to test anaconda. You can execute <code>make check</code> in the
source directory which will trigger the package test suite. The other possibility
is to perform an actual installation, on bare meta or virtual machine, using the
<a href="https://kojipkgs.fedoraproject.org/mash/">latest Rawhide snapshots</a> which also
include the latest anaconda. For both of these methods we can collect code
coverage information. In live installation mode coverage is enabled via the
<code>inst.debug</code> boot argument. Fedora 23 and earlier use <code>debug=1</code> but that
can lead to <a href="https://github.com/rhinstaller/anaconda/pull/291">problems</a>
sometimes.</p>

<h2>Kickstart Testing</h2>

<p><a href="https://github.com/rhinstaller/pykickstart/blob/master/docs/kickstart-docs.rst">Kickstart</a>
is a method of automating the installation of Fedora by supplying the necessary
configuration into a text file and pointing the installer at this file. There is
the directory <code>tests/kickstart_tests</code>, inside the anaconda source, where each
test is a kickstart file and a shell script. The test runner provisions a virtual
machine using boot.iso and the kickstart file. A shell script then verifies
installation was as expected and copies files of interest to the host system.
Kickstart files are also the basis for testing Fedora installations in
<a href="https://beaker.fedoraproject.org/bkr/jobs/">Beaker</a>.</p>

<p>Naturally some of these in-package kickstart tests are the same as
<a href="https://bitbucket.org/fedoraqa/fedora-beaker-tests/">out-of-band kickstart tests</a>.
Hint: there are more available but not yet public.</p>

<p>The question which I don't have an answer for right now is
"Can we remove some of the duplicates and how this affects devel and QE teams" ?
The pros of in-package testing are that it is faster compared to Beaker. The cons
are that you're not testing the real distro (every snapshot is a possible final
release to the users).</p>

<h2>Dogtail</h2>

<p><a href="https://fedorahosted.org/dogtail/">Dogtail</a> uses accessibility technologies to
communicate with desktop applications. It is written in Python and can be used
as GUI test automation framework. Long time ago I've proposed support for Dogtail
in anaconda which was rejected, then couple of years later it was accepted and
later removed from the code again.</p>

<p>Anaconda has in-package Dogtail tests (<code>tests/gui/</code>). They work by attaching
a second disk image with the test suite to a VM running a LiveCD. Anaconda is
started on the LiveCD and an attempt to install Fedora on disk 1 is made.
Everything is driven by the Dogtail scripts. There are only a few of these
tests available and they are currently disabled.
Red Hat QE has also created another method for running Dogtail tests in anaconda
using an updates.img with the previous functionality.</p>

<p>Even if there are some duplicate tests I'm not convinced we have to drop the
<code>tests/gui/</code> directory from the code because
the framework used to drive the graphical interface of anaconda appears to be very
well written. The code is clean and easy to follow.
Also I don't have metrics of how much these two methods differ or how much they cover
in their testing. IMO they are pretty close and before we can find a way to
reliably execute them on a regular basis there isn't much to be done here.
One idea is to use the <code>--dirinstall</code> or <code>--image</code> options and skip the
LiveCD part entirely.</p>

<h2>How Much is Tested</h2>

<p><code>make ci</code> covers 10% of the entire code base for anaconda. Mind you that
<code>tests/storage</code> and <code>tests/gui</code> are currently disabled.
See <a href="https://github.com/rhinstaller/anaconda/pull/346">PR #346</a>,
<a href="https://github.com/rhinstaller/anaconda/pull/327">PR #327</a> and
<a href="https://github.com/rhinstaller/anaconda/pull/319">PR #319</a>!
There is definitely room for improvement.</p>

<p>On the other hand live installation testing is much
better. Text mode covers around 25% while graphical installations around 40%.
Text and graphical combined cover 50% though. These numbers will drop quite a bit
once anaconda learns to
<a href="https://github.com/rhinstaller/anaconda/pull/397">include all possible files</a>
in its report but it is a good estimate.</p>

<p>The important questions to ask here are:</p>

<ul>
<li>How much can PyUnit tests cover in anaconda?</li>
<li>How much can kickstart tests cover ?</li>
<li>Have we reached a threshold in any of the two primary methods for testing ?</li>
<li>Does UI automation (with Dogtail) improve anything ?</li>
<li>When testing a particular feature (say user creation) how different is the
code execution path between manual (GUI) testing, kickstart and unit testing ?
If not so different can we invest in unit tests instead of higher level tests then ?</li>
<li>How different is the code execution path between different tests (manual or kickstart) ?
In other words how much value are we getting from testing for the resources we're putting in ?</li>
</ul>


<p>In my next post I will talk more about these questions and some rudimentary
analysis against coverage data from the various test methods and test cases!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Anaconda &amp; coverage.py - Pt.1 - Introduction]]></title>
    <link href="http://atodorov.org/blog/2015/10/14/anaconda-coverage.py-introduction/"/>
    <updated>2015-10-14T13:44:00+03:00</updated>
    <id>http://atodorov.org/blog/2015/10/14/anaconda-coverage.py-introduction</id>
    <content type="html"><![CDATA[<p>Since early 2015 I've been working on testing installation related
components in Rawhide. I'm interested in the code produced by the
<a href="https://github.com/rhinstaller/">Red Hat Installer Engineering Team</a> and in
particular in <em>anaconda</em>, <em>blivet</em>, <em>pyparted</em> and <em>pykickstart</em>. The goal of
this effort is to improve the overall testing of these components and also
have Red Hat QE contribute some of our knowledge back to the community. The benefit
of course will be better software for everyone. In the next
several posts I'll summarize what has been done so far and what's to be expected
in the future.</p>

<h2>Test Documentation Matters</h2>

<p>Do you want others to contribute tests? I certainly do! When I started looking
at the code it was obviously clear there was no documentation related to testing.
Everyone needs to know how to write and execute these tests! Currently we have
basic README files describing how to install necessary dependencies for development
and test execution, how to execute the tests (and what can be tested) and most
importantly what is the test architecture. There is description of how the file
structure is organized and which are the base classes to inherit from when adding
new tests. Most of the times each component goes through a <em>pylint</em> check and
a standard PyUnit test suite.</p>

<p>Test documentation is usually in a <code>tests/README</code> file. For example:</p>

<ul>
<li><a href="https://github.com/rhinstaller/anaconda/blob/master/tests/README.rst">anaconda</a></li>
<li><a href="https://github.com/rhinstaller/blivet/blob/master/tests/README.rst">blivet</a></li>
<li><a href="https://github.com/rhinstaller/pykickstart/blob/master/tests/README.rst">pykickstart</a></li>
<li><a href="https://github.com/rhinstaller/pyparted/blob/master/tests/README.rst">pyparted</a></li>
</ul>


<p>I've tried to explain as much as possible without bloating the files and going into
unnecessary details. If you spot something missing please send a pull request.</p>

<h2>Continuous Integration</h2>

<p>This has been largely an effort driven by Chris Lumens from the devel team.
All the components I'm interested in are tested regularly in a CI environment.
There is a <code>make ci</code> Makefile target for those of you interested in what exactly
gets executed.</p>

<h2>Test Coverage</h2>

<p>In order to <strong>improve</strong> something you need to know where you stand. We'll I didn't.
That's why the first step was to integrate the
<a href="https://bitbucket.org/ned/coveragepy">coverage.py</a> tool with all of these components.</p>

<p>With the exception of blivet (written in C) all of the other
components integrate well with coverage.py and produce good statistics. pykickstart is
the champ here with 90% coverage, while anaconda is somewhere between 10% and 50%.
Full test coverage measurement for anaconda isn't straight forward and will be the
subject of my next post. For the C based code we have to hook up with
<a href="https://gcc.gnu.org/onlinedocs/gcc/Gcov.html">Gcov</a> which shouldn't be too difficult.</p>

<p>At the moment there are several open pull requests to integrate the coverage test
targets with <code>make ci</code> and also report the results in human readable form. I will be
collecting these for historical references.</p>

<h2>Tools</h2>

<p>I've created some basic text-mode
<a href="https://github.com/atodorov/coverage-tools">coverage-tools</a> to help me combine and
compare data from different executions. These are only the start of it and I'm expanding
them as my needs for reporting and analytics evolve. I'm also looking into
<a href="/blog/2015/07/27/call-for-ideas-graphical-test-coverage-reports/">more detailed coverage reports</a>
but I don't have enough data and use cases to work on this front at the moment.</p>

<p>Some ideas currently in mind:</p>

<ul>
<li>map code changes (git commits) to existing test coverage to get a feeling where to
invest in more testing;</li>
<li>map bugs to code areas and to existing test coverage to see if we aren't
missing tests in areas where the bugs are happening;</li>
</ul>


<h2>Bugs</h2>

<p>coverage.py is a very nice tool indeed but I guess most people use it in a very
limited way. Shortly after I started working with it I've found several places which
need improvements. These have to do with combining and reporting on multiple files.</p>

<p>Some of the interesting issues I've found and still open are:</p>

<ul>
<li><a href="https://bitbucket.org/ned/coveragepy/pull-requests/63/">PR #63 - New option --dont-remove when combining coverage data</a></li>
<li><a href="https://bitbucket.org/ned/coveragepy/issues/425">#425 - source parameter not including files which are explicitly specified</a></li>
<li><a href="https://bitbucket.org/ned/coveragepy/issues/426">#426 - Difference between coverage results with source specifies full dir instead of module name</a></li>
</ul>


<p>In my next post I will talk about anaconda code coverage and what I want to do with it.
In the mean time please use the comments to share your feedback.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Unit Testing Example - Bad Stub Design in DNF]]></title>
    <link href="http://atodorov.org/blog/2015/09/25/unit-testing-bad-stub-design-in-dnf/"/>
    <updated>2015-09-25T11:20:00+03:00</updated>
    <id>http://atodorov.org/blog/2015/09/25/unit-testing-bad-stub-design-in-dnf</id>
    <content type="html"><![CDATA[<p>In software testing, usually unit testing, test stubs are programs that simulate
the behaviors of external dependencies that a module undergoing the test depends
on. Test stubs provide canned answers to calls made during the test.</p>

<p>I've discovered an improperly written stub method in one of
<a href="http://dnf.baseurl.org/">DNF</a>'s tests:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>tests/test_download.py </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">class</span> <span class="nc">DownloadCommandTest</span><span class="p">(</span><span class="n">unittest</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="k">def</span> <span class="nf">setUp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">stub_fn</span><span class="p">(</span><span class="n">pkg_spec</span><span class="p">):</span>
</span><span class='line'>        <span class="k">if</span> <span class="s">&#39;.src.rpm&#39;</span> <span class="ow">in</span> <span class="n">pkg_spec</span><span class="p">:</span>
</span><span class='line'>            <span class="k">return</span> <span class="n">Query</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">sourcerpm</span><span class="o">=</span><span class="n">pkg_spec</span><span class="p">)</span>
</span><span class='line'>        <span class="k">else</span><span class="p">:</span>
</span><span class='line'>            <span class="n">q</span> <span class="o">=</span> <span class="n">Query</span><span class="o">.</span><span class="n">latest</span><span class="p">()</span>
</span><span class='line'>            <span class="k">return</span> <span class="p">[</span><span class="n">pkg</span> <span class="k">for</span> <span class="n">pkg</span> <span class="ow">in</span> <span class="n">q</span> <span class="k">if</span> <span class="n">pkg_spec</span> <span class="o">==</span> <span class="n">pkg</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">cli</span> <span class="o">=</span> <span class="n">mock</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">()</span>
</span><span class='line'>    <span class="bp">self</span><span class="o">.</span><span class="n">cmd</span> <span class="o">=</span> <span class="n">download</span><span class="o">.</span><span class="n">DownloadCommand</span><span class="p">(</span><span class="n">cli</span><span class="p">)</span>
</span><span class='line'>    <span class="bp">self</span><span class="o">.</span><span class="n">cmd</span><span class="o">.</span><span class="n">cli</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">repos</span> <span class="o">=</span> <span class="n">dnf</span><span class="o">.</span><span class="n">repodict</span><span class="o">.</span><span class="n">RepoDict</span><span class="p">()</span>
</span><span class='line'>
</span><span class='line'>    <span class="bp">self</span><span class="o">.</span><span class="n">cmd</span><span class="o">.</span><span class="n">_get_query</span> <span class="o">=</span> <span class="n">stub_fn</span>
</span><span class='line'>    <span class="bp">self</span><span class="o">.</span><span class="n">cmd</span><span class="o">.</span><span class="n">_get_query_source</span> <span class="o">=</span> <span class="n">stub_fn</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>The replaced methods look like this:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>plugins/download.py </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="k">def</span> <span class="nf">_get_query</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pkg_spec</span><span class="p">):</span>
</span><span class='line'>    <span class="sd">&quot;&quot;&quot;Return a query to match a pkg_spec.&quot;&quot;&quot;</span>
</span><span class='line'>    <span class="n">subj</span> <span class="o">=</span> <span class="n">dnf</span><span class="o">.</span><span class="n">subject</span><span class="o">.</span><span class="n">Subject</span><span class="p">(</span><span class="n">pkg_spec</span><span class="p">)</span>
</span><span class='line'>    <span class="n">q</span> <span class="o">=</span> <span class="n">subj</span><span class="o">.</span><span class="n">get_best_query</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">sack</span><span class="p">)</span>
</span><span class='line'>    <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">available</span><span class="p">()</span>
</span><span class='line'>    <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">latest</span><span class="p">()</span>
</span><span class='line'>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">run</span><span class="p">())</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span class='line'>        <span class="n">msg</span> <span class="o">=</span> <span class="n">_</span><span class="p">(</span><span class="s">&quot;No package &quot;</span> <span class="o">+</span> <span class="n">pkg_spec</span> <span class="o">+</span> <span class="s">&quot; available.&quot;</span><span class="p">)</span>
</span><span class='line'>        <span class="k">raise</span> <span class="n">dnf</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">PackageNotFoundError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">q</span>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">_get_query_source</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pkg_spec</span><span class="p">):</span>
</span><span class='line'>    <span class="sd">&quot;&quot;&quot;&quot;Return a query to match a source rpm file name.&quot;&quot;&quot;</span>
</span><span class='line'>    <span class="n">pkg_spec</span> <span class="o">=</span> <span class="n">pkg_spec</span><span class="p">[:</span><span class="o">-</span><span class="mi">4</span><span class="p">]</span>  <span class="c"># skip the .rpm</span>
</span><span class='line'>    <span class="n">nevra</span> <span class="o">=</span> <span class="n">hawkey</span><span class="o">.</span><span class="n">split_nevra</span><span class="p">(</span><span class="n">pkg_spec</span><span class="p">)</span>
</span><span class='line'>    <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">sack</span><span class="o">.</span><span class="n">query</span><span class="p">()</span>
</span><span class='line'>    <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">available</span><span class="p">()</span>
</span><span class='line'>    <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">latest</span><span class="p">()</span>
</span><span class='line'>    <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">nevra</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="n">nevra</span><span class="o">.</span><span class="n">version</span><span class="p">,</span>
</span><span class='line'>                 <span class="n">release</span><span class="o">=</span><span class="n">nevra</span><span class="o">.</span><span class="n">release</span><span class="p">,</span> <span class="n">arch</span><span class="o">=</span><span class="n">nevra</span><span class="o">.</span><span class="n">arch</span><span class="p">)</span>
</span><span class='line'>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">run</span><span class="p">())</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span class='line'>        <span class="n">msg</span> <span class="o">=</span> <span class="n">_</span><span class="p">(</span><span class="s">&quot;No package &quot;</span> <span class="o">+</span> <span class="n">pkg_spec</span> <span class="o">+</span> <span class="s">&quot; available.&quot;</span><span class="p">)</span>
</span><span class='line'>        <span class="k">raise</span> <span class="n">dnf</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">PackageNotFoundError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">q</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>As seen here <em>stub_fn</em> replaces the <em>_get_query</em> methods from the class under
test. At the time of writing this has probably seemed like a good idea to
speed up writing the tests.</p>

<p>The trouble is we should be replacing the external dependencies of <em>_get_query</em>
(other parts of DNF essentially) and not methods from <em>DownloadCommand</em>. To
understand why this is a bad idea check
<a href="https://github.com/rpm-software-management/dnf-plugins-core/pull/113">PR #113</a>,
which directly modifies <em>_get_query</em>. There's no way to test this patch
with the current state of the test.</p>

<p>So I took a few days to experiment and update the current test stubs. The
result is
<a href="https://github.com/rpm-software-management/dnf-plugins-core/pull/118">PR #118</a>.
The important bits are the <em>SackStub</em> and <em>SubjectStub</em> classes which hold
information about the available RPM packages on the system. The rest are cosmetics
to fit around the way the query objects are used (q.available(), q.latest(), q.filter()).
The proposed design correctly overrides the external dependencies on
<em>dnf.subject.Subject</em> and <em>self.base.sack</em> which are initialized before our
plugin is loaded by DNF.</p>

<p>I must say this is the first error of this kind I've seen in my QA practice so far.
I have no idea if this was a minor oversight or something which happens more frequently
in open source projects but it's a great example nevertheless.</p>

<p>For those of you who'd like to get started on unit testing I can recommend the book
<a href="http://www.amazon.com/gp/product/1933988274/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=1933988274&linkCode=as2&tag=atodorovorg-20">The Art of Unit Testing: With Examples in .Net</a><img src="http://www.assoc-amazon.com/e/ir?t=atodorovorg-20&l=as2&o=1&a=1933988274" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" />
by Roy Osherove!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[4000+ bugs in Fedora - checksec failures]]></title>
    <link href="http://atodorov.org/blog/2015/09/16/4000-bugs-in-fedora-checksec-failures/"/>
    <updated>2015-09-16T17:03:00+03:00</updated>
    <id>http://atodorov.org/blog/2015/09/16/4000-bugs-in-fedora-checksec-failures</id>
    <content type="html"><![CDATA[<p>In the last week I've been trying to figure out how many packages
conform to the new
<a href="https://fedoraproject.org/wiki/Changes/Harden_All_Packages">Harden All Packages</a>
policy in Fedora!</p>

<p>From 46884 RPMs, 17385 are 'x86_64' meaning they may contain ELF objects.
From them 4489 are reported as failed <code>checksec</code>.</p>

<p>What you should see as the output from <code>checksec is</code></p>

<pre><code>Full RELRO      Canary found      NX enabled    PIE enabled     No RPATH   No RUNPATH
Full RELRO      Canary found      NX enabled    DSO             No RPATH   No RUNPATH
</code></pre>

<p>The first line is for binaries, the second one for libraries b/c
DSOs on x86_64 are always position-independent. Some RPATHs are acceptable,
e.g. <code>%{_libdir}/foo/</code> and I've tried to exclude them unless
other offenses are found. The script which does this is
<a href="https://github.com/atodorov/fedora-scripts/blob/master/checksec-collect">checksec-collect</a>.</p>

<p>Most often I'm seeing <em>Partial RELRO</em>, <em>No canary found</em> and <em>No PIE</em> errors.
Since all packages potentially process untrusted input, it makes sense for all of them
to be hardened and enhance the security of Fedora. That's why all of these errors
should be considered valid bugs.</p>

<h2>Attn package maintainers</h2>

<p>Please see if your package is in the list and try to fix it or let me know
why it should be excluded, for example it's a boot loader and doesn't function
properly with hardening enabled. The full list is available at
<a href="https://github.com/atodorov/fedora-scripts/blob/master/checksec.log">GitHub</a>.</p>

<p>For more information about the different protection mechanisms see the following
links:</p>

<ul>
<li><a href="http://tk-blog.blogspot.bg/2009/02/relro-not-so-well-known-memory.html">Partial vs Full RELRO</a></li>
<li><a href="https://en.wikipedia.org/wiki/Buffer_overflow_protection#Canaries">Stack canaries</a></li>
<li><a href="https://en.wikipedia.org/wiki/NX_bit#Linux">NX memory protection</a></li>
<li><a href="https://securityblog.redhat.com/2012/11/28/position-independent-executables-pie/">Position Independent Executables</a></li>
<li><a href="https://fedoraproject.org/wiki/Packaging:Guidelines#Beware_of_Rpath">RPATH</a></li>
<li><a href="http://blog.tremily.us/posts/rpath/">RUNPATH</a></li>
</ul>


<p><strong>UPDATE 2015-09-17</strong></p>

<p>I've posted my findings on
<a href="https://lists.fedoraproject.org/pipermail/devel/2015-September/thread.html">fedora-devel</a>
and the comments are more than interesting even revealing an old bug in libtool.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Minor Typo Bug in Messenger for bg_BG.UTF-8]]></title>
    <link href="http://atodorov.org/blog/2015/08/20/minor-typo-bug-in-messenger/"/>
    <updated>2015-08-20T16:34:00+03:00</updated>
    <id>http://atodorov.org/blog/2015/08/20/minor-typo-bug-in-messenger</id>
    <content type="html"><![CDATA[<p><img src="/images/messenger_typo.png" title="Messenger typo" alt="Messenger typo" /></p>

<p>There's a typo in the Bulgarian translation of Messenger.com.
It is highlighted by the red dot on the picture.</p>

<p><em>hunspell</em> easily catches it so either Facebook doesn't run their
translations through a spell checker or their spell checker is
borked.</p>
]]></content>
  </entry>
  
</feed>
