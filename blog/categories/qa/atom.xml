<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>atodorov.org</title><link href="http://atodorov.org/" rel="alternate"></link><link href="http://atodorov.org/blog/categories/qa/atom.xml" rel="self"></link><id>http://atodorov.org/</id><updated>2015-11-24T21:44:00+02:00</updated><entry><title>python-libs in RHEL 7.2 broke SSL verification in s3cmd</title><link href="http://atodorov.org/blog/2015/11/24/python-libs-in-rhel-7.2-broke-ssl-verification-in-s3cmd/" rel="alternate"></link><updated>2015-11-24T21:44:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2015-11-24:blog/2015/11/24/python-libs-in-rhel-7.2-broke-ssl-verification-in-s3cmd/</id><summary type="html">&lt;p&gt;Today started with &lt;a href="http://planet.sofiavalley.com"&gt;Planet Sofia Valley&lt;/a&gt; being
broken again. Indeed it's been broken since last Friday when I've upgraded to
the latest RHEL 7.2. I quickly identified that I was hitting
&lt;a href="https://github.com/s3tools/s3cmd/issues/647"&gt;Issue #647&lt;/a&gt;. Then I tried the
git checkout without any luck. This is when I started to suspect that python-libs
has been updated in an incompatible way.&lt;/p&gt;
&lt;p&gt;After series of reported bugs,
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1284916"&gt;rhbz#1284916&lt;/a&gt;,
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1284930"&gt;rhbz#1284930&lt;/a&gt;,
&lt;a href="http://bugs.python.org/issue25722"&gt;Python#25722&lt;/a&gt;, it was clear that
&lt;code&gt;ssl.py&lt;/code&gt; was working according to RFC6125, that Amazon S3 was not playing
nicely with this same RFC and that my patch proposal was wrong.
This immediately had me looking upper in the stack at &lt;code&gt;httplib.py&lt;/code&gt; and &lt;code&gt;s3cmd&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Indeed there was a change in &lt;code&gt;httplib.py&lt;/code&gt; which introduced two parameters,
&lt;em&gt;context&lt;/em&gt; and &lt;em&gt;check_hostname&lt;/em&gt;, to &lt;code&gt;HTTPSConnection.__init__&lt;/code&gt;. The change
also supplied the logic which performs SSL hostname validation.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;if not self._context.check_hostname and self._check_hostname:
    try:
        ssl.match_hostname(self.sock.getpeercert(), server_hostname)
    except Exception:
        self.sock.shutdown(socket.SHUT_RDWR)
        self.sock.close()
        raise
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This looks a bit doggy as I don't quite understand the intention behind
&lt;em&gt;not PREDICATE and PREDICATE&lt;/em&gt;. Anyway to disable the validation you need
both parameters set to False, which is
&lt;a href="https://github.com/s3tools/s3cmd/pull/668"&gt;PR #668&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Notice the two try-except blocks. This is in case we're running with a
version that has a context but not the check_hostname parameter. I've found
the &lt;em&gt;inspect.getmembers&lt;/em&gt; function which can be used to figure out what
parameters are there for the init method but a solution based on it
doesn't appear to be more elegant. I will describe this in more details in
my next post.&lt;/p&gt;</summary><category term="QA"></category><category term="fedora.planet"></category><category term="RHEL"></category><category term="Python"></category></entry><entry><title>GitHub Bugzilla Hook</title><link href="http://atodorov.org/blog/2015/11/24/github-bugzilla-hook/" rel="alternate"></link><updated>2015-11-24T13:32:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2015-11-24:blog/2015/11/24/github-bugzilla-hook/</id><summary type="html">&lt;p&gt;Last month I've created a tool which adds comments to Bugzilla when a commit
message references a bug number. It was done as a proof of concept and didn't
receive much attention at the time. Today I'm happy to announce the existence
of &lt;a href="https://github.com/atodorov/github-bugzilla-hook"&gt;GitHub Bugzilla Hook&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I've used David Shea's
&lt;a href="https://github.com/rhinstaller/github-email-hook/"&gt;GitHub Email Hook&lt;/a&gt; as my
starting template and only modified it where needed. GitHub Bugzilla Hook will
examine push data and post comments for every unique bug+branch combination.
Once a comment for that particular bug+branch combination is made, new ones
will not be posted, even if later commits reference the same bug.
My main assumption is commits which are related to a bug will be pushed together
most of the times so there shouldn't be lots of noise in Bugzilla.&lt;/p&gt;
&lt;p&gt;See &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1274703"&gt;rhbz#1274703&lt;/a&gt; for
example of how the comments look. The parser behavior is taken from anaconda
and conforms to the style the Red Hat Installer Engineering Team uses.
Hopefully you find it useful as well.&lt;/p&gt;
&lt;p&gt;My next step is to find a hosting place for this script and hook it up
with the rhinstaller GitHub repos!&lt;/p&gt;</summary><category term="QA"></category><category term="fedora.planet"></category></entry><entry><title>Bad Stub Design in DNF, Pt.2</title><link href="http://atodorov.org/blog/2015/11/23/bad-stub-design-in-dnf/" rel="alternate"></link><updated>2015-11-23T15:55:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2015-11-23:blog/2015/11/23/bad-stub-design-in-dnf/</id><summary type="html">&lt;p&gt;Do you remember my example of a
&lt;a href="/blog/2015/09/25/unit-testing-bad-stub-design-in-dnf/"&gt;bad stub design in DNF&lt;/a&gt; ?
At that time I didn't have a good example of why this is a bad design and what are the
consequences of it. Today I have!&lt;/p&gt;
&lt;p&gt;From my comment on
&lt;a href="https://github.com/rpm-software-management/dnf-plugins-core/pull/118"&gt;PR #118&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: the benefit of this patch are quite subtle.
I've played around with creating a few more tests and the benefit I see affect
only a few lines of code.&lt;/p&gt;
&lt;p&gt;For #114 there doesn't seem to be any need to test _get_query directly,
although we call&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;   q = self.base.sack.query()
   q = q.available()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;which will benefit from this PR b/c we're stubbing out the entire Sack object.
I will work on a test later today/tomorrow to see how it looks.&lt;/p&gt;
&lt;p&gt;OTOH for #113 where we modify _get_query the test can look something like this:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;def test_get_query_with_local_rpm(self):
    try:
        (fs, rpm_path) = tempfile.mkstemp(&amp;#39;foobar-99.99-1.x86_64.rpm&amp;#39;)
        # b/c self.cmd.cli.base is a mock object add_remote_rpm
        # will not update the available packages while testing.
        # it is expected to hit an exception
        with self.assertRaises(dnf.exceptions.PackageNotFoundError):
            self.cmd._get_query(rpm_path)
        self.cmd.cli.base.add_remote_rpm.assert_called_with(rpm_path)
    finally:
        os.remove(rpm_path)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Note the comment above the with block. If we leave out &lt;code&gt;_get_query&lt;/code&gt; as before
(a simple stub function) we're not going to be able to use &lt;code&gt;assert_called_with&lt;/code&gt;
later.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now a more practical example. See 
&lt;a href="https://github.com/rpm-software-management/dnf-plugins-core/commit/fe130669ffc4c1d6eba8f10cda35ab4d803d5a3d"&gt;commit fe13066&lt;/a&gt;
- in case the package is not found we log the error. In case configuration is
&lt;code&gt;strict=True&lt;/code&gt; then the plugin will raise another exception. With the initial version
of the stubs this change in behavior is silently ignored. If there was an error
in the newly introduced lines it would go straight into production because the
existing tests passed.&lt;/p&gt;
&lt;p&gt;What happens is that &lt;code&gt;test_get_packages()&lt;/code&gt; calls &lt;code&gt;_get_packages(['notfound'])&lt;/code&gt;,
which is not the real code but a test stub and returns an empty list in this case.
The empty list is expected from the test and it will not fail!&lt;/p&gt;
&lt;p&gt;With my new stub design the test will execute the actual &lt;code&gt;_get_packages()&lt;/code&gt;
method from &lt;code&gt;download.py&lt;/code&gt; and choke on the exception. The test itself needs
to be modified, which is done in
&lt;a href="https://github.com/atodorov/dnf-plugins-core/commit/2c2b34237c99cbf32e23bde43027d22873f4e8b7"&gt;commit 2c2b34&lt;/a&gt;
and no further errors were found.&lt;/p&gt;
&lt;p&gt;So let me summarize:
&lt;strong&gt;
When using mocks, stubs and fake objects we should be replacing external
dependencies of the software under test, not internal methods from the SUT!
&lt;/strong&gt;&lt;/p&gt;</summary><category term="QA"></category><category term="fedora.planet"></category></entry><entry><title>Tip: Running DNF Plugins from git</title><link href="http://atodorov.org/blog/2015/11/23/tip-running-dnf-plugins-from-git/" rel="alternate"></link><updated>2015-11-23T15:50:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2015-11-23:blog/2015/11/23/tip-running-dnf-plugins-from-git/</id><summary type="html">&lt;p&gt;This is mostly for self reference because it is not currently documented
in the code. To use dnf plugins from a local git checkout modify your
&lt;code&gt;/etc/dnf/dnf.conf&lt;/code&gt; and add the following line under the &lt;code&gt;[main]&lt;/code&gt; section:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;pluginpath=/path/to/dnf-plugins-core/plugins
&lt;/pre&gt;&lt;/div&gt;</summary><category term="QA"></category><category term="fedora.planet"></category><category term="tips"></category></entry><entry><title>Revamping Anaconda's Dogtail Tests</title><link href="http://atodorov.org/blog/2015/11/20/revamping-anaconda-dogtail-tests/" rel="alternate"></link><updated>2015-11-20T15:34:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2015-11-20:blog/2015/11/20/revamping-anaconda-dogtail-tests/</id><summary type="html">&lt;p&gt;In my &lt;a href="/blog/2015/11/13/running-anaconda-from-git/"&gt;previous post&lt;/a&gt; I briefly talked
about running anaconda from a git checkout. My goal was to rewrite &lt;code&gt;tests/gui/&lt;/code&gt; so
that they don't use a LiveCD and virtual machines anymore. I'm pleased to announce
that this is already done (still not merged), see 
&lt;a href="https://github.com/rhinstaller/anaconda/pull/457"&gt;PR#457&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The majority of the changes are just shuffling bits around and deleting
unused code. The existing UI tests were mostly working and only needed minor
changes. There are two things which didn't work and are temporarily disabled:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Clicking the Help button results in 
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1282432"&gt;rhbz#1282432&lt;/a&gt;,
which in turn may be hiding another bug behind it;&lt;/li&gt;
&lt;li&gt;Looping over the available languages resulted in AT-SPI NonImplementedError
which I'm going to debug next.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To play around with this make sure you have accessibility enabled and:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;# cd anaconda/
# export top_srcdir=`pwd`
# setenforce 0
# cd tests/gui/
# ./run_gui_tests.sh
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; you also need Dogtail for Python3 which isn't officially available
yet. I'm building from
&lt;a href="https://vhumpa.fedorapeople.org/dogtail/beta/dogtail3-0.9.1-0.3.beta3.src.rpm"&gt;https://vhumpa.fedorapeople.org/dogtail/beta/dogtail3-0.9.1-0.3.beta3.src.rpm&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;My future plans are to figure out how to re-enable what is temporarily
disabled, update &lt;code&gt;run_gui_tests.sh&lt;/code&gt; to properly start gnome-session and
enable accessibility, do a better job cleaning up after a failure,
enable coverage and hook everything into &lt;code&gt;make ci&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Happy testing!&lt;/p&gt;</summary><category term="QA"></category><category term="fedora.planet"></category></entry><entry><title>Running Anaconda from git</title><link href="http://atodorov.org/blog/2015/11/13/running-anaconda-from-git/" rel="alternate"></link><updated>2015-11-13T10:48:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2015-11-13:blog/2015/11/13/running-anaconda-from-git/</id><summary type="html">&lt;p&gt;It is now possible to execute anaconda directly from a git checkout.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Disclaimer:&lt;/strong&gt; this is only for testing purposes, you are not supposed to
execute anaconda from git and install a running system! My intention is
to use this feature and rewrite the Dogtail tests inside &lt;code&gt;tests/gui/&lt;/code&gt; which
rely on having a LiveCD.iso and running VMs to execute. For me this has proven
very slow and difficult to debug problems in the past hence the change.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; you will need to have an active DISPLAY in your environment and
also set SELinux to permissive, see 
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1276376"&gt;rhbz#1276376&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Please see &lt;a href="https://github.com/rhinstaller/anaconda/pull/438"&gt;PR 438&lt;/a&gt; for
more details.&lt;/p&gt;</summary><category term="QA"></category><category term="fedora.planet"></category></entry><entry><title>How Krasi Tsonev Broke Planet.SofiaValley.com</title><link href="http://atodorov.org/blog/2015/11/13/how-krasi-tsonev-broke-planet.sofiavalley.com/" rel="alternate"></link><updated>2015-11-13T10:09:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2015-11-13:blog/2015/11/13/how-krasi-tsonev-broke-planet.sofiavalley.com/</id><summary type="html">&lt;p&gt;Yesterday I've added &lt;a href="http://krasimirtsonev.com/blog/"&gt;Krasimir Tsonev's blog&lt;/a&gt; to
&lt;a href="http://planet.sofiavalley.com"&gt;http://planet.sofiavalley.com&lt;/a&gt; and the planet broke. Suddenly it started showing
only Krasi's articles and all of them with the same date. The problem was the RSS
feed didn't have any timestamps. The fix is trivial:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gd"&gt;--- rss.xml.orig    2015-11-13 10:12:35.348625718 +0200&lt;/span&gt;
&lt;span class="gi"&gt;+++ rss.xml 2015-11-13 10:12:45.157932304 +0200&lt;/span&gt;
&lt;span class="gu"&gt;@@ -9,120 +9,160 @@&lt;/span&gt;
                             &amp;lt;title&amp;gt;&amp;lt;![CDATA[A modern React starter pack based on webpack]]&amp;gt;&amp;lt;/title&amp;gt;
                             &amp;lt;link&amp;gt;http://krasimirtsonev.com/blog/article/a-modern-react-starter-pack-based-on-webpack&amp;lt;/link&amp;gt;
                             &amp;lt;description&amp;gt;&amp;lt;![CDATA[&amp;lt;p&amp;gt;&amp;lt;i&amp;gt;Checkout React webpack starter in &amp;lt;a href=\&amp;quot;https://github.com/krasimir/react-web&amp;lt;br /&amp;gt;&amp;lt;p&amp;gt;You know how crazy is the JavaScript world nowadays. There are new frameworks, libraries and tools coming every day. Frequently I’m exploring some of these goodies. I got a week long holiday. I promised to myself that I’ll not code, read or watch about code. Well, it’s stronger than me. &amp;lt;a href=\&amp;quot;https://github.com/krasimir/react-webpack-starter\&amp;quot;&amp;gt;React werbpack starter&amp;lt;/a&amp;gt; is the result of my no-programming week.&amp;lt;/p&amp;gt;]]&amp;gt;&amp;lt;/description&amp;gt;
&lt;span class="gi"&gt;+                            &amp;lt;pubDate&amp;gt;Thu, 01 Oct 2015 00:00:00 +0300&amp;lt;/pubDate&amp;gt;&lt;/span&gt;
&lt;span class="gi"&gt;+                            &amp;lt;guid&amp;gt;http://krasimirtsonev.com/blog/article/a-modern-react-starter-pack-based-on-webpack&amp;lt;/guid&amp;gt;&lt;/span&gt;
                         &amp;lt;/item&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Thanks to Krasi for fixing this quickly and happy reading!&lt;/p&gt;</summary><category term="QA"></category><category term="fedora.planet"></category></entry><entry><title>UI Usability Bug for QAChallengeAccepted.com</title><link href="http://atodorov.org/blog/2015/11/11/ui-usability-bug-qachallengeaccepted.com/" rel="alternate"></link><updated>2015-11-11T22:36:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2015-11-11:blog/2015/11/11/ui-usability-bug-qachallengeaccepted.com/</id><summary type="html">&lt;p&gt;&lt;img alt="Initial view" src="/images/qachallenge1.png" title="Initial view" /&gt;&lt;/p&gt;
&lt;p&gt;Today I wanted to submit a presentation proposal for
&lt;a href="http://qachallengeaccepted.com"&gt;QA Challenge Accepted 2016&lt;/a&gt; and found a usability
problem in their website. The first picture is how the UI looks on my screen.
As you can see the screen height is enough to show the first section of the
interface. There's something orange at the bottom which isn't clearly identifiable.
The next picture shows the UI as it looks after clicking on the PROGRAM menu link.&lt;/p&gt;
&lt;p&gt;&lt;img alt="View after clicking the menu" src="/images/qachallenge2.png" title="View after clicking the menu" /&gt;&lt;/p&gt;
&lt;p&gt;The problem is that I never saw the orange section, which turned out to be
the call for papers and a link to the submission form. To fix this the orange
section either needs to go at the top and be clearly visible or at least a new
item be added to the menu.&lt;/p&gt;
&lt;p&gt;Btw the next event will be in March 2016 in Sofia and I hope to see you there!&lt;/p&gt;</summary><category term="QA"></category></entry><entry><title>Anaconda &amp; coverage.py - Pt.3 - coverage-diff</title><link href="http://atodorov.org/blog/2015/10/27/anaconda-coverage.py-coverage-diff/" rel="alternate"></link><updated>2015-10-27T11:12:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2015-10-27:blog/2015/10/27/anaconda-coverage.py-coverage-diff/</id><summary type="html">&lt;p&gt;In my &lt;a href="/blog/2015/10/15/anaconda-coverage.py-details/"&gt;previous post&lt;/a&gt;
I've talked about testing anaconda and friends and raised some questions.
Today I'm going to give an example of how to answer one of them:
"How different is the code execution path between different tests?"&lt;/p&gt;
&lt;h2&gt;coverate-tools&lt;/h2&gt;
&lt;p&gt;I'm going to use &lt;a href="https://github.com/atodorov/coverage-tools"&gt;coverage-tools&lt;/a&gt;
in my explanations below so a little introduction is required. All the tools
are executable Python scripts which build on top of existing coverage.py API.
The difference is mainly in flexibility of parameters and output formatting.
I've tried to keep as close as possible to the existing behavior of coverage.py.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;coverage-annotate&lt;/em&gt; - when given a .coverage data file prints the source code
annotated with line numbers and execution markers.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="err"&gt;!!!&lt;/span&gt; &lt;span class="n"&gt;missing&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;usr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib64&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;python2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;site&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;packages&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;pyanaconda&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;anaconda_argparse&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;covered&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;usr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib64&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;python2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;site&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;packages&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;pyanaconda&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;anaconda_argparse&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt; &lt;span class="n"&gt;skip&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="mi"&gt;37&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;logging&lt;/span&gt;
    &lt;span class="mi"&gt;38&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;log&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getLogger&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;anaconda&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="mi"&gt;39&lt;/span&gt;   
    &lt;span class="mi"&gt;40&lt;/span&gt;   &lt;span class="c"&gt;# Help text formatting constants&lt;/span&gt;
    &lt;span class="mi"&gt;41&lt;/span&gt;   
    &lt;span class="mi"&gt;42&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;LEFT_PADDING&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;  &lt;span class="c"&gt;# the help text will start after 8 spaces&lt;/span&gt;
    &lt;span class="mi"&gt;43&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;RIGHT_PADDING&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;  &lt;span class="c"&gt;# there will be 8 spaces left on the right&lt;/span&gt;
    &lt;span class="mi"&gt;44&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;DEFAULT_HELP_WIDTH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;80&lt;/span&gt;
    &lt;span class="mi"&gt;45&lt;/span&gt;   
    &lt;span class="mi"&gt;46&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_help_width&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="mi"&gt;47&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt;     &lt;span class="s"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="s"&gt;    48 &amp;gt;     Try to detect the terminal window width size and use it to&lt;/span&gt;
&lt;span class="s"&gt;    49 &amp;gt;     compute optimal help text width. If it can&amp;#39;t be detected&lt;/span&gt;
&lt;span class="s"&gt;    50 &amp;gt;     a default values is returned.&lt;/span&gt;
&lt;span class="s"&gt;    51   &lt;/span&gt;
&lt;span class="s"&gt;    52 &amp;gt;     :returns: optimal help text width in number of characters&lt;/span&gt;
&lt;span class="s"&gt;    53 &amp;gt;     :rtype: int&lt;/span&gt;
&lt;span class="s"&gt;    54 &amp;gt;     &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="mi"&gt;55&lt;/span&gt;       &lt;span class="c"&gt;# don&amp;#39;t do terminal size detection on s390, it is not supported&lt;/span&gt;
    &lt;span class="mi"&gt;56&lt;/span&gt;       &lt;span class="c"&gt;# by its arcane TTY system and only results in cryptic error messages&lt;/span&gt;
    &lt;span class="mi"&gt;57&lt;/span&gt;       &lt;span class="c"&gt;# ending on the standard output&lt;/span&gt;
    &lt;span class="mi"&gt;58&lt;/span&gt;       &lt;span class="c"&gt;# (we do the s390 detection here directly to avoid&lt;/span&gt;
    &lt;span class="mi"&gt;59&lt;/span&gt;       &lt;span class="c"&gt;#  the delay caused by importing the Blivet module&lt;/span&gt;
    &lt;span class="mi"&gt;60&lt;/span&gt;       &lt;span class="c"&gt;#  just for this single call)&lt;/span&gt;
    &lt;span class="mi"&gt;61&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt;     &lt;span class="n"&gt;is_s390&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uname&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;startswith&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;s390&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="mi"&gt;62&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt;     &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;is_s390&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="mi"&gt;63&lt;/span&gt; &lt;span class="err"&gt;!&lt;/span&gt;         &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;DEFAULT_HELP_WIDTH&lt;/span&gt;
    &lt;span class="mi"&gt;64&lt;/span&gt;   
&lt;span class="o"&gt;...&lt;/span&gt; &lt;span class="n"&gt;skip&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In the example above all lines starting with &lt;strong&gt;&amp;gt;&lt;/strong&gt; were executed by the interpreter.
All top-level import statements were executed as you would expect. Then the method
&lt;em&gt;get_help_width()&lt;/em&gt; was executed (called from somewhere). Because this was on x86_64
machine line 63 was not executed. It is marked with &lt;strong&gt;!&lt;/strong&gt;. The comments and empty
lines are of no interest.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;coverage-diff&lt;/em&gt; - produces git like diff reports on the text output of annotate.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gd"&gt;--- a/usr/lib64/python2.7/site-packages/pyanaconda/ui/gui/spokes/source.py&lt;/span&gt;
&lt;span class="gi"&gt;+++ b/usr/lib64/python2.7/site-packages/pyanaconda/ui/gui/spokes/source.py&lt;/span&gt;
&lt;span class="gu"&gt;@@ -634,7 +634,7 @@&lt;/span&gt;
    634           # Wait to make sure the other threads are done before sending ready, otherwise
    635           # the spoke may not get be sensitive by _handleCompleteness in the hub.
    636 &amp;gt;         while not self.ready:
&lt;span class="gd"&gt;-   637 !             time.sleep(1)&lt;/span&gt;
&lt;span class="gi"&gt;+   637 &amp;gt;             time.sleep(1)&lt;/span&gt;
    638 &amp;gt;         hubQ.send_ready(self.__class__.__name__, False)
    639   
    640 &amp;gt;     def refresh(self):\
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In this example line 637 was not executed in the first test run, while it was executed
in the second test run. Reading the comments above it is clear the difference between
the two test runs is just timing and synchronization.&lt;/p&gt;
&lt;h2&gt;Kickstart vs. Kickstart&lt;/h2&gt;
&lt;p&gt;How different is the code execution path between different tests? Looking at
&lt;a href="https://fedoraproject.org/wiki/Test_Results:Fedora_23_Final_RC3_Installation"&gt;Fedora 23 test results&lt;/a&gt;
we see several tests which differ only slightly in their setup - installation
via HTTP, FTP or NFS; installation to SATA, SCSI, SAS drives; installation using
RAID for the root file system; These are good candidates for further analysis.&lt;/p&gt;
&lt;p&gt;Note: my results below are not from Fedora 23 but the conclusions still apply!
The tests were executed on bare metal and virtual machines, trying to use the
same hardware or same systems configurations where possible!&lt;/p&gt;
&lt;p&gt;Example: HTTP vs. FTP&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gd"&gt;--- a/usr/lib64/python2.7/site-packages/pyanaconda/packaging/__init__.py&lt;/span&gt;
&lt;span class="gi"&gt;+++ b/usr/lib64/python2.7/site-packages/pyanaconda/packaging/__init__.py&lt;/span&gt;
&lt;span class="gu"&gt;@@ -891,7 +891,7 @@&lt;/span&gt;
    891   
    892               # Run any listeners for the new state
    893 &amp;gt;             for func in self._event_listeners[event_id]:
&lt;span class="gd"&gt;-   894 !                 func()&lt;/span&gt;
&lt;span class="gi"&gt;+   894 &amp;gt;                 func()&lt;/span&gt;
    895   
    896 &amp;gt;     def _runThread(self, storage, ksdata, payload, fallback, checkmount):
    897           # This is the thread entry
&lt;span class="gd"&gt;--- a/usr/lib64/python2.7/site-packages/pyanaconda/ui/gui/spokes/lib/resize.py&lt;/span&gt;
&lt;span class="gi"&gt;+++ b/usr/lib64/python2.7/site-packages/pyanaconda/ui/gui/spokes/lib/resize.py&lt;/span&gt;
&lt;span class="gu"&gt;@@ -102,10 +102,10 @@&lt;/span&gt;
    102           # Otherwise, fall back on increasingly vague information.
    103 &amp;gt;         if not part.isleaf:
    104 &amp;gt;             return self.storage.devicetree.getChildren(part)[0].name
&lt;span class="gd"&gt;-   105 &amp;gt;         if getattr(part.format, &amp;quot;label&amp;quot;, None):&lt;/span&gt;
&lt;span class="gi"&gt;+   105 !         if getattr(part.format, &amp;quot;label&amp;quot;, None):&lt;/span&gt;
    106 !             return part.format.label
&lt;span class="gd"&gt;-   107 &amp;gt;         elif getattr(part.format, &amp;quot;name&amp;quot;, None):&lt;/span&gt;
&lt;span class="gd"&gt;-   108 &amp;gt;             return part.format.name&lt;/span&gt;
&lt;span class="gi"&gt;+   107 !         elif getattr(part.format, &amp;quot;name&amp;quot;, None):&lt;/span&gt;
&lt;span class="gi"&gt;+   108 !             return part.format.name&lt;/span&gt;
    109 !         else:
    110 !             return &amp;quot;&amp;quot;
    111   
&lt;span class="gu"&gt;@@ -315,10 +315,10 @@&lt;/span&gt;
    315 &amp;gt;     def on_key_pressed(self, window, event, *args):
    316           # Handle any keyboard events.  Right now this is just delete for
    317           # removing a partition, but it could include more later.
&lt;span class="gd"&gt;-   318 &amp;gt;         if not event or event and event.type != Gdk.EventType.KEY_RELEASE:&lt;/span&gt;
&lt;span class="gi"&gt;+   318 !         if not event or event and event.type != Gdk.EventType.KEY_RELEASE:&lt;/span&gt;
    319 !             return
    320   
&lt;span class="gd"&gt;-   321 &amp;gt;         if event.keyval == Gdk.KEY_Delete and self._deleteButton.get_sensitive():&lt;/span&gt;
&lt;span class="gi"&gt;+   321 !         if event.keyval == Gdk.KEY_Delete and self._deleteButton.get_sensitive():&lt;/span&gt;
    322 !             self._deleteButton.emit(&amp;quot;clicked&amp;quot;)
    323   
    324 &amp;gt;     def _sumReclaimableSpace(self, model, path, itr, *args):
&lt;span class="gd"&gt;--- a/usr/lib64/python2.7/site-packages/pyanaconda/ui/gui/spokes/source.py&lt;/span&gt;
&lt;span class="gi"&gt;+++ b/usr/lib64/python2.7/site-packages/pyanaconda/ui/gui/spokes/source.py&lt;/span&gt;
&lt;span class="gu"&gt;@@ -634,7 +634,7 @@&lt;/span&gt;
    634           # Wait to make sure the other threads are done before sending ready, otherwise
    635           # the spoke may not get be sensitive by _handleCompleteness in the hub.
    636 &amp;gt;         while not self.ready:
&lt;span class="gd"&gt;-   637 !             time.sleep(1)&lt;/span&gt;
&lt;span class="gi"&gt;+   637 &amp;gt;             time.sleep(1)&lt;/span&gt;
    638 &amp;gt;         hubQ.send_ready(self.__class__.__name__, False)
    639   
    640 &amp;gt;     def refresh(self):
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The difference in &lt;code&gt;source.py&lt;/code&gt; is from timing/synchronization and can safely be ignored.
I'm not exactly sure about &lt;code&gt;__init__.py&lt;/code&gt; but doesn't look much of a big deal.
We're left with &lt;code&gt;resize.py&lt;/code&gt;. The differences in &lt;em&gt;on_key_pressed()&lt;/em&gt; are because
I've probably used the keyboard instead the mouse (these are indeed manual installs).
The other difference is in how the partition labels are displayed. One of the installs
was probably using fresh disks while the other not.&lt;/p&gt;
&lt;p&gt;Example: SATA vs. SCSI - no difference&lt;/p&gt;
&lt;p&gt;Example: SATA vs. SAS (mpt2sas driver)&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gd"&gt;--- a/usr/lib64/python2.7/site-packages/pyanaconda/bootloader.py&lt;/span&gt;
&lt;span class="gi"&gt;+++ b/usr/lib64/python2.7/site-packages/pyanaconda/bootloader.py&lt;/span&gt;
&lt;span class="gu"&gt;@@ -109,10 +109,10 @@&lt;/span&gt;
    109 &amp;gt;     try:
    110 &amp;gt;         opts.parity = arg[idx+0]
    111 &amp;gt;         opts.word   = arg[idx+1]
&lt;span class="gd"&gt;-   112 !         opts.flow   = arg[idx+2]&lt;/span&gt;
&lt;span class="gd"&gt;-   113 !     except IndexError:&lt;/span&gt;
&lt;span class="gd"&gt;-   114 &amp;gt;         pass&lt;/span&gt;
&lt;span class="gd"&gt;-   115 &amp;gt;     return opts&lt;/span&gt;
&lt;span class="gi"&gt;+   112 &amp;gt;         opts.flow   = arg[idx+2]&lt;/span&gt;
&lt;span class="gi"&gt;+   113 &amp;gt;     except IndexError:&lt;/span&gt;
&lt;span class="gi"&gt;+   114 !         pass&lt;/span&gt;
&lt;span class="gi"&gt;+   115 !     return opts&lt;/span&gt;
    116   
    117 ! def _is_on_iscsi(device):
    118 !     &amp;quot;&amp;quot;&amp;quot;Tells whether a given device is on an iSCSI disk or not.&amp;quot;&amp;quot;&amp;quot;
&lt;span class="gu"&gt;@@ -1075,13 +1075,13 @@&lt;/span&gt;
   1075 &amp;gt;             command = [&amp;quot;serial&amp;quot;]
   1076 &amp;gt;             s = parse_serial_opt(self.console_options)
   1077 &amp;gt;             if unit and unit != &amp;#39;0&amp;#39;:
&lt;span class="gd"&gt;-  1078 !                 command.append(&amp;quot;--unit=%s&amp;quot; % unit)&lt;/span&gt;
&lt;span class="gi"&gt;+  1078 &amp;gt;                 command.append(&amp;quot;--unit=%s&amp;quot; % unit)&lt;/span&gt;
   1079 &amp;gt;             if s.speed and s.speed != &amp;#39;9600&amp;#39;:
   1080 &amp;gt;                 command.append(&amp;quot;--speed=%s&amp;quot; % s.speed)
   1081 &amp;gt;             if s.parity:
&lt;span class="gd"&gt;-  1082 !                 if s.parity == &amp;#39;o&amp;#39;:&lt;/span&gt;
&lt;span class="gi"&gt;+  1082 &amp;gt;                 if s.parity == &amp;#39;o&amp;#39;:&lt;/span&gt;
   1083 !                     command.append(&amp;quot;--parity=odd&amp;quot;)
&lt;span class="gd"&gt;-  1084 !                 elif s.parity == &amp;#39;e&amp;#39;:&lt;/span&gt;
&lt;span class="gi"&gt;+  1084 &amp;gt;                 elif s.parity == &amp;#39;e&amp;#39;:&lt;/span&gt;
   1085 !                     command.append(&amp;quot;--parity=even&amp;quot;)
   1086 &amp;gt;             if s.word and s.word != &amp;#39;8&amp;#39;:
   1087 !                 command.append(&amp;quot;--word=%s&amp;quot; % s.word)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As you can see the difference is minimal, mostly related to the underlying
hardware. As far as I can tell this has to do with how the bootloader is
installed on disk but I'm no expert on this particular piece of code.
I've seen the same difference in other comparisons so it probably has to do
more with hardware than with what kind of disk/driver is used.&lt;/p&gt;
&lt;p&gt;Example: RAID 0 vs. RAID 1 - manual install&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gd"&gt;--- a/usr/lib64/python2.7/site-packages/pyanaconda/ui/gui/spokes/datetime_spoke.py&lt;/span&gt;
&lt;span class="gi"&gt;+++ b/usr/lib64/python2.7/site-packages/pyanaconda/ui/gui/spokes/datetime_spoke.py&lt;/span&gt;
&lt;span class="gu"&gt;@@ -490,9 +490,9 @@&lt;/span&gt;
    490   
    491 &amp;gt;         time_init_thread = threadMgr.get(constants.THREAD_TIME_INIT)
    492 &amp;gt;         if time_init_thread is not None:
&lt;span class="gd"&gt;-   493 &amp;gt;             hubQ.send_message(self.__class__.__name__,&lt;/span&gt;
&lt;span class="gd"&gt;-   494 &amp;gt;                              _(&amp;quot;Restoring hardware time...&amp;quot;))&lt;/span&gt;
&lt;span class="gd"&gt;-   495 &amp;gt;             threadMgr.wait(constants.THREAD_TIME_INIT)&lt;/span&gt;
&lt;span class="gi"&gt;+   493 !             hubQ.send_message(self.__class__.__name__,&lt;/span&gt;
&lt;span class="gi"&gt;+   494 !                              _(&amp;quot;Restoring hardware time...&amp;quot;))&lt;/span&gt;
&lt;span class="gi"&gt;+   495 !             threadMgr.wait(constants.THREAD_TIME_INIT)&lt;/span&gt;
    496   
    497 &amp;gt;         hubQ.send_ready(self.__class__.__name__, False)
    498
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As far as I can tell the difference is related to hardware clock settings,
probably due to different defaults in BIOS on the various hardware.
Additional tests with RAID 5 and RAID 6 reveals the same exact difference.
RAID 0 vs. RAID 10 shows no difference at all. Indeed as far as I know anaconda
delegates the creation of RAID arrays to mdadm once the desired configuration
is known so these results are to be expected.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;As you can see sometimes there are tests which appear to be very important
but in reality they cover a corner case of the base test. For example if any
of the RAID levels works we can be pretty confident 
&lt;strike&gt;all of them work&lt;/strike&gt; &lt;em&gt;they won't break in anaconda&lt;/em&gt;
(thanks Adam Williamson)!&lt;/p&gt;
&lt;p&gt;What you do with this information is up to you. Sometimes QA is able to
execute all the tests and life is good. Sometimes we have to compromise,
skip some testing and accept the risks of doing so. Sometimes you can
execute all tests for every build, sometimes only once per milestone.
Whatever the case having the information to back up your decision is vital!&lt;/p&gt;
&lt;p&gt;In my next post on this topic I'm going to talk more about functional tests
vs. unit tests. Both anaconda and blivet have both kinds of tests and I'm
interested to know if tests from the two categories focus on the same
functionality how are they different. If we have a unit test for feature X,
does it warrant to spend the resources doing functional testing for X as well?&lt;/p&gt;</summary><category term="QA"></category><category term="fedora.planet"></category></entry><entry><title>Anaconda &amp; coverage.py - Pt.2 - Details</title><link href="http://atodorov.org/blog/2015/10/15/anaconda-coverage.py-details/" rel="alternate"></link><updated>2015-10-15T14:15:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2015-10-15:blog/2015/10/15/anaconda-coverage.py-details/</id><summary type="html">&lt;p&gt;My &lt;a href="/blog/2015/10/14/anaconda-coverage.py-introduction/"&gt;previous post&lt;/a&gt;
was an introduction to testing installation related components. Now I'm going to
talk more about anaconda and how it is tested.&lt;/p&gt;
&lt;p&gt;There are two primary ways to test anaconda. You can execute &lt;code&gt;make check&lt;/code&gt; in the
source directory which will trigger the package test suite. The other possibility
is to perform an actual installation, on bare meta or virtual machine, using the
&lt;a href="https://kojipkgs.fedoraproject.org/mash/"&gt;latest Rawhide snapshots&lt;/a&gt; which also
include the latest anaconda. For both of these methods we can collect code
coverage information. In live installation mode coverage is enabled via the
&lt;code&gt;inst.debug&lt;/code&gt; boot argument. Fedora 23 and earlier use &lt;code&gt;debug=1&lt;/code&gt; but that
can lead to &lt;a href="https://github.com/rhinstaller/anaconda/pull/291"&gt;problems&lt;/a&gt;
sometimes.&lt;/p&gt;
&lt;h2&gt;Kickstart Testing&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/rhinstaller/pykickstart/blob/master/docs/kickstart-docs.rst"&gt;Kickstart&lt;/a&gt;
is a method of automating the installation of Fedora by supplying the necessary
configuration into a text file and pointing the installer at this file. There is
the directory &lt;code&gt;tests/kickstart_tests&lt;/code&gt;, inside the anaconda source, where each
test is a kickstart file and a shell script. The test runner provisions a virtual
machine using boot.iso and the kickstart file. A shell script then verifies
installation was as expected and copies files of interest to the host system.
Kickstart files are also the basis for testing Fedora installations in
&lt;a href="https://beaker.fedoraproject.org/bkr/jobs/"&gt;Beaker&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Naturally some of these in-package kickstart tests are the same as
&lt;a href="https://bitbucket.org/fedoraqa/fedora-beaker-tests/"&gt;out-of-band kickstart tests&lt;/a&gt;.
Hint: there are more available but not yet public.&lt;/p&gt;
&lt;p&gt;The question which I don't have an answer for right now is
"Can we remove some of the duplicates and how this affects devel and QE teams" ?
The pros of in-package testing are that it is faster compared to Beaker. The cons
are that you're not testing the real distro (every snapshot is a possible final
release to the users).&lt;/p&gt;
&lt;h2&gt;Dogtail&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://fedorahosted.org/dogtail/"&gt;Dogtail&lt;/a&gt; uses accessibility technologies to
communicate with desktop applications. It is written in Python and can be used
as GUI test automation framework. Long time ago I've proposed support for Dogtail
in anaconda which was rejected, then couple of years later it was accepted and
later removed from the code again.&lt;/p&gt;
&lt;p&gt;Anaconda has in-package Dogtail tests (&lt;code&gt;tests/gui/&lt;/code&gt;). They work by attaching
a second disk image with the test suite to a VM running a LiveCD. Anaconda is
started on the LiveCD and an attempt to install Fedora on disk 1 is made.
Everything is driven by the Dogtail scripts. There are only a few of these
tests available and they are currently disabled.
Red Hat QE has also created another method for running Dogtail tests in anaconda
using an updates.img with the previous functionality.&lt;/p&gt;
&lt;p&gt;Even if there are some duplicate tests I'm not convinced we have to drop the
&lt;code&gt;tests/gui/&lt;/code&gt; directory from the code because
the framework used to drive the graphical interface of anaconda appears to be very
well written. The code is clean and easy to follow.
Also I don't have metrics of how much these two methods differ or how much they cover
in their testing. IMO they are pretty close and before we can find a way to
reliably execute them on a regular basis there isn't much to be done here.
One idea is to use the &lt;code&gt;--dirinstall&lt;/code&gt; or &lt;code&gt;--image&lt;/code&gt; options and skip the
LiveCD part entirely.&lt;/p&gt;
&lt;h2&gt;How Much is Tested&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;make ci&lt;/code&gt; covers 10% of the entire code base for anaconda. Mind you that
&lt;code&gt;tests/storage&lt;/code&gt; and &lt;code&gt;tests/gui&lt;/code&gt; are currently disabled.
See &lt;a href="https://github.com/rhinstaller/anaconda/pull/346"&gt;PR #346&lt;/a&gt;,
&lt;a href="https://github.com/rhinstaller/anaconda/pull/327"&gt;PR #327&lt;/a&gt; and
&lt;a href="https://github.com/rhinstaller/anaconda/pull/319"&gt;PR #319&lt;/a&gt;!
There is definitely room for improvement.&lt;/p&gt;
&lt;p&gt;On the other hand live installation testing is much
better. Text mode covers around 25% while graphical installations around 40%.
Text and graphical combined cover 50% though. These numbers will drop quite a bit
once anaconda learns to
&lt;a href="https://github.com/rhinstaller/anaconda/pull/397"&gt;include all possible files&lt;/a&gt;
in its report but it is a good estimate.&lt;/p&gt;
&lt;p&gt;The important questions to ask here are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How much can PyUnit tests cover in anaconda?&lt;/li&gt;
&lt;li&gt;How much can kickstart tests cover ?&lt;/li&gt;
&lt;li&gt;Have we reached a threshold in any of the two primary methods for testing ?&lt;/li&gt;
&lt;li&gt;Does UI automation (with Dogtail) improve anything ?&lt;/li&gt;
&lt;li&gt;When testing a particular feature (say user creation) how different is the
code execution path between manual (GUI) testing, kickstart and unit testing ?
If not so different can we invest in unit tests instead of higher level tests then ?&lt;/li&gt;
&lt;li&gt;How different is the code execution path between different tests (manual or kickstart) ?
In other words how much value are we getting from testing for the resources we're putting in ?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In my next post I will talk more about these questions and some rudimentary
analysis against coverage data from the various test methods and test cases!&lt;/p&gt;</summary><category term="QA"></category><category term="fedora.planet"></category></entry><entry><title>Anaconda &amp; coverage.py - Pt.1 - Introduction</title><link href="http://atodorov.org/blog/2015/10/14/anaconda-coverage.py-introduction/" rel="alternate"></link><updated>2015-10-14T13:44:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2015-10-14:blog/2015/10/14/anaconda-coverage.py-introduction/</id><summary type="html">&lt;p&gt;Since early 2015 I've been working on testing installation related
components in Rawhide. I'm interested in the code produced by the
&lt;a href="https://github.com/rhinstaller/"&gt;Red Hat Installer Engineering Team&lt;/a&gt; and in
particular in &lt;em&gt;anaconda&lt;/em&gt;, &lt;em&gt;blivet&lt;/em&gt;, &lt;em&gt;pyparted&lt;/em&gt; and &lt;em&gt;pykickstart&lt;/em&gt;. The goal of
this effort is to improve the overall testing of these components and also
have Red Hat QE contribute some of our knowledge back to the community. The benefit
of course will be better software for everyone. In the next
several posts I'll summarize what has been done so far and what's to be expected
in the future.&lt;/p&gt;
&lt;h2&gt;Test Documentation Matters&lt;/h2&gt;
&lt;p&gt;Do you want others to contribute tests? I certainly do! When I started looking
at the code it was obviously clear there was no documentation related to testing.
Everyone needs to know how to write and execute these tests! Currently we have
basic README files describing how to install necessary dependencies for development
and test execution, how to execute the tests (and what can be tested) and most
importantly what is the test architecture. There is description of how the file
structure is organized and which are the base classes to inherit from when adding
new tests. Most of the times each component goes through a &lt;em&gt;pylint&lt;/em&gt; check and
a standard PyUnit test suite.&lt;/p&gt;
&lt;p&gt;Test documentation is usually in a &lt;code&gt;tests/README&lt;/code&gt; file. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/rhinstaller/anaconda/blob/master/tests/README.rst"&gt;anaconda&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/rhinstaller/blivet/blob/master/tests/README.rst"&gt;blivet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/rhinstaller/pykickstart/blob/master/tests/README.rst"&gt;pykickstart&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/rhinstaller/pyparted/blob/master/tests/README.rst"&gt;pyparted&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I've tried to explain as much as possible without bloating the files and going into
unnecessary details. If you spot something missing please send a pull request.&lt;/p&gt;
&lt;h2&gt;Continuous Integration&lt;/h2&gt;
&lt;p&gt;This has been largely an effort driven by Chris Lumens from the devel team.
All the components I'm interested in are tested regularly in a CI environment.
There is a &lt;code&gt;make ci&lt;/code&gt; Makefile target for those of you interested in what exactly
gets executed.&lt;/p&gt;
&lt;h2&gt;Test Coverage&lt;/h2&gt;
&lt;p&gt;In order to &lt;strong&gt;improve&lt;/strong&gt; something you need to know where you stand. We'll I didn't.
That's why the first step was to integrate the
&lt;a href="https://bitbucket.org/ned/coveragepy"&gt;coverage.py&lt;/a&gt; tool with all of these components.&lt;/p&gt;
&lt;p&gt;With the exception of blivet (written in C) all of the other
components integrate well with coverage.py and produce good statistics. pykickstart is
the champ here with 90% coverage, while anaconda is somewhere between 10% and 50%.
Full test coverage measurement for anaconda isn't straight forward and will be the
subject of my next post. For the C based code we have to hook up with
&lt;a href="https://gcc.gnu.org/onlinedocs/gcc/Gcov.html"&gt;Gcov&lt;/a&gt; which shouldn't be too difficult.&lt;/p&gt;
&lt;p&gt;At the moment there are several open pull requests to integrate the coverage test
targets with &lt;code&gt;make ci&lt;/code&gt; and also report the results in human readable form. I will be
collecting these for historical references.&lt;/p&gt;
&lt;h2&gt;Tools&lt;/h2&gt;
&lt;p&gt;I've created some basic text-mode
&lt;a href="https://github.com/atodorov/coverage-tools"&gt;coverage-tools&lt;/a&gt; to help me combine and
compare data from different executions. These are only the start of it and I'm expanding
them as my needs for reporting and analytics evolve. I'm also looking into
&lt;a href="/blog/2015/07/27/call-for-ideas-graphical-test-coverage-reports/"&gt;more detailed coverage reports&lt;/a&gt;
but I don't have enough data and use cases to work on this front at the moment.&lt;/p&gt;
&lt;p&gt;Some ideas currently in mind:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;map code changes (git commits) to existing test coverage to get a feeling where to
invest in more testing;&lt;/li&gt;
&lt;li&gt;map bugs to code areas and to existing test coverage to see if we aren't
missing tests in areas where the bugs are happening;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Bugs&lt;/h2&gt;
&lt;p&gt;coverage.py is a very nice tool indeed but I guess most people use it in a very
limited way. Shortly after I started working with it I've found several places which
need improvements. These have to do with combining and reporting on multiple files.&lt;/p&gt;
&lt;p&gt;Some of the interesting issues I've found and still open are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://bitbucket.org/ned/coveragepy/pull-requests/63/"&gt;PR #63 - New option --dont-remove when combining coverage data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bitbucket.org/ned/coveragepy/issues/425"&gt;#425 - source parameter not including files which are explicitly specified&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bitbucket.org/ned/coveragepy/issues/426"&gt;#426 - Difference between coverage results with source specifies full dir instead of module name&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In my next post I will talk about anaconda code coverage and what I want to do with it.
In the mean time please use the comments to share your feedback.&lt;/p&gt;</summary><category term="QA"></category><category term="fedora.planet"></category></entry><entry><title>Unit Testing Example - Bad Stub Design in DNF</title><link href="http://atodorov.org/blog/2015/09/25/unit-testing-bad-stub-design-in-dnf/" rel="alternate"></link><updated>2015-09-25T11:20:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2015-09-25:blog/2015/09/25/unit-testing-bad-stub-design-in-dnf/</id><summary type="html">&lt;p&gt;In software testing, usually unit testing, test stubs are programs that simulate
the behaviors of external dependencies that a module undergoing the test depends
on. Test stubs provide canned answers to calls made during the test.&lt;/p&gt;
&lt;p&gt;I've discovered an improperly written stub method in one of
&lt;a href="http://dnf.baseurl.org/"&gt;DNF&lt;/a&gt;'s tests:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;span class="filename"&gt;tests/test_download.py&lt;/span&gt;&lt;pre&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;DownloadCommandTest&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;unittest&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TestCase&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;setUp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;stub_fn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pkg_spec&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;.src.rpm&amp;#39;&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;pkg_spec&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Query&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sourcerpm&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;pkg_spec&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Query&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;latest&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pkg&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;pkg&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;pkg_spec&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;pkg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

        &lt;span class="n"&gt;cli&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mock&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MagicMock&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cmd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;download&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DownloadCommand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cli&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cmd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cli&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;base&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dnf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repodict&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RepoDict&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cmd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_get_query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;stub_fn&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cmd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_get_query_source&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;stub_fn&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The replaced methods look like this:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;span class="filename"&gt;plugins/download.py&lt;/span&gt;&lt;pre&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_get_query&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pkg_spec&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Return a query to match a pkg_spec.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;subj&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dnf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subject&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Subject&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pkg_spec&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subj&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_best_query&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;base&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sack&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;available&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;latest&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;msg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;No package &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;pkg_spec&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot; available.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="n"&gt;dnf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exceptions&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PackageNotFoundError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;msg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_get_query_source&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pkg_spec&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&amp;quot;Return a query to match a source rpm file name.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;pkg_spec&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pkg_spec&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;  &lt;span class="c"&gt;# skip the .rpm&lt;/span&gt;
        &lt;span class="n"&gt;nevra&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hawkey&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split_nevra&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pkg_spec&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;base&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;available&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;latest&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nevra&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nevra&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                     &lt;span class="n"&gt;release&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nevra&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;release&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;arch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nevra&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arch&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;msg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;No package &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;pkg_spec&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot; available.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="n"&gt;dnf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exceptions&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PackageNotFoundError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;msg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As seen here &lt;em&gt;stub_fn&lt;/em&gt; replaces the &lt;em&gt;_get_query&lt;/em&gt; methods from the class under
test. At the time of writing this has probably seemed like a good idea to
speed up writing the tests.&lt;/p&gt;
&lt;p&gt;The trouble is we should be replacing the external dependencies of &lt;em&gt;_get_query&lt;/em&gt;
(other parts of DNF essentially) and not methods from &lt;em&gt;DownloadCommand&lt;/em&gt;. To
understand why this is a bad idea check
&lt;a href="https://github.com/rpm-software-management/dnf-plugins-core/pull/113"&gt;PR #113&lt;/a&gt;,
which directly modifies &lt;em&gt;_get_query&lt;/em&gt;. There's no way to test this patch
with the current state of the test.&lt;/p&gt;
&lt;p&gt;So I took a few days to experiment and update the current test stubs. The
result is 
&lt;a href="https://github.com/rpm-software-management/dnf-plugins-core/pull/118"&gt;PR #118&lt;/a&gt;.
The important bits are the &lt;em&gt;SackStub&lt;/em&gt; and &lt;em&gt;SubjectStub&lt;/em&gt; classes which hold
information about the available RPM packages on the system. The rest are cosmetics
to fit around the way the query objects are used (q.available(), q.latest(), q.filter()).
The proposed design correctly overrides the external dependencies on
&lt;em&gt;dnf.subject.Subject&lt;/em&gt; and &lt;em&gt;self.base.sack&lt;/em&gt; which are initialized before our
plugin is loaded by DNF.&lt;/p&gt;
&lt;p&gt;I must say this is the first error of this kind I've seen in my QA practice so far.
I have no idea if this was a minor oversight or something which happens more frequently
in open source projects but it's a great example nevertheless.&lt;/p&gt;
&lt;p&gt;For those of you who'd like to get started on unit testing I can recommend the book
&lt;a href="http://www.amazon.com/gp/product/1933988274/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1933988274&amp;linkCode=as2&amp;tag=atodorovorg-20"&gt;The Art of Unit Testing: With Examples in .Net&lt;/a&gt;&lt;img src="http://www.assoc-amazon.com/e/ir?t=atodorovorg-20&amp;l=as2&amp;o=1&amp;a=1933988274" width="1" height="1" border="0"  style="border:none !important; margin:0px !important;" /&gt;
by Roy Osherove!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;UPDATE&lt;/strong&gt;: Part 2 with more practical examples can be found
&lt;a href="/blog/2015/11/23/bad-stub-design-in-dnf/"&gt;here&lt;/a&gt;.&lt;/p&gt;</summary><category term="QA"></category><category term="fedora.planet"></category></entry><entry><title>4000+ bugs in Fedora - checksec failures</title><link href="http://atodorov.org/blog/2015/09/16/4000-bugs-in-fedora-checksec-failures/" rel="alternate"></link><updated>2015-09-16T17:03:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2015-09-16:blog/2015/09/16/4000-bugs-in-fedora-checksec-failures/</id><summary type="html">&lt;p&gt;In the last week I've been trying to figure out how many packages
conform to the new
&lt;a href="https://fedoraproject.org/wiki/Changes/Harden_All_Packages"&gt;Harden All Packages&lt;/a&gt;
policy in Fedora!&lt;/p&gt;
&lt;p&gt;From 46884 RPMs, 17385 are 'x86_64' meaning they may contain ELF objects.
From them 4489 are reported as failed &lt;code&gt;checksec&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;What you should see as the output from &lt;code&gt;checksec is&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;Full RELRO      Canary found      NX enabled    PIE enabled     No RPATH   No RUNPATH
Full RELRO      Canary found      NX enabled    DSO             No RPATH   No RUNPATH
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The first line is for binaries, the second one for libraries b/c
DSOs on x86_64 are always position-independent. Some RPATHs are acceptable,
e.g. &lt;code&gt;%{_libdir}/foo/&lt;/code&gt; and I've tried to exclude them unless
other offenses are found. The script which does this is
&lt;a href="https://github.com/atodorov/fedora-scripts/blob/master/checksec-collect"&gt;checksec-collect&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Most often I'm seeing &lt;em&gt;Partial RELRO&lt;/em&gt;, &lt;em&gt;No canary found&lt;/em&gt; and &lt;em&gt;No PIE&lt;/em&gt; errors.
Since all packages potentially process untrusted input, it makes sense for all of them
to be hardened and enhance the security of Fedora. That's why all of these errors
should be considered valid bugs.&lt;/p&gt;
&lt;h2&gt;Attn package maintainers&lt;/h2&gt;
&lt;p&gt;Please see if your package is in the list and try to fix it or let me know
why it should be excluded, for example it's a boot loader and doesn't function
properly with hardening enabled. The full list is available at
&lt;a href="https://github.com/atodorov/fedora-scripts/blob/master/checksec.log"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For more information about the different protection mechanisms see the following
links:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://tk-blog.blogspot.bg/2009/02/relro-not-so-well-known-memory.html"&gt;Partial vs Full RELRO&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Buffer_overflow_protection#Canaries"&gt;Stack canaries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/NX_bit#Linux"&gt;NX memory protection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://securityblog.redhat.com/2012/11/28/position-independent-executables-pie/"&gt;Position Independent Executables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://fedoraproject.org/wiki/Packaging:Guidelines#Beware_of_Rpath"&gt;RPATH&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.tremily.us/posts/rpath/"&gt;RUNPATH&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;UPDATE 2015-09-17&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I've posted my findings on 
&lt;a href="https://lists.fedoraproject.org/pipermail/devel/2015-September/thread.html"&gt;fedora-devel&lt;/a&gt;
and the comments are more than interesting even revealing an old bug in libtool.&lt;/p&gt;</summary><category term="QA"></category><category term="fedora.planet"></category></entry><entry><title>Minor Typo Bug in Messenger for bg_BG.UTF-8</title><link href="http://atodorov.org/blog/2015/08/20/minor-typo-bug-in-messenger/" rel="alternate"></link><updated>2015-08-20T16:34:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2015-08-20:blog/2015/08/20/minor-typo-bug-in-messenger/</id><summary type="html">&lt;p&gt;&lt;img alt="Messenger typo" src="/images/messenger_typo.png" title="Messenger typo" /&gt;&lt;/p&gt;
&lt;p&gt;There's a typo in the Bulgarian translation of Messenger.com.
It is highlighted by the red dot on the picture.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;hunspell&lt;/em&gt; easily catches it so either Facebook doesn't run their
translations through a spell checker or their spell checker is
borked.&lt;/p&gt;</summary><category term="QA"></category></entry><entry><title>Pedometer Bug in Samsung S Health</title><link href="http://atodorov.org/blog/2015/08/17/pedometer-bug-in-samsung-s-health/" rel="alternate"></link><updated>2015-08-17T16:43:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2015-08-17:blog/2015/08/17/pedometer-bug-in-samsung-s-health/</id><summary type="html">&lt;p&gt;Do you remember the 
&lt;a href="/blog/2015/01/09/pedometer-bug-in-samsung-gear-fit-smartwatch/"&gt;pedometer bug in Samsung Gear Fit&lt;/a&gt;
I've discovered earlier ? It turns out that Samsung is a fan of this one
and has the exact same bug in their &lt;em&gt;S Health&lt;/em&gt; application.&lt;/p&gt;
&lt;p&gt;The application doesn't block pedometer(e.g. steps counting) while
performing other activities such as cycling for example. So in reallity it
reports incorrect value for burned callories. At this time I call it
bad software development practice/architecture on Samsung's part which leads
to this bug being present.&lt;/p&gt;
&lt;p&gt;Btw for more interesting bugs see
&lt;a href="http://gearfitbugs.tumblr.com/"&gt;Samsung Gear Fit Bug-of-the-Day&lt;/a&gt;.&lt;/p&gt;</summary><category term="QA"></category><category term="Samsung"></category></entry><entry><title>Call for Ideas: Graphical Test Coverage Reports</title><link href="http://atodorov.org/blog/2015/07/27/call-for-ideas-graphical-test-coverage-reports/" rel="alternate"></link><updated>2015-07-27T13:04:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2015-07-27:blog/2015/07/27/call-for-ideas-graphical-test-coverage-reports/</id><summary type="html">&lt;p&gt;If you are working with Python and writing unit tests chances are you are
familiar with the &lt;a href="http://nedbatchelder.com/code/coverage/"&gt;coverage&lt;/a&gt; reporting
tool. However there are testing scenarios in which we either don't use unit tests
or maybe execute different code paths(test cases) independent of each other.&lt;/p&gt;
&lt;p&gt;For example, this is the case with installation testing in Fedora. Because anaconda
- the installer is very complex the easiest way is to test it live, not with unit tests.
Even though we can get a coverage report (anaconda is written in Python) it reflects
only the test case it was collected from.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;coverage combine&lt;/code&gt; can be used to combine several data files and produce an aggregate
report. This can tell you how much test coverage you have across all your tests.&lt;/p&gt;
&lt;p&gt;As far as I can tell Python's coverage doesn't tell you how many times a particular
line of code has been executed. It also doesn't tell you which test cases executed
a particular line
(see &lt;a href="https://bitbucket.org/ned/coveragepy/pull-request/59"&gt;PR #59&lt;/a&gt;).
In the Fedora example, I have the feeling many of our tests are touching the same
code base and not contributing that much to the overall test coverage.
So I started working on these items.&lt;/p&gt;
&lt;p&gt;I imagine a script which will read coverage data from several test executions
(preferably in JSON format, 
&lt;a href="https://bitbucket.org/ned/coveragepy/pull-request/60"&gt;PR #60&lt;/a&gt;) and produce a 
graphical report similar to what GitHub does for your commit activity.&lt;/p&gt;
&lt;p&gt;See an example &lt;a href="https://s3.amazonaws.com/atodorov/blog/pykickstart_report.html"&gt;here&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;The example uses darker colors to indicate more line executions, lighter for less
executions. Check the HTML for the actual numbers b/c there are no hints yet.
The input JSON files are
&lt;a href="https://s3.amazonaws.com/atodorov/blog/coverage_json_reports.tar.gz"&gt;here&lt;/a&gt; and
the script to generate the above HTML is at 
&lt;a href="https://github.com/atodorov/fedora-scripts/blob/master/coverage-tool"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now I need your ideas and comments!&lt;/p&gt;
&lt;p&gt;What kinds of coverage reports are you using in your job ? How do you generate them ?
How do they look like ?&lt;/p&gt;</summary><category term="Fedora"></category><category term="QA"></category><category term="Django"></category><category term="fedora.planet"></category></entry><entry><title>Bug in VMware Open House Website</title><link href="http://atodorov.org/blog/2015/05/21/bug-in-vmware-open-house-website/" rel="alternate"></link><updated>2015-05-21T14:55:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2015-05-21:blog/2015/05/21/bug-in-vmware-open-house-website/</id><summary type="html">&lt;p&gt;&lt;img alt="&amp;quot;Open House website bug&amp;quot;" src="/images/vmware_bug.png" title="Bug in VMware Open House website" /&gt;&lt;/p&gt;
&lt;p&gt;This is a slightly annoying UI bug in
&lt;a href="http://www.openhouse.vmware-bulgaria.com/"&gt;VMware's Open House&lt;/a&gt; website. I've reported
it and hopefully they will fix it.&lt;/p&gt;</summary><category term="QA"></category></entry><entry><title>Free Software Testing Books</title><link href="http://atodorov.org/blog/2015/05/20/free-software-testing-books/" rel="alternate"></link><updated>2015-05-20T11:35:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2015-05-20:blog/2015/05/20/free-software-testing-books/</id><summary type="html">&lt;p&gt;There's a huge list of 
&lt;a href="https://github.com/ligurio/free-software-testing-books/blob/master/free-software-testing-books.md"&gt;free books&lt;/a&gt;
on the topic of software testing. This will definitely be my summer reading list.
I hope you find it helpful.&lt;/p&gt;
&lt;h2&gt;200 Graduation Theses About Software Testing&lt;/h2&gt;
&lt;p&gt;The guys from &lt;a href="http://qahelp.net"&gt;QAHelp&lt;/a&gt; have compiled a list of 200
graduation theses from various universities which are freely accessible
online. The list can be found
&lt;a href="http://qahelp.net/200-dissertatsij-po-testirovaniyu-v-svobodnoj-dostupe/"&gt;here&lt;/a&gt;.&lt;/p&gt;</summary><category term="fedora.planet"></category><category term="QA"></category><category term="Django"></category><category term="books"></category></entry><entry><title>Pedometer Bug in Samsung Gear Fit Smartwatch</title><link href="http://atodorov.org/blog/2015/01/09/pedometer-bug-in-samsung-gear-fit-smartwatch/" rel="alternate"></link><updated>2015-01-09T10:53:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2015-01-09:blog/2015/01/09/pedometer-bug-in-samsung-gear-fit-smartwatch/</id><summary type="html">&lt;p&gt;&lt;a style="float:left;display:inline-block;margin-right:10px;" href="http://www.amazon.com/gp/product/B00J4DY8RU/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=B00J4DY8RU&amp;linkCode=as2&amp;tag=atodorovorg-20&amp;linkId=RNJGVYUTOOJFGWOU"&gt;
&lt;img src="/images/samsung/gear_fit.jpg" /&gt;
&lt;/a&gt;
&lt;sub&gt;
Image source &lt;a href="http://pocketnow.com/2014/05/02/samsung-gear-fit-review-pre-buttal-video"&gt;Pocketnow&lt;/a&gt;
&lt;sub&gt;&lt;/p&gt;
&lt;p&gt;Recently I've been playing around with a
&lt;a href="http://www.amazon.com/gp/product/B00J4DY8RU/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=B00J4DY8RU&amp;linkCode=as2&amp;tag=atodorovorg-20&amp;linkId=RNJGVYUTOOJFGWOU"&gt;Samsung Gear Fit&lt;/a&gt;&lt;img src="http://ir-na.amazon-adsystem.com/e/ir?t=atodorovorg-20&amp;l=as2&amp;o=1&amp;a=B00J4DY8RU" width="1" height="1" border="0"  style="border:none !important; margin:0px !important;" /&gt;
and while the hardware seems good I'm a bit disapointed on the software side.
There is at least one bug which is clearly visible - &lt;strong&gt;pedometer counts calories twice
when it's on and exercise mode is started&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;How to test:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Start the &lt;em&gt;Pedometer&lt;/em&gt; app and record any initial readings;&lt;/li&gt;
&lt;li&gt;Walk a fixed distance and at the end record all readings;&lt;/li&gt;
&lt;li&gt;Now go back to the &lt;em&gt;Exercise&lt;/em&gt; app and select a &lt;em&gt;Walking&lt;/em&gt;
exercise from the menu. Tap &lt;em&gt;Start&lt;/em&gt;;&lt;/li&gt;
&lt;li&gt;Walk back the same distance/road as before. At the end of the journey
stop the walking exercise and record all readings.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Expected results:&lt;/p&gt;
&lt;p&gt;At the end of the trip I expect to see roughly the same calories burned
for both directions.&lt;/p&gt;
&lt;p&gt;Actual results:&lt;/p&gt;
&lt;p&gt;The return trip counted twice as many calories compared to the forward trip.
Here's some actual data to prove it:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;+--------------------------+----------+----------------+---------+-------------+---------+
|                          | Initial  | Forward trip   |         | Return trip |         |
|                          | Readings | Pedometer only |  Delta  | Pedometer &amp;amp; |  Delta  |
|                          |          |                |         | Exercise    |         |
+--------------------------+----------+----------------+---------+-------------+---------+
|              Total Steps | 14409 st | 14798 st       | 389 st  | 15246 st    | 448 st  |
+--------------------------+----------+----------------+---------+-------------+---------+
|           Total Distance | 12,19 km | 12,52 km       | 0,33 km | 12,90 km    | 0,38 km |
+--------------------------+----------+----------------+---------+-------------+---------+
| Cal burned via Pedometer |  731 Cal |  751 Cal       | 20 Cal  |  772 Cal    | 21 Cal  |
+--------------------------+----------+----------------+=========+-------------+=========+
| Cal burned via Exercise  |  439 Cal |  439 Cal       | 0       |  460 Cal    | 21 Cal  |
+--------------------------+----------+----------------+---------+-------------+=========+
|    Total calories burned | 1170 Cal | 1190 Cal       | 20 cal  | 1232 Cal    | 42 Cal  |
+--------------------------+----------+----------------+=========+-------------+=========+
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Data values above were taken from Samsung's &lt;em&gt;S Health&lt;/em&gt; app which is easier to work with
instead of the Gear Fit itself.&lt;/p&gt;
&lt;p&gt;The problem is that both apps are accessing the sensor simultaneously and not aware of each other.
In theory it should be relatively easy to block access of one app while the other is running but
that may not be so easy to implement on the limited platform the Gear Fit is.&lt;/p&gt;</summary><category term="QA"></category><category term="Samsung"></category></entry><entry><title>2 Barcode Related Bugs in MyFitnessPal</title><link href="http://atodorov.org/blog/2015/01/07/2-barcode-related-bugs-in-myfitnesspal/" rel="alternate"></link><updated>2015-01-07T14:44:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2015-01-07:blog/2015/01/07/2-barcode-related-bugs-in-myfitnesspal/</id><summary type="html">&lt;p&gt;&lt;img alt="Barcode that fails to scan" src="/images/barcode/fail.jpg" title="Barcode that fails to scan" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Did you know that the popular &lt;em&gt;MyFitnessPal&lt;/em&gt; application can't scan barcodes
printed on curved surfaces?&lt;/strong&gt; The above barcode fails to scan because it is
printed on a metal can full of roasted almonds :). In contrast the
&lt;em&gt;Barcode Scanner&lt;/em&gt; from &lt;em&gt;ZXing Team&lt;/em&gt; understands it just fine. My bet is
&lt;em&gt;MyFitnessPal&lt;/em&gt; uses less advanced barcode scanning library. Judging from
the visual clues in the app the issue is between 6 and 0 where white space is wider.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Barcode that scans fine" src="/images/barcode/pass.jpg" title="Barcode that scans fine" /&gt;&lt;/p&gt;
&lt;p&gt;Despite being a bit blurry this second barcode is printed on a flat surface and
is understood by both &lt;em&gt;MyFitnessPal&lt;/em&gt; and "ZXing Barcode Scanner".&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt; I get the same results regardless if I try to scan the actual barcode
printed on packaging, a picture from a mobile device screen or these two images
from the laptop screen.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MyFitnessPal also has problems with duplicate barcodes!&lt;/strong&gt; Barcodes are not unique
and many producers use the same code for multiple products. I've seen this in the
case of two different varieties of salami from the same manufacturer on the good end
and two different products produced across the world (eggs and popcorn) on the
extreme end.&lt;/p&gt;
&lt;p&gt;Once the user scans their barcodes and establish that the existing information is
not correct they can &lt;em&gt;Create a Food&lt;/em&gt; and update the calories database. This is then
synced back to MyFitnesPal servers and overrides any existing information. When the same
barcode is scanned for the second time only the new DB entry is visible.&lt;/p&gt;
&lt;p&gt;How to reproduce:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Scan an existing barcode and enter it to MFP database if not already there;&lt;/li&gt;
&lt;li&gt;Scan the same barcode one more time and pretend the information is not correct;&lt;/li&gt;
&lt;li&gt;Click the &lt;em&gt;Create a Food&lt;/em&gt; button and fill-in the fields. For example use a
different food name to distinguish between the two database entries. Save!&lt;/li&gt;
&lt;li&gt;From another device with different account (to verify information in DB)
scan the same barcode again. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Actual results:
The last entered information is shown.&lt;/p&gt;
&lt;p&gt;Expected results:
User is shown both DB records and can select between them.&lt;/p&gt;</summary><category term="QA"></category></entry><entry><title>Endless Loop Bug in Candy Crush Saga Level 80</title><link href="http://atodorov.org/blog/2015/01/05/endless-loop-bug-candy-crush-saga-level-80/" rel="alternate"></link><updated>2015-01-05T15:44:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2015-01-05:blog/2015/01/05/endless-loop-bug-candy-crush-saga-level-80/</id><summary type="html">&lt;p&gt;Happy new year everyone. During the holidays I've discovered several interesting
bugs which will be revealed in this blog. Starting today with a bug in the popular
game &lt;em&gt;Candy Crush Saga&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In level 80 one teleport is still open but the chocolates are blocking the rest.
The game has ended but candies keep flowing through the teleport and the level doesn't exit.
My guess is that the game logic is missing a check whether or not it will go into an endless loop.&lt;/p&gt;
&lt;iframe width="560" height="315" src="//www.youtube.com/embed/haBepFwyaxY" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;This bug seems to be generic for the entire game. It pops up also on
level 137 in the Owl part of the game (recorded by somebody else):&lt;/p&gt;
&lt;iframe width="420" height="315" src="//www.youtube.com/embed/6q1_LIdamqw" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;</summary><category term="QA"></category></entry><entry><title>BlackBerry Z10 is Killing My WiFi Router</title><link href="http://atodorov.org/blog/2014/12/22/blackberry-z10-is-killing-my-wifi-router/" rel="alternate"></link><updated>2014-12-22T15:46:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2014-12-22:blog/2014/12/22/blackberry-z10-is-killing-my-wifi-router/</id><summary type="html">&lt;p&gt;Few days ago I've resurrected my BlackBerry Z10 only to find out that it kills
my WiFi router shortly after connecting to the network.
It looks like many people are having the same problem with BlackBerry but most forum
threads don't offer a meaningful solution so I did some tests. &lt;/p&gt;
&lt;p&gt;Everything works fine when WiFi mode is set to either 11bgn mixed or 11n only and
WiFi security is disabled.&lt;/p&gt;
&lt;p&gt;When using WPA2/Personal security mode and AES encryption the problem occurs
regardless of which WiFi mode is used. There is another type of encryption called TKIP
but the device itself warns that this is not supported by the 802.11n specification
(all my devices use it anyway).&lt;/p&gt;
&lt;p&gt;So to recap:
&lt;strong&gt;BlackBerry Z10 causes my TP-Link router to die if using WPA2/Personal security with
AES Encryption. Switching to open network with MAC address filtering works fine!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I haven't had the time to upgrade the firmware of this router and see if the problem persists.
Most likely I'll just go ahead and flash it with OpenWRT.&lt;/p&gt;</summary><category term="BlackBerry"></category><category term="QA"></category></entry><entry><title>Speed Comparison of Web Proxies Written in Python Twisted and Go</title><link href="http://atodorov.org/blog/2014/11/19/speed-comparison-of-web-proxies-written-in-python-twisted-and-go/" rel="alternate"></link><updated>2014-11-19T16:57:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2014-11-19:blog/2014/11/19/speed-comparison-of-web-proxies-written-in-python-twisted-and-go/</id><summary type="html">&lt;p&gt;After I figured out that
&lt;a href="/blog/2014/11/11/speeding-up-celery-backends-part-3/"&gt;Celery is rather slow&lt;/a&gt;
I moved on to test another part of my environment - a web proxy server.
The test here compares two proxy 
&lt;a href="https://gist.github.com/atodorov/666035d270d97d982cd5"&gt;implementations&lt;/a&gt;
- one with Python Twisted,
the other in Go. The backend is a simple web server written in Go, which is
probably the fastest thing when it comes to serving HTML.&lt;/p&gt;
&lt;p&gt;The test content is a snapshot of the front page of this blog taken few days ago.
The system is a standard Lenovo X220 laptop, with Intel Core i7 CPU, with 4 cores.
The measurement instrument is the popular wrk tool with a
&lt;a href="/blog/2014/11/18/proxy-support-for-wrk-http-benchmarking-tool/"&gt;custom Lua script to redirect the requests through the proxy&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;All tests were repeated several times, only the best results are shown here.
I've taken time between the tests in order for all open TCP ports to close.
I've also observed the number of open ports (e.g. sockets) using &lt;code&gt;netstat&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;Baseline&lt;/h2&gt;
&lt;p&gt;Using wrk against the web server in Go yields around 30000 requests per second
with an average of 2000 TCP ports in use:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;./wrk -c1000 -t20 -d30s http://127.0.0.1:8000/atodorov.html
Running 30s &lt;span class="nb"&gt;test&lt;/span&gt; @ http://127.0.0.1:8000/atodorov.html
  &lt;span class="m"&gt;20&lt;/span&gt; threads and &lt;span class="m"&gt;1000&lt;/span&gt; connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   304.43ms  518.27ms   1.47s    82.69%
    Req/Sec     1.72k     2.45k   17.63k    88.70%
  &lt;span class="m"&gt;1016810&lt;/span&gt; requests in 29.97s, 34.73GB &lt;span class="nb"&gt;read&lt;/span&gt;
&lt;span class="nb"&gt;  &lt;/span&gt;Non-2xx or 3xx responses: 685544
Requests/sec:  33928.41
Transfer/sec:      1.16GB
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Python Twisted&lt;/h2&gt;
&lt;p&gt;The &lt;a href="https://gist.github.com/atodorov/666035d270d97d982cd5"&gt;Twisted implementation&lt;/a&gt;
performs at little over 1000 reqs/sec with an average TCP port use between 20000 and 30000:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;./wrk -c1000 -t20 -d30s http://127.0.0.1:8080 -s scripts/proxy.lua -- http://127.0.0.1:8000/atodorov.html
Running 30s test @ http://127.0.0.1:8080
  20 threads and 1000 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   335.53ms  117.26ms 707.57ms   64.77%
    Req/Sec   104.14     72.19   335.00     55.94%
  40449 requests in 30.02s, 3.67GB read
  Socket errors: connect 0, read 0, write 0, timeout 8542
  Non-2xx or 3xx responses: 5382
Requests/sec:   1347.55
Transfer/sec:    125.12MB
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Go proxy&lt;/h2&gt;
&lt;p&gt;First I've run several 30 seconds tests and performance was around 8000 req/sec
with around 20000 ports used (most of them remain in TIME_WAIT state for a while).
Then I've modified &lt;code&gt;proxy.go&lt;/code&gt; to make use of all available CPUs on the system and let
the test run for 5 minutes.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;./wrk -c1000 -t20 -d300s http://127.0.0.1:9090 -s scripts/proxy.lua -- http://127.0.0.1:8000/atodorov.html
Running 5m &lt;span class="nb"&gt;test&lt;/span&gt; @ http://127.0.0.1:9090
  &lt;span class="m"&gt;20&lt;/span&gt; threads and &lt;span class="m"&gt;1000&lt;/span&gt; connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   137.22ms  437.95ms   4.45s    97.55%
    Req/Sec   669.54    198.52     1.71k    76.40%
  &lt;span class="m"&gt;3423108&lt;/span&gt; requests in 5.00m, 58.27GB &lt;span class="nb"&gt;read&lt;/span&gt;
&lt;span class="nb"&gt;  &lt;/span&gt;Socket errors: connect 0, &lt;span class="nb"&gt;read &lt;/span&gt;26, write 181, timeout 24268
  Non-2xx or 3xx responses: 2870522
Requests/sec:  11404.19
Transfer/sec:    198.78MB
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Performance peaked at 10000 req/sec. TCP port usage initially rose to around 30000
but rapidly dropped and stayed around 3000. Both &lt;code&gt;webserver.go&lt;/code&gt; and &lt;code&gt;proxy.go&lt;/code&gt; were
printing the following messages on the console:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nt"&gt;2014&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;11&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;18&lt;/span&gt; &lt;span class="nt"&gt;21&lt;/span&gt;&lt;span class="nd"&gt;:53:06&lt;/span&gt; &lt;span class="nt"&gt;http&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;Accept&lt;/span&gt; &lt;span class="nt"&gt;error&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;accept&lt;/span&gt; &lt;span class="nt"&gt;tcp&lt;/span&gt; &lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="nd"&gt;:9090&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;too&lt;/span&gt; &lt;span class="nt"&gt;many&lt;/span&gt; &lt;span class="nt"&gt;open&lt;/span&gt; &lt;span class="nt"&gt;files&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="nt"&gt;retrying&lt;/span&gt; &lt;span class="nt"&gt;in&lt;/span&gt; &lt;span class="nt"&gt;1s&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;There's no doubt that Go is blazingly fast compared to Python and I'm most likely to use it
further in my experiments. Still I didn't expect a 3x difference in performance from webserver vs. proxy.&lt;/p&gt;
&lt;p&gt;Another thing that worries me is the huge number of open TCP ports which then drops and stays
consistent over time and the error messages from both webserver and proxy (maybe per process sockets limit).&lt;/p&gt;
&lt;p&gt;At the moment I'm not aware of the internal workings of neither wrk, nor
Go itself, nor the goproxy library to make conclusion if this is a bad thing or expected.
I'm eager to hear what others think in the comments. Thanks!&lt;/p&gt;
&lt;h2&gt;Update 2015-01-27&lt;/h2&gt;
&lt;p&gt;I have retested with PyPy but on a different system so I'm giving all the test results
on it as well. &lt;code&gt;/proc/cpuinfo&lt;/code&gt; says we have 16 x Intel(R) Xeon(R) CPU E5-2450L 0 @ 1.80GHz
CPUs. &lt;/p&gt;
&lt;p&gt;Baseline - Go server:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;./wrk -c1000 -t20 -d30s http://127.0.0.1:8000/atodorov.html
Running 30s &lt;span class="nb"&gt;test&lt;/span&gt; @ http://127.0.0.1:8000/atodorov.html
  &lt;span class="m"&gt;20&lt;/span&gt; threads and &lt;span class="m"&gt;1000&lt;/span&gt; connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    15.57ms   20.38ms 238.93ms   98.11%
    Req/Sec     3.55k     1.32k   15.91k    82.49%
  &lt;span class="m"&gt;1980738&lt;/span&gt; requests in 30.00s, 174.53GB &lt;span class="nb"&gt;read&lt;/span&gt;
&lt;span class="nb"&gt;  &lt;/span&gt;Socket errors: connect 0, &lt;span class="nb"&gt;read &lt;/span&gt;0, write 0, timeout 602
  Non-2xx or 3xx responses: 60331
Requests/sec:  66022.87
Transfer/sec:      5.82GB
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Go proxy (30 sec):&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;./wrk -c1000 -t20 -d30s http://127.0.0.1:9090 -s scripts/proxy.lua -- http://127.0.0.1:8000/atodorov.html
Running 30s &lt;span class="nb"&gt;test&lt;/span&gt; @ http://127.0.0.1:9090
  &lt;span class="m"&gt;20&lt;/span&gt; threads and &lt;span class="m"&gt;1000&lt;/span&gt; connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    68.93ms  718.98ms  12.60s    99.58%
    Req/Sec     1.61k   784.01     4.83k    62.50%
  &lt;span class="m"&gt;942757&lt;/span&gt; requests in 30.00s, 32.16GB &lt;span class="nb"&gt;read&lt;/span&gt;
&lt;span class="nb"&gt;  &lt;/span&gt;Socket errors: connect 0, &lt;span class="nb"&gt;read &lt;/span&gt;26, write 0, timeout 3050
  Non-2xx or 3xx responses: 589940
Requests/sec:  31425.47
Transfer/sec:      1.07GB
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Python proxy with &lt;code&gt;Twisted==14.0.2&lt;/code&gt; and &lt;code&gt;pypy-2.2.1-2.el7.x86_64&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;./wrk -c1000 -t20 -d30s http://127.0.0.1:8080 -s scripts/proxy.lua -- http://127.0.0.1:8000/atodorov.html
Running 30s &lt;span class="nb"&gt;test&lt;/span&gt; @ http://127.0.0.1:8080
  &lt;span class="m"&gt;20&lt;/span&gt; threads and &lt;span class="m"&gt;1000&lt;/span&gt; connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   858.75ms    1.47s    6.00s    88.09%
    Req/Sec   146.39    104.83   341.00     54.18%
  &lt;span class="m"&gt;85645&lt;/span&gt; requests in 30.00s, 853.54MB &lt;span class="nb"&gt;read&lt;/span&gt;
&lt;span class="nb"&gt;  &lt;/span&gt;Socket errors: connect 0, &lt;span class="nb"&gt;read &lt;/span&gt;289, write 0, timeout 3297
  Non-2xx or 3xx responses: 76567
Requests/sec:   2854.45
Transfer/sec:     28.45MB
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Update 2015-01-27-2&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Python proxy with &lt;code&gt;Twisted==14.0.2&lt;/code&gt; and &lt;code&gt;python-2.7.5-16.el7.x86_64&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;./wrk -c1000 -t20 -d30s http://127.0.0.1:8080 -s scripts/proxy.lua -- http://127.0.0.1:8000/atodorov.html
Running 30s &lt;span class="nb"&gt;test&lt;/span&gt; @ http://127.0.0.1:8080
  &lt;span class="m"&gt;20&lt;/span&gt; threads and &lt;span class="m"&gt;1000&lt;/span&gt; connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   739.64ms    1.58s   14.22s    96.18%
    Req/Sec    84.43     36.61   157.00     67.79%
  &lt;span class="m"&gt;49173&lt;/span&gt; requests in 30.01s, 701.77MB &lt;span class="nb"&gt;read&lt;/span&gt;
&lt;span class="nb"&gt;  &lt;/span&gt;Socket errors: connect 0, &lt;span class="nb"&gt;read &lt;/span&gt;240, write 0, timeout 2463
  Non-2xx or 3xx responses: 41683
Requests/sec:   1638.38
Transfer/sec:     23.38MB
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As seen Go proxy is slower than the Go server by factor of 2.
Python proxy is slower by than the Go server by factor of 20.
These results are similar to previous ones so I don't think PyPy
makes any significant difference.&lt;/p&gt;</summary><category term="QA"></category></entry><entry><title>Proxy Support for wrk HTTP Benchmarking Tool</title><link href="http://atodorov.org/blog/2014/11/18/proxy-support-for-wrk-http-benchmarking-tool/" rel="alternate"></link><updated>2014-11-18T10:04:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2014-11-18:blog/2014/11/18/proxy-support-for-wrk-http-benchmarking-tool/</id><summary type="html">&lt;p&gt;Few times recently I've seen people using an HTTP benchmarking tool called
&lt;a href="https://github.com/wg/wrk"&gt;wrk&lt;/a&gt; and decided to give it a try. It is a very cool
instrument but didn't fit my use case perfectly. What I needed is to be able to
redirect the connection through a web proxy and measure how much the proxy
slows down things compared to hitting the web server directly with wrk.
In other words - how fast is the proxy server.&lt;/p&gt;
&lt;h2&gt;How does a proxy work&lt;/h2&gt;
&lt;p&gt;I've examined the source code of two proxies (one in Python and another one in Go)
and what happens is this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The proxy server starts listening to a TCP port&lt;/li&gt;
&lt;li&gt;A client (e.g. the browser) sends the request using an absolute URL (GET http://example.com/about.html)&lt;/li&gt;
&lt;li&gt;Instead of connecting directly to the web server behind example.com the client connects to the proxy&lt;/li&gt;
&lt;li&gt;The proxy server does connect to example.com directly, reads the response and delivers it back to 
the client.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Proxy in wrk&lt;/h2&gt;
&lt;p&gt;Luckily wrk supports the execution of Lua scripts so we can make a 
&lt;a href="https://github.com/wg/wrk/pull/107"&gt;simple script&lt;/a&gt; like this:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nx"&gt;init&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nx"&gt;target_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;args&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt; &lt;span class="nx"&gt;proxy&lt;/span&gt; &lt;span class="nx"&gt;needs&lt;/span&gt; &lt;span class="nx"&gt;absolute&lt;/span&gt; &lt;span class="nx"&gt;URL&lt;/span&gt;
&lt;span class="nx"&gt;end&lt;/span&gt;

&lt;span class="nx"&gt;request&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;wrk&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;GET&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;target_url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then update your command line to something like this:
    ./wrk [options] http://proxy:port -s proxy.lua -- http://example.com/about.html&lt;/p&gt;
&lt;p&gt;This causes wrk to connect to our proxy server but instead issue GET requests for another URL.
Depending on how your proxy works you may need to add the &lt;code&gt;Host: example.com&lt;/code&gt; header as well.
Now let's do some testing.&lt;/p&gt;</summary><category term="QA"></category></entry><entry><title>Speeding Up Celery Backends, Part 3</title><link href="http://atodorov.org/blog/2014/11/11/speeding-up-celery-backends-part-3/" rel="alternate"></link><updated>2014-11-11T15:59:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2014-11-11:blog/2014/11/11/speeding-up-celery-backends-part-3/</id><summary type="html">&lt;p&gt;In the second part of this article we've seen 
&lt;a href="/blog/2014/11/07/speeding-up-celery-backends-part-2/"&gt;how slow Celery actually is&lt;/a&gt;.
Now let's explore what happens inside and see if we can't speed things up.&lt;/p&gt;
&lt;p&gt;I've used &lt;a href="http://pycallgraph.slowchop.com/en/latest/"&gt;pycallgraph&lt;/a&gt; to create
call graph visualizations of my application. It has the nice feature to also show
execution time and use different colors for fast and slow operations.&lt;/p&gt;
&lt;p&gt;Full command line is:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;pycallgraph -v --stdlib --include ... graphviz -o calls.png -- ./manage.py celery_load_test
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;where the &lt;code&gt;--include&lt;/code&gt; is used to limit the graph to a particular Python module(s).&lt;/p&gt;
&lt;h2&gt;General findings&lt;/h2&gt;
&lt;p&gt;&lt;img alt="call graph" src="/images/celery/general.png" title="call graph" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The first four calls is where most of the time is spent as seen on the picture. &lt;/li&gt;
&lt;li&gt;As it seems most of the slow down comes from Celery itself, not the underlying messaging
transport Kombu (not shown on picture)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;celery.app.amqp.TaskProducer.publish_task&lt;/code&gt; takes half of the execution time of
&lt;code&gt;celery.app.base.Celery.send_task&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;celery.app.task.Task.delay&lt;/code&gt; directly executes &lt;code&gt;.apply_async&lt;/code&gt; and can be skipped if one
rewrites the code.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;More findings&lt;/h2&gt;
&lt;p&gt;In &lt;code&gt;celery.app.base.Celery.send_task&lt;/code&gt; there is this block of code:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;349         with self.producer_or_acquire(producer) as P:
350             self.backend.on_task_call(P, task_id)
351             task_id = P.publish_task(
352                 name, args, kwargs, countdown=countdown, eta=eta,
353                 task_id=task_id, expires=expires,
354                 callbacks=maybe_list(link), errbacks=maybe_list(link_error),
355                 reply_to=reply_to or self.oid, **options
356             )
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;producer&lt;/code&gt; is always None because delay() doesn't pass it as argument.
I've tried passing it explicitly to apply_async() as so:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;djapp.celery&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;

&lt;span class="c"&gt;# app = debug_task._get_app() # if not defined in djapp.celery&lt;/span&gt;
&lt;span class="n"&gt;producer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;amqp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;producer_pool&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;acquire&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;block&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;debug_task&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply_async&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;producer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;producer&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;However this doesn't speedup anything. If we replace the above code block like this:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;349         with producer as P:
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;it blows up on the second iteration because producer and its channel is already None !?!&lt;/p&gt;
&lt;p&gt;If you are unfamiliar with the with statement in Python please read
&lt;a href="http://effbot.org/zone/python-with-statement.htm"&gt;this article&lt;/a&gt;. In short the with statement is
a compact way of writing try/finally. The underlying &lt;code&gt;kombu.messaging.Producer&lt;/code&gt; class does a
&lt;code&gt;self.release()&lt;/code&gt; on exit of the with statement.&lt;/p&gt;
&lt;p&gt;I also tried killing the with statement and using producer directly but with limited success. While
it was not released(was non None) on subsequent iterations the memory usage grew much more and there
wasn't any performance boost.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The with statement is used throughout both Celery and Kombu and I'm not at all sure if
there's a mechanism for keep-alive connections. My time constraints are limited and I'll probably
not spend anymore time on this problem soon.&lt;/p&gt;
&lt;p&gt;Since my use case involves task producer and consumers on localhost I'll try to workaround the
current limitations by using Kombu directly 
(see &lt;a href="https://gist.github.com/atodorov/2bc1fcd34531ad260ed7"&gt;this gist&lt;/a&gt;) with a transport that
uses either a UNIX domain socket or a name pipe (FIFO) file.&lt;/p&gt;</summary><category term="Python"></category><category term="Django"></category><category term="QA"></category></entry><entry><title>Speeding up Celery Backends, Part 2</title><link href="http://atodorov.org/blog/2014/11/07/speeding-up-celery-backends-part-2/" rel="alternate"></link><updated>2014-11-07T15:48:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2014-11-07:blog/2014/11/07/speeding-up-celery-backends-part-2/</id><summary type="html">&lt;p&gt;In the &lt;a href="/blog/2014/11/05/speeding-up-celery-backends/"&gt;first part&lt;/a&gt; of this
post I looked at a few celery backends and discovered they didn't meet my needs.
Why is the Celery stack slow? How slow is it actually?&lt;/p&gt;
&lt;h2&gt;How slow is Celery in practice&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Queue: 500`000 msg/sec&lt;/li&gt;
&lt;li&gt;Kombu:  14`000 msg/sec&lt;/li&gt;
&lt;li&gt;Celery:  2`000 msg/sec&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Detailed test description&lt;/h2&gt;
&lt;p&gt;There are three main components of the Celery stack: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Celery itself&lt;/li&gt;
&lt;li&gt;Kombu which handles the transport layer&lt;/li&gt;
&lt;li&gt;Python Queue()'s underlying everything&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Using the &lt;a href="https://gist.github.com/atodorov/2bc1fcd34531ad260ed7"&gt;Queue and Kombu tests&lt;/a&gt;
run for 1 000 000 messages I got the following results:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Raw Python Queue: Msgs per sec: 500`000&lt;/li&gt;
&lt;li&gt;Raw Kombu without Celery where &lt;code&gt;kombu/utils/__init__.py:uuid()&lt;/code&gt; is set to return 0&lt;ul&gt;
&lt;li&gt;with json serializer: Msgs per sec: 5`988&lt;/li&gt;
&lt;li&gt;with pickle serializer: Msgs per sec: 12`820&lt;/li&gt;
&lt;li&gt;with the custom mem_serializer from &lt;a href="/blog/2014/11/05/speeding-up-celery-backends/"&gt;part 1&lt;/a&gt;:
Msgs per sec: 14`492&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; when the test is executed with 100K messages mem_serializer yielded
25`000 msg/sec then the performance is saturated. I've observed similar behavior 
with raw Python Queue()'s. I saw some cache buffers being managed internally to avoid OOM
exceptions. This is probably the main reason performance becomes saturated over a longer
execution.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using &lt;a href="https://gist.github.com/atodorov/0156cc41491a5e1ff953"&gt;celery_load_test.py&lt;/a&gt; modified to
loop 1 000 000 times I got 1908.0 tasks created per sec.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Another interesting this worth outlining - in the kombu test there are these lines:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;with producers[connection].acquire(block=True) as producer:
    for j in range(1000000):
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If we swap them the performance drops down to 3875 msg/sec which is comparable with the
Celery results. Indeed inside Celery there's the same &lt;code&gt;with producer.acquire(block=True)&lt;/code&gt;
construct which is executed every time a new task is published. Next I will be looking 
into this to figure out exactly where the slowliness comes from.&lt;/p&gt;</summary><category term="Python"></category><category term="Django"></category><category term="QA"></category></entry><entry><title>Speeding up Celery Backends, Part 1</title><link href="http://atodorov.org/blog/2014/11/05/speeding-up-celery-backends/" rel="alternate"></link><updated>2014-11-05T15:20:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2014-11-05:blog/2014/11/05/speeding-up-celery-backends/</id><summary type="html">&lt;p&gt;I'm working on an application which fires a lot of Celery tasks - the more
the better! Unfortunately Celery backends seem to be rather slow :(.
Using the &lt;a href="https://gist.github.com/atodorov/0156cc41491a5e1ff953"&gt;celery_load_test.py&lt;/a&gt;
command for Django I was able to capture some metrics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Amazon SQS backend: 2 or 3 tasks/sec&lt;/li&gt;
&lt;li&gt;Filesystem backend: 2000 - 2500 tasks/sec&lt;/li&gt;
&lt;li&gt;Memory backend: around 3000 tasks/sec&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Not bad but I need in the order of 10000 tasks created per sec!
The other noticeable thing is that memory backend isn't much faster compared to
the filesystem one! NB: all of these backends actually come from the kombu package.&lt;/p&gt;
&lt;h2&gt;Why is Celery slow ?&lt;/h2&gt;
&lt;p&gt;Using &lt;code&gt;celery_load_test.py&lt;/code&gt; together with 
&lt;a href="/blog/2014/11/05/performance-profiling-in-python-with-cprofile/"&gt;cProfile&lt;/a&gt; I
was able to pin-point some problematic areas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;kombu/transports/virtual/__init__.py&lt;/code&gt;: class Channel.basic_publish() - does
self.encode_body() into base64 encoded string. Fixed with custom transport backend
I called fastmemory which redefines the body_encoding property:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nd"&gt;@cached_property&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;body_encoding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Celery uses json or pickle (or other) serializers to serialize the data.
While json yields between 2000-3000 tasks/sec, pickle does around 3500 tasks/sec.
Replacing with a custom serializer which just returns
the objects (since we read/write from/to memory) yields about 4000 tasks/sec tops:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;kombu.serialization&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;register&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;loads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;dumps&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;

&lt;span class="n"&gt;register&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;mem_serializer&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dumps&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;content_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;application/x-memory&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;content_encoding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;binary&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;kombu/utils/__init__.py&lt;/code&gt;: def uuid() - generates random unique identifiers
which is a slow operation. Replacing it with &lt;code&gt;return "00000000"&lt;/code&gt; boosts performance
to 7000 tasks/sec.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It's clear that a constant UUID is not of any practical use but serves well to illustrate
how much does this function affect performance. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;
Subsequent executions of &lt;code&gt;celery_load_test&lt;/code&gt; seem to report degraded performance even with
the most optimized transport backend. I'm not sure why is this. One possibility is the random
UUID usage in other parts of the Celery/Kombu stack which drains entropy on the system and
generating more random numbers becomes slower. If you know better please tell me!&lt;/p&gt;
&lt;p&gt;I will be looking for a better understanding
of these IDs in Celery and hope to be able to produce a faster uuid() function. Then I'll be
exploring the transport stack even more in order to reach the goal of 10000 tasks/sec.
If you have any suggestions or pointers please share them in the comments.&lt;/p&gt;</summary><category term="Python"></category><category term="Django"></category><category term="QA"></category></entry><entry><title>Performance Profiling in Python with cProfile</title><link href="http://atodorov.org/blog/2014/11/05/performance-profiling-in-python-with-cprofile/" rel="alternate"></link><updated>2014-11-05T14:40:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2014-11-05:blog/2014/11/05/performance-profiling-in-python-with-cprofile/</id><summary type="html">&lt;p&gt;This is a quick reference on profiling Python applications with
&lt;a href="https://docs.python.org/2/library/profile.html#module-cProfile"&gt;cProfile&lt;/a&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;python -m cProfile -s &lt;span class="nb"&gt;time &lt;/span&gt;application.py
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The output is sorted by execution time &lt;code&gt;-s time&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;     &lt;span class="mi"&gt;9072842&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;calls&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;8882140&lt;/span&gt; &lt;span class="nx"&gt;primitive&lt;/span&gt; &lt;span class="nx"&gt;calls&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="mf"&gt;9.830&lt;/span&gt; &lt;span class="nx"&gt;CPU&lt;/span&gt; &lt;span class="nx"&gt;seconds&lt;/span&gt;

   &lt;span class="nx"&gt;Ordered&lt;/span&gt; &lt;span class="nx"&gt;by&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;internal&lt;/span&gt; &lt;span class="nx"&gt;time&lt;/span&gt;

   &lt;span class="nx"&gt;ncalls&lt;/span&gt;  &lt;span class="nx"&gt;tottime&lt;/span&gt;  &lt;span class="nx"&gt;percall&lt;/span&gt;  &lt;span class="nx"&gt;cumtime&lt;/span&gt;  &lt;span class="nx"&gt;percall&lt;/span&gt; &lt;span class="nx"&gt;filename&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="nx"&gt;lineno&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;function&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="mi"&gt;61868&lt;/span&gt;    &lt;span class="mf"&gt;0.575&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt;    &lt;span class="mf"&gt;0.861&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt; &lt;span class="kr"&gt;abstract&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;py&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="mi"&gt;41250&lt;/span&gt;    &lt;span class="mf"&gt;0.527&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt;    &lt;span class="mf"&gt;0.660&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt; &lt;span class="nx"&gt;uuid&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;py&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;101&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="mi"&gt;61863&lt;/span&gt;    &lt;span class="mf"&gt;0.405&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt;    &lt;span class="mf"&gt;1.054&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt; &lt;span class="kr"&gt;abstract&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;py&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;as_dict&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="mi"&gt;41243&lt;/span&gt;    &lt;span class="mf"&gt;0.343&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt;    &lt;span class="mf"&gt;1.131&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt; &lt;span class="nx"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;py&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;143&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;uuid4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
   &lt;span class="mi"&gt;577388&lt;/span&gt;    &lt;span class="mf"&gt;0.338&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt;    &lt;span class="mf"&gt;0.649&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt; &lt;span class="kr"&gt;abstract&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;py&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;46&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nx"&gt;genexpr&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="mi"&gt;20622&lt;/span&gt;    &lt;span class="mf"&gt;0.289&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt;    &lt;span class="mf"&gt;8.824&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt; &lt;span class="nx"&gt;base&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;py&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;331&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;send_task&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="mi"&gt;61907&lt;/span&gt;    &lt;span class="mf"&gt;0.232&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt;    &lt;span class="mf"&gt;0.477&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt; &lt;span class="nx"&gt;datastructures&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;py&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;467&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;__getitem__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="mi"&gt;20622&lt;/span&gt;    &lt;span class="mf"&gt;0.225&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt;    &lt;span class="mf"&gt;9.298&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt; &lt;span class="nx"&gt;task&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;py&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;455&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;apply_async&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="mi"&gt;61863&lt;/span&gt;    &lt;span class="mf"&gt;0.218&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt;    &lt;span class="mf"&gt;2.502&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt; &lt;span class="kr"&gt;abstract&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;py&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;__copy__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="mi"&gt;20621&lt;/span&gt;    &lt;span class="mf"&gt;0.208&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt;    &lt;span class="mf"&gt;4.766&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt; &lt;span class="nx"&gt;amqp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;py&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;208&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;publish_task&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
   &lt;span class="mi"&gt;462640&lt;/span&gt;    &lt;span class="mf"&gt;0.193&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt;    &lt;span class="mf"&gt;0.247&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
   &lt;span class="mi"&gt;515525&lt;/span&gt;    &lt;span class="mf"&gt;0.162&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt;    &lt;span class="mf"&gt;0.193&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt; &lt;span class="kr"&gt;abstract&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;py&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;41&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="mi"&gt;41246&lt;/span&gt;    &lt;span class="mf"&gt;0.153&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt;    &lt;span class="mf"&gt;0.633&lt;/span&gt;    &lt;span class="mf"&gt;0.000&lt;/span&gt; &lt;span class="nx"&gt;entity&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;py&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;143&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In the example above (actual application) first line is kombu's
&lt;code&gt;abstract.py: class Object(object).__init__()&lt;/code&gt;
and the second one is Python's
&lt;code&gt;uuid.py: class UUID().__init__()&lt;/code&gt;.&lt;/p&gt;</summary><category term="Python"></category><category term="QA"></category></entry><entry><title>SNAKE is no Longer Needed to Run Installation Tests in Beaker</title><link href="http://atodorov.org/blog/2014/07/18/snake-is-no-longer-needed-to-run-installation-tests-in-beaker/" rel="alternate"></link><updated>2014-07-18T23:05:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2014-07-18:blog/2014/07/18/snake-is-no-longer-needed-to-run-installation-tests-in-beaker/</id><summary type="html">&lt;p&gt;This is a quick status update for one of the pieces of
&lt;a href="/blog/2013/11/19/open-source-quality-assurance-infrastructure-for-fedora-qa/"&gt;Fedora QA infrastructure&lt;/a&gt;
and mostly a self-note.&lt;/p&gt;
&lt;p&gt;Previously to control the kickstart configuration used during installation in Beaker one
had to either modify the job XML in Beaker or use SNAKE (&lt;code&gt;bkr workflow-snake&lt;/code&gt;) to render
a kickstart configuration from a Python template.&lt;/p&gt;
&lt;p&gt;SNAKE presented challenges when deploying and using
&lt;a href="https://beaker.fedoraproject.org"&gt;beaker.fedoraproject.org&lt;/a&gt; and is
virtually unmaintained.&lt;/p&gt;
&lt;p&gt;I present the new &lt;code&gt;bkr workflow-installer-test&lt;/code&gt; which uses Jinja2 templates to
generate a kickstart configuration when provisioning the system. This is already
available in beaker-client-0.17.1.&lt;/p&gt;
&lt;p&gt;The templates make use of all Jinja2 features (as far as I can tell) so you can create
very complex ones. You can even include snippets from one template into another if required.
The standard context that is passed to the template is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;DISTRO&lt;/strong&gt; - if specified, the distro name&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FAMILY&lt;/strong&gt; - as returned by Beaker server, e.g. &lt;em&gt;RedHatEnterpriseLinux6&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OS_MAJOR&lt;/strong&gt; and &lt;strong&gt;OS_MINOR&lt;/strong&gt; - also taken from Beaker server. e.g. OS_MAJOR=6 and OS_MINOR=5 for RHEL 6.5&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;VARIANT&lt;/strong&gt; - if specified&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ARCH&lt;/strong&gt; - CPU architecture like x86_64&lt;/li&gt;
&lt;li&gt;any parameters passed to the test job with &lt;code&gt;--taskparam&lt;/code&gt;. They are processed last and can override previous values.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Installation related tests at &lt;a href="https://bitbucket.org/fedoraqa/fedora-beaker-tests"&gt;fedora-beaker-tests&lt;/a&gt;
have been updated with a &lt;code&gt;ks.cfg.tmpl&lt;/code&gt; templates to use with this new workflow.&lt;/p&gt;
&lt;p&gt;This workflow also has the ability to return boot arguments for the installer if needed. 
If any, they should be defined in a &lt;code&gt;{% block kernel_options %}{% endblock %}&lt;/code&gt;
block inside the template. A simpler variant is to define a comment line that stars with
&lt;em&gt;## kernel_options:&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;There are still a few issues which need to be fixed before beaker.fedoraproject.org
can be used by the general public though. I will be writing another post about that
so stay tuned.&lt;/p&gt;</summary><category term="Fedora"></category><category term="QA"></category></entry><entry><title>How Do You Test Thai Scalable Fonts</title><link href="http://atodorov.org/blog/2014/03/17/how-do-you-test-thai-scalable-fonts/" rel="alternate"></link><updated>2014-03-17T22:51:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2014-03-17:blog/2014/03/17/how-do-you-test-thai-scalable-fonts/</id><summary type="html">&lt;p&gt;Recently I wrote about &lt;a href="/blog/2014/03/04/how-do-you-test-fonts/"&gt;testing fonts&lt;/a&gt;.
I finally managed to get an answer from the authors of &lt;em&gt;thai-scalable-fonts&lt;/em&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;What is your approach for testing Fonts-TLWG?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It's not automated test. What it does is generate PDF with sample
texts at several sizes (the waterfall), pangrams, and glyph table.
It needs human eyes to investigate.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;What kind of problems is your test suite designed for ?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Shaping&lt;/li&gt;
&lt;li&gt;Glyph coverage&lt;/li&gt;
&lt;li&gt;Metrics&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We also make use of fontforge features to make spotting errors
easier, such as
- Show extremas
- Show almost vertical/horizontal lines/curves&lt;/p&gt;
&lt;p&gt;Theppitak Karoonboonyanan, Fonts-TLWG&lt;/p&gt;
&lt;/blockquote&gt;</summary><category term="Fedora"></category><category term="QA"></category></entry><entry><title>How do You Test Fonts</title><link href="http://atodorov.org/blog/2014/03/04/how-do-you-test-fonts/" rel="alternate"></link><updated>2014-03-04T21:30:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2014-03-04:blog/2014/03/04/how-do-you-test-fonts/</id><summary type="html">&lt;p&gt;&lt;a href="/blog/2014/03/03/last-week-in-fedora-qa/"&gt;Previously&lt;/a&gt; I mentioned about testing
fonts but didn't have any idea how this is done. Authors
Khaled Hosny of &lt;a href="http://www.amirifont.org/"&gt;Amiri Font&lt;/a&gt; and Steve White of
&lt;a href="http://www.gnu.org/software/freefont/"&gt;GNU FreeFont&lt;/a&gt; provided valuable insight
and material for further reading. I've asked them:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is your approach for testing ?&lt;/li&gt;
&lt;li&gt;What kind of problems is your test suite designed for ?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here's what they say:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Currently my test suite consists of text strings (or lists of code
points) and expected output glyph sequences and then use HarfBuzz
(through its hb-shape command line tool) to check that the fonts always
output the expected sequence of glyphs, sometimes with the expected
positioning as well. Amiri is a complex font that have many glyph
substitution and positioning rules, so the test suite is designed to
make sure those rules are always executed correctly to catch regressions
in the font (or in HarfBuzz, which sometimes happens since the things I
do in my fonts are not always that common).&lt;/p&gt;
&lt;p&gt;I think Lohit project do similar testing for their fonts, and HarfBuzz
itself has a similar test suite with a bunch of nice scripts (though
they are not installed when building HarfBuzz, yet[1]).&lt;/p&gt;
&lt;p&gt;Recently I added more kinds of tests, namely checking that OTS[2]
sanitizes the fonts successfully as this is important for using them on
the web, and a test for a common mistakes I made in my feature files
that result in unexpected blank glyphs in the fonts.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://github.com/behdad/harfbuzz/pull/12"&gt;https://github.com/behdad/harfbuzz/pull/12&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/khaledhosny/ots"&gt;https://github.com/khaledhosny/ots&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Khaled Hosny, Amiri Font&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;The answer is complicated.  I'll do what I can to answer.&lt;/p&gt;
&lt;p&gt;First, the FontForge application has a "verification" function which
can be run from a script, and which identifies numerous technical
problems.&lt;/p&gt;
&lt;p&gt;FontForge also has a "Find Problems" function that I run by hand.&lt;/p&gt;
&lt;p&gt;The monospaced face has special restrictions, first that all glyphs of
non-zero width must be of the same width, and second, that all glyphs
lie within the vertical bounds of the font.&lt;/p&gt;
&lt;p&gt;Beside this, I have several other scripts that check for a few things
that FontForge doesn't (duplicate names, that glyph slots agree with
Unicode code within Unicode character blocks).&lt;/p&gt;
&lt;p&gt;Several tests scripts have yet to be uploaded to the version control
system -- because I'm unsure of them.&lt;/p&gt;
&lt;p&gt;There is a more complicated check of TrueType tables, which attempts
to find cases of tables that have been "shadowed" by the
script/language specification of another table.  This is helpful, but
works imperfectly.&lt;/p&gt;
&lt;p&gt;ALL THAT SAID,&lt;/p&gt;
&lt;p&gt;In the end, every script used in the font has to be visually checked.
This process takes me weeks, and there's nothing systematic about it,
except that I look at printout of documents in each language to see if
things have gone awry.&lt;/p&gt;
&lt;p&gt;For a few documents in a few languages, I have images of how text
&lt;em&gt;should&lt;/em&gt; look, and can compare that visually (especially important for
complex scripts.)&lt;/p&gt;
&lt;p&gt;A few years back, somebody wrote a clever script that generated images
of text and compared them pixel-by-pixel.  This was a great idea, and
I wish I could use it more effectively, but the problem was that it
was much too sensitive.  A small change to the font (e.g. PostScript
parameters) would cause a small but global change in the rendering.
Also the rendering could vary from one version of the rendering
software to another.  So I don't use this anymore.&lt;/p&gt;
&lt;p&gt;That's all I can think of right now.&lt;/p&gt;
&lt;p&gt;In fact, testing has been a big problem in getting releases out.  In
the past, each release has taken at least two weeks to test, and then
another week to fix and bundle...if I was lucky.  And for the past
couple of years, I just haven't been able to justify the time
expenditure.  (Besides this, there are still a few serious problems
with the fonts--once again, a matter of time.)&lt;/p&gt;
&lt;p&gt;Have a look at the bugs pages, to get an idea of work being done.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://savannah.gnu.org/bugs/?group=freefont"&gt;http://savannah.gnu.org/bugs/?group=freefont&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Steve White, GNU FreeFont&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I'm not sure if ImageMagic or PIL can help solve the rendering and compare
problem Steve is talking about. They can definitely be used for
&lt;a href="/blog/2013/05/17/linux-and-python-tools-to-compare-images/"&gt;image comparison&lt;/a&gt;
so maybe coupled with some rendering library it's worth a quick try.&lt;/p&gt;
&lt;p&gt;If you happen to know more about fonts, please join me in 
&lt;a href="/blog/2014/02/28/action-improving-test-coverage-in-fedora/"&gt;improving overall test coverage in Fedora&lt;/a&gt;
by designing test suites for fonts packages.&lt;/p&gt;</summary><category term="Fedora"></category><category term="QA"></category></entry><entry><title>Last Week in Fedora QA</title><link href="http://atodorov.org/blog/2014/03/03/last-week-in-fedora-qa/" rel="alternate"></link><updated>2014-03-03T10:23:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2014-03-03:blog/2014/03/03/last-week-in-fedora-qa/</id><summary type="html">&lt;p&gt;Here are some highlights from the past week discussions in Fedora which I found
interesting or participated in.&lt;/p&gt;
&lt;h2&gt;Call to Action: Improving Overall Test Coverage in Fedora&lt;/h2&gt;
&lt;p&gt;I can not stress enough how important it is to further
&lt;a href="/blog/2014/02/28/action-improving-test-coverage-in-fedora/"&gt;improve test coverage in Fedora&lt;/a&gt;!
You can help too. Here's how:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Join upstream and create a test suite for a package you find interesting;&lt;/li&gt;
&lt;li&gt;Provide patches - &lt;a href="https://lists.fedoraproject.org/pipermail/devel/2014-February/196035.html"&gt;first patch&lt;/a&gt;
came in less than 30 minutes of initial announcement :);&lt;/li&gt;
&lt;li&gt;Review packages in the wiki and help identify false negatives;&lt;/li&gt;
&lt;li&gt;Forward to people who may be interested to work on these items;&lt;/li&gt;
&lt;li&gt;Share and promote in your local open source and developer communities;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Auto BuildRequires&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://people.redhat.com/~rjones/auto-buildrequires/"&gt;Auto-BuildRequires&lt;/a&gt;
is a simple set of scripts which compliments &lt;code&gt;rpmbuild&lt;/code&gt; by
automatically suggesting BuildRequires lines for the just built package.&lt;/p&gt;
&lt;p&gt;It would be interesting to have this integrated into Koji and/or
continuous integration environment and compare the output between every two
consecutive builds (iow older and newer package versions). It sounds like a
good way to identify newly added or removed dependencies and update the package
specs accordingly.&lt;/p&gt;
&lt;h2&gt;How To Test Fonts Packages&lt;/h2&gt;
&lt;p&gt;This is exactly what 
&lt;a href="https://lists.fedoraproject.org/pipermail/test/2014-February/120570.html"&gt;Christopher Meng asked&lt;/a&gt;
and frankly I have no idea. &lt;/p&gt;
&lt;p&gt;I've come across a few fonts packages (&lt;em&gt;amiri-fonts&lt;/em&gt;, &lt;em&gt;gnu-free-fonts&lt;/em&gt; and &lt;em&gt;thai-scalable-fonts&lt;/em&gt;)
which seem to have some sort of test suites but I don't know how they work or
what type of problems they test for. On top of that all three have a different
way of doing things (e.g. not using a standardized test framework or a variation of such).&lt;/p&gt;
&lt;p&gt;I'll keep you posted on this once I manage to get more info from upstream developers.&lt;/p&gt;
&lt;h2&gt;Is URL Field in RPM Useless&lt;/h2&gt;
&lt;p&gt;So is it? Opinions here differ from totally useless to "don't remove it, I need it".
However I run a small test and from 2574 RPMs on the source DVD there is around 
40% of "something different than HTTP 200 OK". This means &lt;strong&gt;40% potentially broken URLs&lt;/strong&gt;!&lt;/p&gt;
&lt;p&gt;The majority are responses in the 3XX range and only less than 10% are 
actual errors (4XX, 5XX, missing URLs or connection errors).&lt;/p&gt;
&lt;p&gt;It will be interesting to see if this can be removed from &lt;code&gt;rpm&lt;/code&gt; altogether.
I don't think it will happen soon but if we don't use it why have it there? &lt;/p&gt;
&lt;p&gt;My script for the test is
&lt;a href="https://github.com/atodorov/fedora-scripts/blob/master/test-rpm-url-field.sh"&gt;here&lt;/a&gt;.&lt;/p&gt;</summary><category term="Fedora"></category><category term="QA"></category></entry><entry><title>Call to Action: Improving Overall Test Coverage in Fedora</title><link href="http://atodorov.org/blog/2014/02/28/action-improving-test-coverage-in-fedora/" rel="alternate"></link><updated>2014-02-28T14:46:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2014-02-28:blog/2014/02/28/action-improving-test-coverage-in-fedora/</id><summary type="html">&lt;p&gt;Around Christmas 2013
&lt;a href="/blog/2013/12/24/upstream-test-suite-status-of-fedora-20/"&gt;I said&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;... it looks like on average 30% of the packages execute their test suites at
build time in the %check section and less than 35% have test suites at all!
There’s definitely room for improvement and I plan to focus on this during 2014!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I've recently started working on this goal by first identifying potential offending
packages and discussing the idea on Fedora's
&lt;a href="https://lists.fedoraproject.org/pipermail/devel/2014-February/thread.html"&gt;devel&lt;/a&gt;,
&lt;a href="https://lists.fedoraproject.org/pipermail/packaging/2014-February/thread.html"&gt;packaging&lt;/a&gt;
and &lt;a href="https://lists.fedoraproject.org/pipermail/test/2014-February/thread.html"&gt;test&lt;/a&gt;
mailing lists.&lt;/p&gt;
&lt;p&gt;May I present you nearly &lt;strong&gt;2000 packages&lt;/strong&gt; which need your love:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://fedoraproject.org/wiki/QA/Testing_in_check"&gt;wiki/QA/Testing_in_check&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://fedoraproject.org/wiki/QA/Missing_upstream_test_suites"&gt;wiki/QA/Missing_upstream_test_suites&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The intent for these pages is to serve as a source of working material for Fedora 
volunteers.&lt;/p&gt;
&lt;h2&gt;How Can I Help&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Join upstream and create a test suite for a package you find interesting;&lt;/li&gt;
&lt;li&gt;Provide patches - &lt;a href="https://lists.fedoraproject.org/pipermail/devel/2014-February/196035.html"&gt;first patch&lt;/a&gt;
came in less than 30 minutes of initial announcement :);&lt;/li&gt;
&lt;li&gt;Review packages in the wiki and help identify false negatives;&lt;/li&gt;
&lt;li&gt;Forward to people who may be interested to work on these items;&lt;/li&gt;
&lt;li&gt;Share and promote in your local open source and developer communities;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Important&lt;/h2&gt;
&lt;p&gt;If you would like to gain some open source practice and QA experience I will
happily provide mentorship and general help so you can start working on Fedora.
Just ping me!&lt;/p&gt;</summary><category term="Fedora"></category><category term="QA"></category></entry><entry><title>7 Years and 1400 Bugs Later as Red Hat QA</title><link href="http://atodorov.org/blog/2014/02/19/7-years-1400-bugs-red-hat-qa/" rel="alternate"></link><updated>2014-02-19T10:43:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2014-02-19:blog/2014/02/19/7-years-1400-bugs-red-hat-qa/</id><summary type="html">&lt;p&gt;Today I celebrate my 7th year working at Red Hat's Quality Engineering department.
Here's my story!&lt;/p&gt;
&lt;p&gt;&lt;img alt="Platform QE" src="/images/redhat_platform_qe.jpg" title="Platform QE" /&gt;&lt;/p&gt;
&lt;p&gt;On a cold winter Friday in 2007 I left my job as a software developer in Sofia,
packed my stuff together, purchased my &lt;a href="http://amzn.to/1hlPuyr"&gt;first laptop&lt;/a&gt; and
on Sunday jumped the train to Brno to join the Release Test Team at Red Hat.
Little did I know what it was all about. When I was offered the position
I was on a very noisy bus and had to pick between two positions. I didn't quite understood
what were the options and just picked the second one.
Luckily everything turned out great and continues to this day.&lt;/p&gt;
&lt;p&gt;I'm sharing my experience and highlighting some bugs which I've found.
Hopefully you will find this interesting and amusing. If you are a QA engineer
I urge you to take a look at &lt;a href="http://red.ht/1gbHElQ"&gt;my public bug portfolio&lt;/a&gt;,
dive into details, read the comments and learn as much as you can.&lt;/p&gt;
&lt;h2&gt;What do I do exactly&lt;/h2&gt;
&lt;p&gt;From all QE teams in Red Hat, Release Test Team is the first one and
last one to test a release. The team has both technical function and a more managerial one.
Our focus is on the core Red Hat Enterprise Linux product. 
Unfortunately I can't go into much details because this is not a public facing unit.
I will limit myself to &lt;strong&gt;public and/or non-sensitive information&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;We are the first to test a new nightly build or a
snapshot of the upcoming RHEL release. If the tree is installable other teams take over
and do their magic. At the end when bits are published live we're the last to
verify that content is published where it is expected to be. In short this is
covering the work of the release engineering team which is to build a product and
publish the contents for consumption.&lt;/p&gt;
&lt;p&gt;The same principles apply to Fedora although the engagement here is less demanding.&lt;/p&gt;
&lt;p&gt;Personally I have been and continue to be responsible for Red Hat Enterprise Linux 5
family of releases. It's up to me to give the go ahead for further testing or request
a re-spin. This position
also has the power to block and delay the GA release if not happy with testing or
there is a considerable risk of failure until things are sorted out.&lt;/p&gt;
&lt;p&gt;Like in other QA teams I create test plan documents, write test case scenarios,
implement test automation scripts (and sometimes tools), regularly execute said test
plans and test cases, find and report any new bugs and verify old ones are fixed. 
Most importantly make sure RHEL installs and is usable for further testing :).&lt;/p&gt;
&lt;p&gt;Sometimes I have to deal with capacity planning and as RHEL 5 installation 
test lead I have to organize and manage the entire installation testing campaign
for that product.&lt;/p&gt;
&lt;p&gt;My favorite testing technique is
&lt;a href="https://en.wikipedia.org/wiki/Exploratory_testing"&gt;exploratory testing&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Stats and Numbers&lt;/h2&gt;
&lt;p&gt;It is hard (if not impossible) to &lt;a href="https://github.com/atodorov/qe-metrics"&gt;measure QA work&lt;/a&gt;
with numbers alone but here are some interesting facts about my experience so far.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nearly 1400 bugs filed (1390 at the time of writing);&lt;/li&gt;
&lt;li&gt;Reported bugs across 32 different products. Top 3 being RHEL 6, RHEL 5 and Fedora (1000+ bugs);&lt;/li&gt;
&lt;li&gt;Top 3 components for reporting bugs against: anaconda, releng, kernel;&lt;/li&gt;
&lt;li&gt;Nearly 100 bugs filed in my first year 2007;&lt;/li&gt;
&lt;li&gt;The 3 most productive years being 2010, 2009, 2011 (800 + bugs); &lt;/li&gt;
&lt;li&gt;Filed 200 bugs/year which is about 1 bug/day considering holidays;&lt;/li&gt;
&lt;li&gt;35th top bug reporter (excluding robot accounts). I was in top 10 a few years back;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Many of &lt;a href="http://red.ht/1gbHElQ"&gt;the bugs I report&lt;/a&gt; are private so if you'd like
to know more stats just ask me and I'll see what I can do.&lt;/p&gt;
&lt;h2&gt;2007&lt;/h2&gt;
&lt;p&gt;My very first bug is &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=231860"&gt;RHBZ #231860&lt;/a&gt;(private)
which is about the graphical update tool Pup which used to show the wrong number of available
updates.&lt;/p&gt;
&lt;p&gt;Then I've played with adding &lt;a href="https://fedorahosted.org/dogtail/"&gt;Dogtail&lt;/a&gt; support to Anaconda.
While initially this was rejected (Fedora 6/7), it was &lt;a href="https://fedoraproject.org/wiki/Anaconda/Features/Dogtail"&gt;implemented&lt;/a&gt;
few years later (Fedora 9) and then removed once again during the big Anaconda rewrite.&lt;/p&gt;
&lt;p&gt;I've spent my time working extensively on RHEL 5 battling with multi-lib issues, SELinux denials and
generally making the 5 family less rough. Because I was still on-boarding I generally worked
on everything I could get my hands on and also did some work on RHEL3-U9 (latest release
before EOL) and some RHEL4-U6 testing.&lt;/p&gt;
&lt;p&gt;With ia64 on RHEL3 I found a corner case
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=240782"&gt;kernel bug&lt;/a&gt; which flooded the serial
console with messages and caused a multi-CPU system to freeze.&lt;/p&gt;
&lt;h2&gt;In 2008 Time went backwards&lt;/h2&gt;
&lt;p&gt;My first bug in 2008 is &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=428280"&gt;RHBZ #428280&lt;/a&gt;.
glibc introduced SHA-256/512 hashes for hashing passwords with crypt but that wasn't documented.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;UPDATE 2014-02-21&lt;/strong&gt;
While testing 5.1 to 5.2 updates I found
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=435475"&gt;RHBZ #435475&lt;/a&gt; - a severe
&lt;strong&gt;performance degradation&lt;/strong&gt; in the package installation process. Upgrades
took almost twice as much time to complete, rising &lt;strong&gt;from 4 hours to 7 hours&lt;/strong&gt;
depending on hardware and package set. This was a tough one to test and verify.
&lt;strong&gt;END UPDATE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;While dogfooding the 5.2 beta in March I hit
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=437252"&gt;RHBZ #437252&lt;/a&gt; - kernel: Timer ISR/0: Time went backwards.
To this date this is one of my favorite bugs with a great error message!&lt;/p&gt;
&lt;p&gt;Removal of a hack in RPM led to file conflicts under &lt;code&gt;/usr/share/doc&lt;/code&gt; in several packages:
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=448905"&gt;RHBZ #448905&lt;/a&gt;,
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=448906"&gt;RHBZ #448906&lt;/a&gt;,
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=448907"&gt;RHBZ #448907&lt;/a&gt;,
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=448909"&gt;RHBZ #448909&lt;/a&gt;,
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=448910"&gt;RHBZ #448910&lt;/a&gt;,
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=448911"&gt;RHBZ #448911&lt;/a&gt;
which is also the first time I happen to file several bugs in a row.&lt;/p&gt;
&lt;p&gt;ia64 couldn't boot with encrypted partitions -
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=464769"&gt;RHBZ #464769&lt;/a&gt;,
RHEL 5 introduced support for ext4 - &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=465248"&gt;RHBZ #465248&lt;/a&gt;
and I've hit a fontconfig issue during upgrades - &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=469190"&gt;RHBZ #469190&lt;/a&gt;
which continued to resurface occasionally during the next 5 years.&lt;/p&gt;
&lt;p&gt;This is the year when I took over responsibility for the general installation
testing of RHEL 5 from James Laska and will continue to do so until it reaches end-of-life!&lt;/p&gt;
&lt;p&gt;I've also worked on RHEL 4, Fedora and even the OLPC project. On the testing side of things
I've participated in testing
&lt;a href="https://fedoraproject.org/wiki/QA/TestPlans/Networking"&gt;Fedora networking on the XO&lt;/a&gt;
hardware and worked on translation and general issues.&lt;/p&gt;
&lt;h2&gt;2009 - here comes RHEL 6&lt;/h2&gt;
&lt;p&gt;This year starts my 3 most productive years period. &lt;/p&gt;
&lt;p&gt;The second bug reported this
year is &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=481338"&gt;RHBZ #481338&lt;/a&gt; which
also mentions one of my hobbies - wrist watches. While browsing a particular
website Xorg CPU usage rose to 100%. I've seen a number of these through the years
and I'm still not sure if its Xorg or Firefox or both to blame. And I still see my
CPU usage go to 100% just like that and drain my battery. I'm open to suggestions how
to test and debug what's going on as it doesn't happen in a reproducible fashion.&lt;/p&gt;
&lt;p&gt;I happened to work on RHEL 4, RHEL 5, Fedora and the upcoming RHEL 6 releases and
managed to file bugs in a row not once but twice. 
I wish I was paid per bug reported back then :).&lt;/p&gt;
&lt;p&gt;The first series was about empty debuginfo packages with both empty packages which
shouldn't have existed at all
(e.g. &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=500628"&gt;redhat-release&lt;/a&gt;) 
and missing debuginfo information for binary packages
(e.g. &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=500612"&gt;nmap&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The second series is around 100 bugs which had to do with the texinfo
documentation of packages when installed with --excludedocs. The first one
is &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=515909"&gt;RHBZ #515909&lt;/a&gt; and the
last one &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=516014"&gt;RHBZ #516014&lt;/a&gt;.
While this works great for bumping up your bug count it made lots of developers
unhappy and not all bugs were fixed. Still the use case is valid and these
were proper software errors. It is also the first time I've used a script to
file the bugs automatically and not by hand.&lt;/p&gt;
&lt;p&gt;Near the end of the year I've started testing installation on new hardware
by the likes of Intel and AMD before they hit the market. I had the pleasure to work
with the latest chipsets and CPUs, even sometime pre-release versions and make sure
Red Hat Enterprise Linux installed and worked properly on them. I've stopped doing
this last year to free up time for other tasks.&lt;/p&gt;
&lt;h2&gt;2010 - one bug a day keeps developers at bay :)&lt;/h2&gt;
&lt;p&gt;My most productive year with 1+ bugs per day.&lt;/p&gt;
&lt;p&gt;2010 starts with a bug about file conflicts (private one) and continues with the same
narrative throughout the year.
As a matter of fact I did a small experiment and found around &lt;strong&gt;50000&lt;/strong&gt;
(you read that right, fifty thousand) potentially
conflicting files, mostly between multi-lib packages, which were being ignored by RPM
due to its multi-lib policies. However these were primarily man pages or documentation
and most of them didn't get fixed. The proper fix would have been to introduce a
-docs sub-package and split these files from the actual binaries. Fortunately the world
migrated to 64bit only and this isn't an issue anymore.&lt;/p&gt;
&lt;p&gt;By that time RHEL 6 development was running at its peak capacity and there were Beta
versions available. Almost the entire year I've been working on internal RHEL 6 snapshots
and discovering the many new bugs introduced with tons of new features in the installer.
Some of the new features included better IPv6 support, dracut and KVM.&lt;/p&gt;
&lt;p&gt;An interesting set of bugs from September are the rpmlint errors and warnings ones,
for example &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=634931"&gt;RHBZ #634931&lt;/a&gt;. I just
run the most basic test tool against some packages. It generated lots of false negatives
but also revealed bugs which were fixed.&lt;/p&gt;
&lt;p&gt;Although there were many bugs filed this year I don't see any particularly interesting ones.
It's been more like lots of work to improve the overall quality than exploring
edge cases and finding interesting failures. If you find a bug from this period that you
think is interesting I will comment on it.&lt;/p&gt;
&lt;h2&gt;2011 - Your system may be seriously compromised&lt;/h2&gt;
&lt;p&gt;This is the last year of my 3 year top cycle. &lt;/p&gt;
&lt;p&gt;It starts with &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=666687"&gt;RHBZ #666687&lt;/a&gt; -
a patch for my crappy printer-scanner-coffee maker which I've been carrying around
since &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=498228"&gt;2009&lt;/a&gt; when I bought it.&lt;/p&gt;
&lt;p&gt;I was still working primarily on RHEL 6 but helped test the latest RHEL 4 release
before it went end-of-life. The interesting thing about it was that unlike other
released RHEL4-U9 was not available on installation media but only as an update from
RHEL4-U8. This was a great experience which you happen to see
&lt;a href="https://access.redhat.com/site/support/policy/updates/errata/"&gt;every 4 to 5 years&lt;/a&gt; or so.&lt;/p&gt;
&lt;p&gt;Btw I've also led the installation testing effort and RTT team through the last few
RHEL 4 releases but given the product was approaching EOL there weren't many changes
and things went smoothly.&lt;/p&gt;
&lt;p&gt;A minor side activity was me playing around with
&lt;a href="/blog/2011/03/14/usb-multi-seat-on-red-hat-enterprise-linux-6/"&gt;USB Multi-seat&lt;/a&gt;
and finding a few bugs here and there along the way.&lt;/p&gt;
&lt;p&gt;Another interesting activity in 2011 was proof-reading the entire product documentation
before its release which I can now relate to the 
&lt;a href="/blog/2014/02/03/fosdem-2014-report-day-2-testing-and-automation/"&gt;Testing Documentation&lt;/a&gt;
talk at FOSDEM 2014.&lt;/p&gt;
&lt;p&gt;In 2011 I've started using the cloud and most notably Red Hat's OpenShift PaaS service.
First internally as an early adopter and later externally after the product was announced
to the public. There are a few interesting bugs here but they are private and I'm not
at liberty to share although they've all been fixed since then.&lt;/p&gt;
&lt;p&gt;An interesting bug with NUMA, Xen and ia64
(&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=696599"&gt;RHBZ #696599&lt;/a&gt; - private) had
me and devel banging our heads against the wall until we figured out that on this
particular system the NUMA configuration was not suitable for running Xen virtualization.&lt;/p&gt;
&lt;p&gt;Can you spot the problem here ?&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;kickstartGui&lt;/span&gt;
&lt;span class="k"&gt;except&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Could not open display because no X server is running.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Try running &amp;#39;system-config-kickstart --help&amp;#39; for a list of options.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Be honest and use the comments form to tell me what you've found. If you struggled
then see &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=703085"&gt;RHBZ #703085&lt;/a&gt; and come
back again to comment. I'd love to hear from you.&lt;/p&gt;
&lt;p&gt;What do you do when you see an error message saying: 
&lt;strong&gt;Your system may be seriously compromised! /usr/sbin/NetworkManager tried to load a kernel module.&lt;/strong&gt;
This is the scariest error message I've ever seen. Luckily its just
SELinux overreacting, see &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=704090"&gt;RHBZ #704090&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;2012 is in the red zone&lt;/h2&gt;
&lt;p&gt;While the number of reported bugs dropped significantly compared to previous
years this is the year when I've reported almost exclusively high priority and
urgent bugs, the first one being 
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=771901"&gt;RHBZ #771901&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=799384"&gt;RHBZ #799384&lt;/a&gt;(against Fedora)
is one of the rare cases when I was able to contribute
(although just by raising awareness) to localization and improved support for
Bulgarian and Cyrillic. 
The other one case was &lt;a href="http://atodorov.org/blog/2013/10/11/fedora-20-gnome-3-dot-10-test-day-post-mortem/"&gt;last year&lt;/a&gt;.
Btw I find it strange that although 
&lt;a href="https://en.wikipedia.org/wiki/Cyrillic_script"&gt;Cyrillic was invented by Bulgarians&lt;/a&gt;
we didn't (or still don't) have a native font co-maintainer.
Somebody please step up!&lt;/p&gt;
&lt;p&gt;The red zone bugs continue to span till the end of the year across RHEL 5, 6 and
early cuts of RHEL 7 with a pinch of OpenShift and some internal and external test tools.&lt;/p&gt;
&lt;h2&gt;In 2013 Bugzilla hit 1 million bugs&lt;/h2&gt;
&lt;p&gt;The year starts with a very annoying and still not fixed bug against ABRT.
It's very frustrating when the tool which is supposed to help you file bugs
doesn't work properly, see &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=903591"&gt;RHBZ #903591&lt;/a&gt;.
It's a known fact that
&lt;a href="/2012/07/13/mission-impossible-abrt-bugzilla-plugin-on-rhel6/"&gt;ABRT has problems&lt;/a&gt;
and for this scenario I may have a 
&lt;a href="/blog/2013/10/12/tip-installing-missing-debuginfo-packages-for-abrt/"&gt;tip&lt;/a&gt; for you.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=923416"&gt;RHBZ #923416&lt;/a&gt; - another one of these
100% CPU bugs. As I said they happen from time to time and mostly go by unfixed or
partially fixed because of their nature. Btw as I'm writing this post and have
a few tabs open in Firefox it keeps using between 15% and 20% CPU and the CPU
temperature is over 90 degrees C. And all I'm doing is writing text in the console.
Help!&lt;/p&gt;
&lt;p&gt;&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=967229"&gt;RHBZ #967229&lt;/a&gt; - a minor one but
reveals an important thing - your output (and input for that matter) methods may
be producing different results. Worth testing if your software supports more than one.&lt;/p&gt;
&lt;p&gt;This year I did some odd jobs working on several of Red Hat's layered products mainly
Developer Toolset. It wasn't a tough job and was a refreshing break away from the mundane
installation testing.&lt;/p&gt;
&lt;p&gt;While I stopped working actively on the various RHEL families which are under development
or still supported I happened to be one of top 10 bug reporters for high/urgent priority bugs
for RHEL 7. In appreciation Red Hat sent me lots of corporate gifts and the Platform QE hoodie
pictured at the top of the page. Many thanks!&lt;/p&gt;
&lt;p&gt;In the summer Red Hat's 
&lt;a href="/blog/2013/08/23/red-hats-bugzilla-hits-one-million-bugs/"&gt;Bugzilla hit One Million bugs&lt;/a&gt;.
The closest I come to this milestone is
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=999941"&gt;RHBZ #999941&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I finally managed to transfer most of my responsibilities to co-workers and joined
the Fedora QA team as a part-time contributor. I had some highs and lows with
&lt;a href="/blog/2013/10/07/fedora-20-virtualization-and-gnome-test-days-at-init-lab-this-week/"&gt;Fedora test days in Sofia&lt;/a&gt;
as well. Good thing is I scored another 15 bugs across the
&lt;a href="/blog/2013/10/08/fedora-20-virtualization-test-day-post-mortem/"&gt;virtualization stack&lt;/a&gt;
and &lt;a href="/blog/2013/10/11/fedora-20-gnome-3-dot-10-test-day-post-mortem/"&gt;GNOME 3.10&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The year wraps up with another series of identical bugs,
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1024729"&gt;RHBZ #1024729&lt;/a&gt; and
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1025289"&gt;RHBZ #1025289&lt;/a&gt; for example.
As it &lt;a href="/blog/2013/12/24/upstream-test-suite-status-of-fedora-20/"&gt;turned out&lt;/a&gt;
lots of packages don't have any test suites at all and those
which do don't always execute them automatically in %check. I've promised myself
to improve this but still haven't had time to work on it. Hopefully by
March I will have something in the works.&lt;/p&gt;
&lt;h2&gt;2014 - Fedora QA improvement&lt;/h2&gt;
&lt;p&gt;Last two months I've been working on some internal projects and looking
a little bit into improving processes, test coverage and QA infrastructure - 
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1064895"&gt;RHBZ #1064895&lt;/a&gt;.
And Rawhide (upcoming Fedora 21) isn't behaving -
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1063245"&gt;RHBZ #1063245&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;My goal for this year is to do more work on improving the overall test coverage
of Fedora and together with the Fedora QA team bring an
&lt;a href="/blog/2013/11/19/open-source-quality-assurance-infrastructure-for-fedora-qa/"&gt;open testing infrastructure&lt;/a&gt;
to the community. &lt;/p&gt;
&lt;p&gt;Let's see how well that plays out!&lt;/p&gt;
&lt;h2&gt;What do I do now&lt;/h2&gt;
&lt;p&gt;During the last year I have gradually changed my responsibilities to work more on Fedora.
As a volunteer in the Fedora QA I'm regularly testing installation
of Rawhide trees and try to work closely with the community. I still have to
manage RHEL 5 test cycles where I don't expect nothing disruptive at this stage in the
product life-cycle!&lt;/p&gt;
&lt;p&gt;I'm open to any ideas and help which can improve test coverage and quality of software
in Fedora. If you're just joining the open source world this is an excellent
opportunity to do some good, get noticed and even maybe get a job. I will definitely
help you get through the process if you're willing to commit your time to this.&lt;/p&gt;
&lt;p&gt;I hope this long post has been useful and fun to read. Please use the comments form to tell
me if I'm missing something or you'd like to know more.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Looking forward to the next 7 years!&lt;/em&gt;&lt;/p&gt;</summary><category term="RHEL"></category><category term="Fedora"></category><category term="QA"></category></entry><entry><title>FOSDEM 2014 Report - Day #2 Testing and Automation</title><link href="http://atodorov.org/blog/2014/02/03/fosdem-2014-report-day-2-testing-and-automation/" rel="alternate"></link><updated>2014-02-03T22:54:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2014-02-03:blog/2014/02/03/fosdem-2014-report-day-2-testing-and-automation/</id><summary type="html">&lt;p&gt;&lt;img alt="Testing and Automation" src="/images/fosdem/2014/testing_automation.jpg" title="Testing and Automation" /&gt;&lt;/p&gt;
&lt;p&gt;FOSDEM was hosting the
&lt;a href="https://fosdem.org/2014/schedule/track/testing_and_automation/"&gt;Testing and automation devroom&lt;/a&gt;
for the second year and this was the very reason I attended the conference. I managed to get in
early and stayed until 15:00 when I had to leave to catch my flight (which was late :(). &lt;/p&gt;
&lt;p&gt;There were 3 talks given by Red Hat employees in the testing devroom which was a nice opportunity
to meet some of the folks I've been working on IRC with. Unfortunately I didn't meet anyone from
Fedora QA. Not sure if they were attending or not. &lt;/p&gt;
&lt;p&gt;All the talks were interesting so see the official schedule and video for more details. I will
highlight only the items I saw as particularly interesting or have not heard of before. &lt;/p&gt;
&lt;h2&gt;ANSTE&lt;/h2&gt;
&lt;p&gt;ANSTE - Advanced Network Service Testing Environment is a test infrastructure controller,
something like our own &lt;a href="http://beaker-project.org/"&gt;Beaker&lt;/a&gt; but designed to create complex
networking environments. I think it lacks many of the provisioning features built in Beaker
and integration with various hypervisors and bare-metal provisioning. What it seems to do better
(as far as I can tell from the talk) is to deploy virtual systems and create more complex network
configuration between them. Not something I will need in the near future but definitely worth
a look at. &lt;/p&gt;
&lt;h2&gt;cwrap&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;cwrap is...&lt;/p&gt;
&lt;p&gt;a set of tools to create a fully isolated network environment to test client/server components on a single host.
It provides synthetic account information, hostname resolution and support for privilege separation.
The heart of cwrap consists of three libraries you can preload to any executable.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That one was the coolest technology I've seen so far although I may not need to use it at all,
hmmm maybe testing DHCP fits the case.&lt;/p&gt;
&lt;p&gt;It evolved from the Samba project and takes advantage of the order in which
libraries are searched when resolving functions. When you preload the project libraries
to any executable they will override standard libc functions for working with sockets,
user accounts and privilege escalation.&lt;/p&gt;
&lt;p&gt;The socket_wrapper library redirects networking sockets through local UNIX sockets and
gives you the ability to test applications which need privileged ports with a local developer
account. &lt;/p&gt;
&lt;p&gt;The nss_wrapper library provides artificial information for user and group accounts,
network name resolution using a hosts file and loading and testing of NSS modules.&lt;/p&gt;
&lt;p&gt;The uid_wrapper library allows uid switching as a normal user (e.g. fake root) and
supports user/group changing in the local thread using the syscalls (like glibc).&lt;/p&gt;
&lt;p&gt;All of these wrapper libraries are controlled via environment variables and definitely
makes testing of daemons and networking applications easier.&lt;/p&gt;
&lt;h2&gt;Testing Documentation&lt;/h2&gt;
&lt;p&gt;That one was just scratching the surface of an entire branch of testing which I've not
even considered before. The talk also explains why it is hard to test documentation and
what possible solutions there are. &lt;/p&gt;
&lt;p&gt;If you write user guides and technical articles which need to
stay current with the software this is definitely the place to start.&lt;/p&gt;
&lt;h2&gt;Automation in the Foreman Infrastructure&lt;/h2&gt;
&lt;p&gt;The last &lt;a href="http://ftp.osuosl.org/pub/fosdem//2014/previews/fosdem/fosdem_2014/dv/UD2218A/2014-02-02/12_51_36.ogv"&gt;talk&lt;/a&gt;
I've listened to. Definitely the best one from a general testing approach
point of view. Greg talked about starting with Foreman unit tests, then testing the merged PR,
then integration tests, then moving on to test the package build and then the resulting packages themselves. &lt;/p&gt;
&lt;p&gt;These guys try to even test their own infrastructure (infra as code) and the test suites
they use to test everything else. It's all about automation and the level of confidence
you have in the entire process.&lt;/p&gt;
&lt;p&gt;I like the fact that no single testing approach can make you confident enough before shipping
the code and that they've taken into account changes which get introduced at various places
(e.g. 3rd party package upgrades, distro specific issues, infrastructure changes and such) &lt;/p&gt;
&lt;p&gt;If I had to attend only one session it would have been this one. There are many things for me
to take back home and apply to my work on Fedora and RHEL.&lt;/p&gt;
&lt;p&gt;If you find any of these topics remotely interesting I advise you to wait until FOSDEM video
team uploads the recordings and watch the entire session stream. I'm definitely missing a lot
of stuff which can't be easily reproduced in text form.&lt;/p&gt;
&lt;p&gt;You can also find my report of the first FOSDEM'14 day on Saturday
&lt;a href="/blog/2014/02/03/fosdem-2014-report-day-1-python-stands-lightning-talks/"&gt;here&lt;/a&gt;.&lt;/p&gt;</summary><category term="events"></category><category term="Fedora"></category><category term="QA"></category></entry><entry><title>Upstream Test Suite Status of Fedora 20</title><link href="http://atodorov.org/blog/2013/12/24/upstream-test-suite-status-of-fedora-20/" rel="alternate"></link><updated>2013-12-24T08:01:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-12-24:blog/2013/12/24/upstream-test-suite-status-of-fedora-20/</id><summary type="html">&lt;p&gt;Last week I've expressed my thoughts about the state of
&lt;a href="https://lists.fedoraproject.org/pipermail/test/2013-December/119637.html"&gt;upstream test suites in Fedora&lt;/a&gt;
along with some other ideas. Following the response on this thread I'm starting
to analyze all SRPM packages in Fedora 20 in order to establish a baseline. Here are my initial findings.&lt;/p&gt;
&lt;h2&gt;What's Inside&lt;/h2&gt;
&lt;p&gt;I've found two source distributions for Fedora 20:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;Fedora-20-source-DVD.iso&lt;/code&gt; file which to my knowledge contains the sources
of all packages that comprise the installation media;&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;Everything/source/SRPMS/&lt;/code&gt; directory which appears to contain the sources
of everything else available in the Fedora 20 repositories.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are &lt;strong&gt;2574&lt;/strong&gt; SRPM packages in Fedora-20 source DVD and &lt;strong&gt;14364&lt;/strong&gt; SRPMs
in the Everything/ directory. 9,2G vs. 41G.&lt;/p&gt;
&lt;h2&gt;Test Suite Execution In %check&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://fedoraproject.org/wiki/Packaging:Guidelines#Test_Suites"&gt;Fedora Packaging Guidelines&lt;/a&gt;
state&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If the source code of the package provides a test suite,
it should be executed in the %check section,
whenever it is practical to do so.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In my research I found &lt;strong&gt;738&lt;/strong&gt; SRPMs on the DVD which have a %check
section and &lt;strong&gt;4838&lt;/strong&gt; such packages under &lt;code&gt;Everything/&lt;/code&gt;. This is &lt;strong&gt;28,6%&lt;/strong&gt; and &lt;strong&gt;33,6%&lt;/strong&gt;
respectively.&lt;/p&gt;
&lt;h2&gt;Test Suite Existence&lt;/h2&gt;
&lt;p&gt;A quick grep for either &lt;code&gt;test/&lt;/code&gt; or &lt;code&gt;tests/&lt;/code&gt; directories in the package sources revealed
&lt;strong&gt;870&lt;/strong&gt; SRPM packages in the source DVD which are very likely to have a test suite.
This is &lt;strong&gt;33,8%&lt;/strong&gt;. &lt;strike&gt;I wasn't able to inspect the &lt;code&gt;Everything/&lt;/code&gt; directory with this script
because it takes too long to execute and my system crashed out of memory.
I will update this post later with that info.&lt;/strike&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;UPDATE 2014-01-02&lt;/em&gt;: 
In the &lt;code&gt;Everything/&lt;/code&gt; directory only &lt;strong&gt;4481&lt;/strong&gt; (&lt;strong&gt;31,2%&lt;/strong&gt;) SRPM packages appear to have
test suites.&lt;/p&gt;
&lt;p&gt;The scripts and raw output are available at &lt;a href="https://github.com/atodorov/fedora-scripts"&gt;https://github.com/atodorov/fedora-scripts&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So it looks like on average &lt;strong&gt;30%&lt;/strong&gt; of the packages execute their test suites at build
time in the %check section and less than &lt;strong&gt;35%&lt;/strong&gt; have test suites at all!
There's definitely room for improvement and I plan to focus on this during 2014!&lt;/p&gt;</summary><category term="Fedora"></category><category term="QA"></category></entry><entry><title>Can I Use Android Phone as Smart Card Reader</title><link href="http://atodorov.org/blog/2013/12/18/can-i-use-android-phone-as-smart-card-reader/" rel="alternate"></link><updated>2013-12-18T23:09:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-12-18:blog/2013/12/18/can-i-use-android-phone-as-smart-card-reader/</id><summary type="html">&lt;p&gt;Today I had troubles with my Omnikey CardMan 6121 smart card reader.
For some reason it will not detect the card inside and was unusable.
&lt;code&gt;/var/log/messages&lt;/code&gt; was filled with  &lt;em&gt;Card Not Powered&lt;/em&gt; messages:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;Dec 18 11:17:55 localhost pcscd: eventhandler.c:292:EHStatusHandlerThread() Error powering up card: -2146435050 0x80100016
Dec 18 11:18:01 localhost pcscd: winscard.c:368:SCardConnect() Card Not Powered
Dec 18 11:18:02 localhost pcscd: winscard.c:368:SCardConnect() Card Not Powered
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="/images/omnikey_cardman_6121.gif" style="float:right;margin-left:20px;" /&gt;&lt;/p&gt;
&lt;p&gt;I've found the solution in 
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=531998"&gt;RHBZ #531998&lt;/a&gt;. &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I've found the problem, and it's purely mechanical.
Omnikey has simply screwed up when they designed this reader.
When the reader is inserted into the ExpressCard slot, it gets slightly
compressed. This is enough to trigger the mechanical switch that detects
insertions. If I jam something in there and force it apart, then pcscd
starts reporting that the slot is empty.&lt;/p&gt;
&lt;p&gt;Pierre Ossman, https://bugzilla.redhat.com/show_bug.cgi?id=531998#c12&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So I tried moving the smart card a millimeter back and forth inside the reader and
that fixed it for me.&lt;/p&gt;
&lt;p&gt;This smart card is standard SIM size and I wonder if it is possible to use
&lt;a href="http://amzn.to/1dnl2gN"&gt;dual SIM&lt;/a&gt; smart phones and &lt;a href="http://amzn.to/18XpWlp"&gt;tablets&lt;/a&gt;
as a reader? I will be happy to work on the software side if there is an open source
project already (e.g. OpenSC + drivers for Android). If not, why not? &lt;/p&gt;
&lt;p&gt;If you happen to have information on the subject please share it in the comments.
Thanks!&lt;/p&gt;</summary><category term="RHEL"></category><category term="Fedora"></category><category term="QA"></category></entry><entry><title>Bug in Python URLGrabber/cURL on Fedora and Amazon Linux</title><link href="http://atodorov.org/blog/2013/11/29/bug-python-urlgrabber-curl-fedora-amazon-linux/" rel="alternate"></link><updated>2013-11-29T14:05:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-11-29:blog/2013/11/29/bug-python-urlgrabber-curl-fedora-amazon-linux/</id><summary type="html">&lt;p&gt;Accidentally I have discovered a bug for Python's
URLGrabber module which has to do with change in behavior in libcurl.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;urlgrabber.grabber&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;URLGrabber&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;URLGrabber&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reget&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlgrab&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;https://s3.amazonaws.com/production.s3.rubygems.org/gems/columnize-0.3.6.gem&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;/tmp/columnize.gem&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Traceback&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;most&lt;/span&gt; &lt;span class="n"&gt;recent&lt;/span&gt; &lt;span class="n"&gt;call&lt;/span&gt; &lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;File&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;lt;console&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;module&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="n"&gt;File&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;/home/celeryd/.virtualenvs/difio/lib/python2.6/site-packages/urlgrabber/grabber.py&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="mi"&gt;976&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;urlgrab&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_retry&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;opts&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;retryfunc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;File&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;/home/celeryd/.virtualenvs/difio/lib/python2.6/site-packages/urlgrabber/grabber.py&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="mi"&gt;880&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;_retry&lt;/span&gt;
    &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;opts&lt;/span&gt;&lt;span class="p"&gt;,)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;{})&lt;/span&gt;
  &lt;span class="n"&gt;File&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;/home/celeryd/.virtualenvs/difio/lib/python2.6/site-packages/urlgrabber/grabber.py&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="mi"&gt;962&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;retryfunc&lt;/span&gt;
    &lt;span class="n"&gt;fo&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PyCurlFileObject&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;opts&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;File&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;/home/celeryd/.virtualenvs/difio/lib/python2.6/site-packages/urlgrabber/grabber.py&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="mi"&gt;1056&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;__init__&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_do_open&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
  &lt;span class="n"&gt;File&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;/home/celeryd/.virtualenvs/difio/lib/python2.6/site-packages/urlgrabber/grabber.py&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="mi"&gt;1307&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;_do_open&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_set_opts&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
  &lt;span class="n"&gt;File&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;/home/celeryd/.virtualenvs/difio/lib/python2.6/site-packages/urlgrabber/grabber.py&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="mi"&gt;1161&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;_set_opts&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;curl_obj&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setopt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pycurl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SSL_VERIFYHOST&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;opts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ssl_verify_host&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;43&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The code above works fine with curl-7.27 or older while it breaks with curl-7.29 and
newer. As explained by 
&lt;a href="http://lists.baseurl.org/pipermail/yum-devel/2013-November/010428.html"&gt;Zdenek Pavlas&lt;/a&gt;
the reason is an internal change in libcurl which doesn't accept a value of 1 anymore!&lt;/p&gt;
&lt;p&gt;The bug is reproducible with a newer libcurl version and a vanilla urlgrabber==3.9.1
from PyPI (e.g. inside a virtualenv). The latest python-urlgrabber RPM packages in both
Fedora and Amazon Linux already have the fix.&lt;/p&gt;
&lt;p&gt;I have tested the patch proposed by Zdenek and it works for me. I still have no idea why
there aren't any updates released on PyPI though!&lt;/p&gt;</summary><category term="Fedora"></category><category term="QA"></category><category term="cloud"></category><category term="Python"></category></entry><entry><title>Open Source Quality Assurance Infrastructure for Fedora QA</title><link href="http://atodorov.org/blog/2013/11/19/open-source-quality-assurance-infrastructure-for-fedora-qa/" rel="alternate"></link><updated>2013-11-19T14:12:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-11-19:blog/2013/11/19/open-source-quality-assurance-infrastructure-for-fedora-qa/</id><summary type="html">&lt;p&gt;&lt;img alt="&amp;quot;Beaker test lab&amp;quot;" src="/images/fedora/beaker.png" title="Beaker test lab" /&gt;&lt;/p&gt;
&lt;p&gt;In the last few weeks I've been working together with 
&lt;a href="https://fedoraproject.org/wiki/User:Tflink"&gt;Tim Flink&lt;/a&gt; and
&lt;a href="https://fedoraproject.org/wiki/User:Kparal"&gt;Kamil Paral&lt;/a&gt; from the Fedora QA
team on bringing some installation testing expertise to Fedora and establishing
an &lt;a href="http://beaker.fedoraproject.org/bkr/"&gt;open source test lab&lt;/a&gt;
to perform automated testing in. The infrastructure is
already in relatively usable condition so I've decided to share this information
with the community. &lt;/p&gt;
&lt;h2&gt;Beaker is Running Our Test Lab&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://beaker-project.org/"&gt;Beaker&lt;/a&gt; is the software suite that powers the test
lab infrastructure. It is quite complex, with many components and sometimes not
very straight-forward to set up. Tim has been working on that with me giving it
a try and reporting issues as they have been discovered and fixed. &lt;/p&gt;
&lt;p&gt;In the process of working on this I've managed to create
&lt;a href="http://gerrit.beaker-project.org/#/q/owner:%22Alexander+Todorov%22,n,z"&gt;couple of patches&lt;/a&gt;
against Beaker and friends. They are still pending release in a future version
because of more urgent bug fixes which need to released first.&lt;/p&gt;
&lt;h2&gt;SNAKE is The Kickstart Template Server&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://fedorahosted.org/snake/"&gt;SNAKE&lt;/a&gt; is a client/server Python framework used
to support Anaconda installations. It supports plain text ks.cfg files, IIRC those
were static templates, no variable substitution.&lt;/p&gt;
&lt;p&gt;The other possibility is Python templates based on Pykickstart:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pykickstart.constants&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;KS_SCRIPT_POST&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pykickstart.parser&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Script&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;installdefaults&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;InstallKs&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;ks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;Anaconda autopart&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;

    &lt;span class="n"&gt;ks&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;InstallKs&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;ks&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;packages&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;@base&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="n"&gt;ks&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clearpart&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;initAll&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ks&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;autopart&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;autopart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;script&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="s"&gt;cp /tmp/ks.cfg /mnt/sysimage/root/ks.cfg || &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;
&lt;span class="s"&gt;cp /run/install/ks.cfg /mnt/sysimage/root/ks.cfg&lt;/span&gt;
&lt;span class="s"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;post&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Script&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;script&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;KS_SCRIPT_POST&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inChroot&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ks&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scripts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;post&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;ks&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;At the moment SNAKE is essentially abandoned but feature complete.
I'm thinking about adopting the project just in case we need to make some fixes.
Will let you know more about this when it happens. &lt;/p&gt;
&lt;h2&gt;Open Source Test Suite&lt;/h2&gt;
&lt;p&gt;I have been working on opening up several test cases for what we (QE) call
a tier #1 installation test suite. They can be found in
&lt;a href="http://taskbot.cloud.fedoraproject.org/cgit/fedora-beaker-tests/"&gt;git&lt;/a&gt;.
The tests are base on &lt;a href="https://fedorahosted.org/beakerlib/"&gt;beakerlib&lt;/a&gt; and
the legacy RHTS framework which is now part of Beaker.&lt;/p&gt;
&lt;p&gt;This effort has been coordinated with Kamil as part of a pilot
project he's responsible for. I've been executing the same test suite against
earlier Fedora 20 snapshots but using an internal environment. Now everything
is going out in the open.&lt;/p&gt;
&lt;h2&gt;Executing The Tests&lt;/h2&gt;
&lt;p&gt;Well you can't do that - YET! There are command line client tools for Fedora
but Beaker and SNAKE are not well suited for use outside a restricted network
like LAN or VPN. There are issues with authentication most notably for SNAKE.&lt;/p&gt;
&lt;p&gt;At the moment I have to ssh through two different systems to get proper access.
However this is been worked on. I've read about a rewrite which will allow Beaker
to utilize a custom authentication framework like FAS for example. Hopefully that
will be implemented soon enough.&lt;/p&gt;
&lt;p&gt;I will also like to see the test systems have direct access to the Internet for
various reasons but this is not without its risks either. This is still to be
decided.&lt;/p&gt;
&lt;p&gt;If you are interested anyway see the &lt;code&gt;kick-tests.sh&lt;/code&gt; file in the test suite for
examples and command line options.&lt;/p&gt;
&lt;h2&gt;Test Results&lt;/h2&gt;
&lt;p&gt;The first successfully completed
&lt;a href="http://beaker.fedoraproject.org/bkr/jobs/"&gt;test jobs&lt;/a&gt; are jobs 50 to 58.
There's a failure in one of the test cases, namely SELinux related 
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1027148"&gt;RHBZ #1027148&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;From what I can tell the lab is now working as expected and we can start doing
some testing against Fedora development snapshots.&lt;/p&gt;
&lt;p&gt;Ping me or join #fedora-qa on irc.freenode.net if you'd like to join Fedora QA!&lt;/p&gt;</summary><category term="Fedora"></category><category term="QA"></category></entry><entry><title>Keeping Backwards Compatibility for pykickstart</title><link href="http://atodorov.org/blog/2013/11/13/keeping-backwards-compatibility-for-pykickstart/" rel="alternate"></link><updated>2013-11-13T23:59:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-11-13:blog/2013/11/13/keeping-backwards-compatibility-for-pykickstart/</id><summary type="html">&lt;p&gt;Consider the following scenario:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I'm using &lt;a href="https://fedorahosted.org/snake/"&gt;SNAKE&lt;/a&gt; templates as part of my
installation testing work;&lt;/li&gt;
&lt;li&gt;SNAKE has a dependency on pykickstart;&lt;/li&gt;
&lt;li&gt;To test the latest and greatest kickstart features in Fedora we need the
latest version of pykickstart;&lt;/li&gt;
&lt;li&gt;Latest pykickstart needs Python 2.7&lt;/li&gt;
&lt;li&gt;Python 2.7 is not available on RHEL 6 which is used to host the test
infrastructure.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Just yesterday I hit an issue with the above setup and figured Fedora QA is
in a kind of strange situation - we always need the latest but need it
conservative enough to run on RHEL 6. See the original thread at
&lt;a href="https://www.redhat.com/archives/kickstart-list/2013-November/msg00001.html"&gt;kickstart-list&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this particular case the solution will be to remove the offending code
and implement the same functionality in backward-compatible manner. Also add
more tests. I will be working on this tomorrow (there's an older patch already).&lt;/p&gt;
&lt;p&gt;The BIG question remains though - how do you manage software evolution and still
keep it compatible with older execution stacks? Please share your experience in
the comments section.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;PP: Spoiler - this is part of an ongoing effort to bring open source installation
testing expertise (my domain) into Fedora world, plus establish a community supported
test infrastructure. More info TBA soon.&lt;/p&gt;</summary><category term="QA"></category><category term="Fedora"></category></entry><entry><title>Fedora 20 GNOME 3.10 Test Day Post-mortem</title><link href="http://atodorov.org/blog/2013/10/11/fedora-20-gnome-3-dot-10-test-day-post-mortem/" rel="alternate"></link><updated>2013-10-11T12:25:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-10-11:blog/2013/10/11/fedora-20-gnome-3-dot-10-test-day-post-mortem/</id><summary type="html">&lt;p&gt;&lt;img alt="&amp;quot;Fedora sausage banner&amp;quot;" src="/images/fedora/sausage-banner.png" title="Fedora sausage banner" /&gt;&lt;/p&gt;
&lt;p&gt;Here is my summary of the second Fedora Test Day hosted at
&lt;a href="http://initlab.org"&gt;init Lab&lt;/a&gt; yesterday.&lt;/p&gt;
&lt;p&gt;Local attendance was a total disaster, in fact I was testing once again by my own.
This time
there were more people in the lab, all busy with their daily routines and tasks.
There were no people who came for the testing :(. I will have to try different
venues in the future and see if the situation improves.&lt;/p&gt;
&lt;p&gt;On the testing front I managed to score 5 bugs against
&lt;a href="https://bugzilla.gnome.org/buglist.cgi?bug_id=709797,709799,709806,709810"&gt;GNOME&lt;/a&gt;
and &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1017807"&gt;Fedora&lt;/a&gt;.
You can see the other test results and bugs on the
&lt;a href="https://fedoraproject.org/wiki/Test_Day:2013-10-10_Gnome_3.10"&gt;wiki&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;There are two things I didn't like in particular&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GNOME 3 as well as its classic mode - simply not the environment I'm used to;&lt;/li&gt;
&lt;li&gt;Having to record test results in the wiki! I'm
&lt;a href="https://lists.fedoraproject.org/pipermail/test/2013-October/118284.html"&gt;writing&lt;/a&gt;
to the Fedora QA mailing list about that as we speak.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At one time I was engaged in a discussion about which Bulgarian keyboard layout
should be the default in GNOME simply because of
&lt;a href="https://bugzilla.gnome.org/show_bug.cgi?id=709799"&gt;GNOME #709799&lt;/a&gt;. The default
keyboard layout will be Bulgarian (traditional phonetic) aka bg+phonetic.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;(16,13,26) rtcm: atodorov: are you bulgarian and/or live in bulgaria?
(16,14,20) rtcm: atodorov: if yes, I wanted to know which keyboard layout most people expect there to be the default
(16,16,34) atodorov: rtcm: I&amp;#39;m a Bulgarian, however I can&amp;#39;t tell which one. Both Phonetic and standard (BDS) are common
(16,16,54) atodorov: a safe bet is to go with phonetic I guess. 
(16,19,46) rtcm: atodorov: can you tell me which one is it in XKB terms? is it &amp;quot;bg&amp;quot;, &amp;quot;bg+bas_phonetic&amp;quot; or &amp;quot;bg+phonetic&amp;quot; ?
(16,20,51) rtcm: they&amp;#39;re labeled as &amp;quot;Bulgarian&amp;quot;, &amp;quot;Bulgarian (new phonetic)&amp;quot; and &amp;quot;Bulgarian (traditional phonetic)&amp;quot;
(16,21,30) atodorov: bg+phonetic is the traditional phonetic
(16,22,04) atodorov: bg labeled as &amp;quot;Bulgarian&amp;quot; is the standard one I guess. Here we call it BDS after the standardization institute
(16,22,34) atodorov: bg+bas_phonetic is created from the Bulgarian Academy of Science and is not very popular as far as I know. I&amp;#39;ve never seen it in use
(16,23,15) rtcm: atodorov: all I want to know is what most people would expect? like what does windows do by default? that&amp;#39;s a good bet
(16,27,46) atodorov: rtcm: I&amp;#39;m just being told that new Windows releases use yet another layout by default, which is like phonetic but with some characters in new places and people don&amp;#39;t like that
(16,27,53) atodorov: my safe bet goes to bg+phonetic
(16,29,05) rtcm: ok, thanks
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It is a rare occasion when you get to make a decision that affects a large group
of people and I hope you don't hate me for that! &lt;/p&gt;
&lt;p&gt;Do you want to see more Fedora Test Days happening in Sofia? Join me and I will
organize some more!&lt;/p&gt;</summary><category term="Fedora"></category><category term="QA"></category></entry><entry><title>Fedora 20 Virtualization Test Day Post-mortem</title><link href="http://atodorov.org/blog/2013/10/08/fedora-20-virtualization-test-day-post-mortem/" rel="alternate"></link><updated>2013-10-08T22:01:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-10-08:blog/2013/10/08/fedora-20-virtualization-test-day-post-mortem/</id><summary type="html">&lt;p&gt;&lt;img alt="&amp;quot;Fedora 20 banner&amp;quot;" src="/images/fedora/fedora20-banner.png" title="Fedora 20 banner" /&gt;&lt;/p&gt;
&lt;p&gt;Here is a quick summary of the first Fedora Test Day in Sofia I hosted at
&lt;a href="http://initlab.org"&gt;init Lab&lt;/a&gt; today.&lt;/p&gt;
&lt;p&gt;Attendance was quite poor, actually nobody else except me participated but
almost nobody else visited the hackespace as well. I get that it is a
working day and Test Days conflict with regular business hours but this
is not going to change anyway. On the other hand where were all the freelancers
and non-office job workers who usually hang around in the Lab? I have no idea!&lt;/p&gt;
&lt;p&gt;On IRC there was much better activity, 5 or 6 people were testing across
Asia, Europe and USA time zones. You can see the test results
&lt;a href="http://209.132.184.192/testdays/show_event?event_id=7"&gt;here&lt;/a&gt;.
I've started filing quite a few bugs in the morning and continued well into the
afternoon. I've managed to file a total of
&lt;a href="https://bugzilla.redhat.com/buglist.cgi?bug_id=1016435,1016449,1016488,1016530,1016604,1016613,1016648,1016663,1016704,1016715"&gt;10 bugs&lt;/a&gt;.
Some of them were not related to virtualization and some of them turned out to be
duplicates or not a bug. I even managed to file 2 duplicate bugs which likely have the
same root cause myself :). &lt;/p&gt;
&lt;p&gt;I've also experienced two bugs filed by other people:
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=967371"&gt;RHBZ #967371&lt;/a&gt; for MATE desktop
and &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1015636"&gt;RHBZ #1015636&lt;/a&gt; for
virt-manager's Save/Restore functionality.&lt;/p&gt;
&lt;p&gt;I've tried ARM on x86_64 but that didn't get anywhere near a running system.
I will make another post about ARM and what I've discovered there.&lt;/p&gt;
&lt;p&gt;The one thing I liked is the 
&lt;a href="http://209.132.184.192/testdays/show_event?event_id=7"&gt;test results application&lt;/a&gt;.
It is not what I'm used to when dealing with RHEL, has far less features but is
very fast and easy to use and suits the Test Days participants just fine.
And is definitely much easier to use compared to filing results in the wiki.&lt;/p&gt;
&lt;p&gt;Overall Fedora 20 virtualization status according to me is pretty good.&lt;/p&gt;
&lt;p&gt;I hope to see more attendance &lt;a href="http://initlab.org/event/gnome-test-day"&gt;on Thursday&lt;/a&gt;
when we're going to test GNOME 3.10.&lt;/p&gt;</summary><category term="Fedora"></category><category term="QA"></category></entry><entry><title>Fedora 20 Virtualization &amp; GNOME Test Days at init Lab this week</title><link href="http://atodorov.org/blog/2013/10/07/fedora-20-virtualization-and-gnome-test-days-at-init-lab-this-week/" rel="alternate"></link><updated>2013-10-07T10:28:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-10-07:blog/2013/10/07/fedora-20-virtualization-and-gnome-test-days-at-init-lab-this-week/</id><summary type="html">&lt;p&gt;Fedora 20 Virtualization and GNOME test days will be tomorrow (8th Oct) and on
Thursday (10th Oct)! Local community in Sofia will gather at
&lt;a href="http://initlab.org"&gt;init Lab&lt;/a&gt;! We start at 10:00 and everybody is welcome.&lt;/p&gt;
&lt;p&gt;If you have no idea what I'm talking about check my
&lt;a href="/blog/categories/fedora/"&gt;previous posts&lt;/a&gt; and the announcement at init Lab's website:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://initlab.org/event/testing-fedora-20-virtualization-test-day"&gt;http://initlab.org/event/testing-fedora-20-virtualization-test-day&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://initlab.org/event/gnome-test-day"&gt;http://initlab.org/event/gnome-test-day&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;See you there!&lt;/p&gt;</summary><category term="Fedora"></category><category term="QA"></category></entry><entry><title>Facebook UI Bug Strikes Again at HackFMI</title><link href="http://atodorov.org/blog/2013/09/23/facebook-ui-bug-strikes-again-at-hackfmi/" rel="alternate"></link><updated>2013-09-23T23:33:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-09-23:blog/2013/09/23/facebook-ui-bug-strikes-again-at-hackfmi/</id><summary type="html">&lt;p&gt;Does this look familiar to you ? &lt;/p&gt;
&lt;p&gt;&lt;img alt="&amp;quot;HackFMI UI bug&amp;quot;" src="/images/hackfmi_facebook_bug.png" title="HackFMI UI bug" /&gt;&lt;/p&gt;
&lt;p&gt;No? See 
&lt;a href="/blog/2013/06/02/sofiavalley-ui-bug/"&gt;SofiaValley&lt;/a&gt; and 
&lt;a href="/blog/2013/07/31/ui-bug-for-opensource-dot-com/"&gt;opensource.com&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Either this is a very common front-end mistake (I would blame CSS) or
Facebook have screwed up their buttons.&lt;/p&gt;</summary><category term="QA"></category></entry><entry><title>Fedora Test Days are Coming to Sofia</title><link href="http://atodorov.org/blog/2013/09/23/fedora-test-days-are-coming-to-sofia/" rel="alternate"></link><updated>2013-09-23T14:27:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-09-23:blog/2013/09/23/fedora-test-days-are-coming-to-sofia/</id><summary type="html">&lt;p&gt;As I &lt;a href="/blog/2013/09/14/upcoming-talk-fedora-test-days-in-sofia/"&gt;mentioned earlier&lt;/a&gt;
I will organize some Fedora testing in Sofia. Here's an outline of my talk this
Saturday and a general guide for anyone who wants to participate.&lt;/p&gt;
&lt;h2&gt;What are Fedora Test Days&lt;/h2&gt;
&lt;p&gt;Fedora Test Days are day long events focused on testing a particular feature
in the upcoming Fedora release. At the time of writing they are focused on
Fedora 20.&lt;/p&gt;
&lt;h2&gt;What You Need Before Joining Fedora&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;a href="https://bugzilla.redhat.com/createaccount.cgi"&gt;bugzilla.redhat.com&lt;/a&gt; account;&lt;/li&gt;
&lt;li&gt;A &lt;a href="https://admin.fedoraproject.org/accounts/user/new"&gt;Fedora account&lt;/a&gt;. Please
complete the &lt;a href="https://fedoraproject.org/wiki/Join"&gt;onboarding process&lt;/a&gt; in advance
as it takes time;&lt;/li&gt;
&lt;li&gt;Create a wiki page for your profile. Mine is 
&lt;a href="https://fedoraproject.org/wiki/User:Atodorov"&gt;here&lt;/a&gt;. This will verify you can
edit the wiki;&lt;/li&gt;
&lt;li&gt;Know how to use IRC. There is a web chat client at &lt;a href="https://webchat.freenode.net/"&gt;https://webchat.freenode.net/&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;What You Need Before The Test Day&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Know how to properly
&lt;a href="https://fedoraproject.org/wiki/Bugs_and_feature_requests"&gt;report a bug&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;Installation ISO (DVD) or Live CD depending on what you want to test;&lt;/li&gt;
&lt;li&gt;Nightly LiveCD ISOs can be found
&lt;a href="http://alt.fedoraproject.org/pub/alt/nightly-composes/"&gt;here&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;Another alternative is official
&lt;a href="http://dl.fedoraproject.org/pub/alt/stage/"&gt;test compose&lt;/a&gt; (TC) images or
yum update to the latest release;&lt;/li&gt;
&lt;li&gt;Extra hardware or a virtual machine for testing.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;What You Need On The Test Day&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Join the #fedora-test-day IRC channel on freenode.net;&lt;/li&gt;
&lt;li&gt;Have the &lt;a href="https://fedoraproject.org/wiki/Test_Day:Current"&gt;current test day&lt;/a&gt;
wiki page handy;&lt;/li&gt;
&lt;li&gt;Execute some test cases and file bugs;&lt;/li&gt;
&lt;li&gt;Report your test results on the wiki;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Time and place for two test days will be announced at the end of the week
and earlier next week so stay tuned!&lt;/p&gt;</summary><category term="Fedora"></category><category term="QA"></category></entry><entry><title>Lenovo Rants: Battery and Dock Flaws</title><link href="http://atodorov.org/blog/2013/09/15/lenovo-rants-battery-and-dock-flaws/" rel="alternate"></link><updated>2013-09-15T10:23:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-09-15:blog/2013/09/15/lenovo-rants-battery-and-dock-flaws/</id><summary type="html">&lt;p&gt;To all my readers - sorry for not being able to blog more frequently lately.
Here's an easy read about my favourite laptop brand Lenovo and some of their
design flaws I've found.&lt;/p&gt;
&lt;h2&gt;X220 and T60 Batterries are ALMOST Identical&lt;/h2&gt;
&lt;p&gt;&lt;img alt="&amp;quot;X220 and T60 batteries&amp;quot;" src="/images/lenovo_x220_t60_battery.jpg" title="X220 and T60 batteries" /&gt;&lt;/p&gt;
&lt;p&gt;As you can see the &lt;a href="http://amzn.to/12y5hwp"&gt;X220&lt;/a&gt; and 
&lt;a href="http://amzn.to/183SgiR"&gt;T60&lt;/a&gt; batteries are nearly identical with the notable
exception of the connector placement. The end result - I have to purchase yet another
battery as a backup for long travel/work on the go. Not what I want.&lt;/p&gt;
&lt;p&gt;I wish all Lenovo models had the same batteries so people can swap them around
as they wish. Is this too much to ask for? Have you seen another brand which
got this right? &lt;/p&gt;
&lt;h2&gt;ThinkPad Mini Dock Design Flaw&lt;/h2&gt;
&lt;p&gt;I'm using a &lt;a href="http://amzn.to/15tjUYi"&gt;ThinkPad Mini Dock Series 3&lt;/a&gt; docking station
with my X220 laptop. Being a QA engineer for so long I immediately
noticed something that wasn't quite right. The buttons on the left and the mechanism
next to them are blocking the hot air exhaust from the CPU fan. This model of docking
station is made to fit several models of laptops and those which dock in position 2 are
less affected from those which dock in possition 1. Mine was not a lucky one.&lt;/p&gt;
&lt;p&gt;&lt;img alt="docking station in position 2" src="/images/dock/alone.jpg" title="docking station in position 2" /&gt;&lt;/p&gt;
&lt;p&gt;On the pictures below it is clearly visible that most of the hot air coming out of the CPU
fan is blocked.&lt;/p&gt;
&lt;p&gt;&lt;img alt="top view" src="/images/dock/top.jpg" title="top view" /&gt;
&lt;img alt="back view" src="/images/dock/back.jpg" title="back view" /&gt;
&lt;img alt="side view" src="/images/dock/side.jpg" title="side view" /&gt;&lt;/p&gt;
&lt;p&gt;In order to reduce laptop heating and provide better cooling I decided to remove the
1/2 position switch mechanism. To do that you have to unscrew all screws from the docking
station and carefully split the top and bottom halves. The offending piece of plastic is
screwed with two tiny screws at the bottom. Once they are removed everything comes off.&lt;/p&gt;
&lt;p&gt;&lt;img alt="blocking part removed" src="/images/dock/removed.jpg" title="blocking part removed" /&gt;&lt;/p&gt;
&lt;p&gt;Even with this piece removed my laptop still hets up too much! I guess 80 C is just
normal for the Core i7 processors :(.&lt;/p&gt;
&lt;p&gt;Have you found something not quite right in your hardware design? Please share in the
comments.&lt;/p&gt;</summary><category term="QA"></category></entry><entry><title>Upcoming Talk: Fedora Test Days in Sofia</title><link href="http://atodorov.org/blog/2013/09/14/upcoming-talk-fedora-test-days-in-sofia/" rel="alternate"></link><updated>2013-09-14T23:11:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-09-14:blog/2013/09/14/upcoming-talk-fedora-test-days-in-sofia/</id><summary type="html">&lt;p&gt;On September 28th I will be giving a short talk about
&lt;a href="https://fedoraproject.org/wiki/QA/Test_Days"&gt;Fedora Test Days&lt;/a&gt; at the regular
Linux for Bulgarians
&lt;a href="http://www.linux-bg.org/cgi-bin/y/index.pl?page=news&amp;amp;key=459487176"&gt;conference&lt;/a&gt;.
I will explain what these are and how one can participate. I will also announce
my plans and schedule to organize some
&lt;a href="https://fedoraproject.org/wiki/QA/Fedora_20_test_days"&gt;Fedora 20 test days&lt;/a&gt;
locally in Sofia. If you are a fan of Fedora and want to file bugs and kick 
some developers' ass this is the way to do it!&lt;/p&gt;
&lt;p&gt;Other talks include Alexander Shopov's „Oracle's take on NoSQL“ which I wanted
to hear since this summer and TBA talks about MicroTik routers.&lt;/p&gt;
&lt;p&gt;The conference will take place on September 28th at the French Institute at
Sofia University
(see &lt;a href="http://conf.linux-bg.org/wp-content/uploads/2009/12/su-2.png"&gt;map&lt;/a&gt;).
It starts at 13:00 and my talk should be at the beginning. See you there!&lt;/p&gt;
&lt;p&gt;PS: this post was initially written on my &lt;a href="http://amzn.to/12y4ewJ"&gt;BlackBerry Z10&lt;/a&gt;
with Penzus Editor - another small step in 
&lt;a href="/blog/2013/08/01/laptop-vs-smartphone-part-one/"&gt;retiring my laptop&lt;/a&gt;.&lt;/p&gt;</summary><category term="Fedora"></category><category term="QA"></category><category term="events"></category></entry><entry><title>Bug Analysis Of RHBZ #1337</title><link href="http://atodorov.org/blog/2013/09/02/bug-analysis-of-rhbz-1337/" rel="alternate"></link><updated>2013-09-02T16:38:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-09-02:blog/2013/09/02/bug-analysis-of-rhbz-1337/</id><summary type="html">&lt;p&gt;In my &lt;a href="/blog/2013/08/23/red-hats-ebugzilla-hits-one-million-bugs/"&gt;previous post&lt;/a&gt;
I asked the readers of this blog to pick a bug number from Red Hat's Bugzilla
so I can analyze it later.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://radorado.me"&gt;Radoslav Georgiev&lt;/a&gt; decided to step up and
selected the &lt;a href="https://en.wikipedia.org/wiki/Leet"&gt;Leet&lt;/a&gt; bug
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1337"&gt;https://bugzilla.redhat.com/show_bug.cgi?id=1337&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is a rather old bug against kernel, in particular
against the token ring driver. There isn't much info on the bug but it seems
the issue is hardware dependent and doesn't reproduce reliably.&lt;/p&gt;
&lt;p&gt;Looking at the bug status and history it looks like it was closed without
fixing it. Most likely the reason for this was there was no hardware
to test, bug was not reproduced and no customers were seeing the issue or
were willing to test and work with devel!&lt;/p&gt;
&lt;p&gt;If you'd like to see my comments on other interesting bugs just post a link
to them in the comments section.&lt;/p&gt;</summary><category term="QA"></category></entry><entry><title>Red Hat's Bugzilla Hits One Million Bugs</title><link href="http://atodorov.org/blog/2013/08/23/red-hats-bugzilla-hits-one-million-bugs/" rel="alternate"></link><updated>2013-08-23T12:21:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-08-23:blog/2013/08/23/red-hats-bugzilla-hits-one-million-bugs/</id><summary type="html">&lt;p&gt;&lt;img alt="&amp;quot;RHBZ 1 million&amp;quot;" src="/images/redhat_1mil_bugs.jpg" title="RHBZ 1 million" /&gt;&lt;/p&gt;
&lt;p&gt;Red Hat's Bugzilla passed the 1 million bugs milestone yesterday!
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1000000"&gt;RHBZ #1000000&lt;/a&gt; has been
filed by Anton Arapov, a kernel engineer and a very nice guy (I know him btw).
I've filed several bugs yesterday but the last one was #999941. A bit too short!&lt;/p&gt;
&lt;p&gt;To celebrate this event I dare you to pick some bugs from Bugzilla that you find
interesting or frustrating and I will try to analyze and explain them from a
QA engineer's point of view. Since I've reported over 1000 bugs and been involved in
another close to 5000 I think I will be able to answer almost any question.&lt;/p&gt;
&lt;p&gt;Challenge accepted!&lt;/p&gt;</summary><category term="RHEL"></category><category term="QA"></category></entry><entry><title>Small But Annoying Twitter Bug</title><link href="http://atodorov.org/blog/2013/08/23/small-but-annoying-twitter-bug/" rel="alternate"></link><updated>2013-08-23T12:09:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-08-23:blog/2013/08/23/small-but-annoying-twitter-bug/</id><summary type="html">&lt;p&gt;&lt;img alt="&amp;quot;Tweet Embed Bug&amp;quot;" src="/images/twitter_embed_bug.png" title="Tweet Embed Bug" /&gt;&lt;/p&gt;
&lt;p&gt;I've been having troubles with Twitter lately but this bug is just annoying!
Where on Earth is the "code below" ? I've already
&lt;a href="https://twitter.com/atodorov_/status/370833992074809345"&gt;reported it&lt;/a&gt;. Let's
see how long it takes for them to fix it!&lt;/p&gt;</summary><category term="QA"></category></entry><entry><title>Notes From Two Interesting GUADEC Talks</title><link href="http://atodorov.org/blog/2013/08/07/notes-from-two-interesting-guadec-talks/" rel="alternate"></link><updated>2013-08-07T14:33:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-08-07:blog/2013/08/07/notes-from-two-interesting-guadec-talks/</id><summary type="html">&lt;p&gt;As this year's &lt;a href="https://www.guadec.org/"&gt;GUADEC&lt;/a&gt; is coming to an end
I'm publishing an interesting update from 
&lt;a href="https://cz.linkedin.com/in/mullerpetr"&gt;Petr Muller&lt;/a&gt; for 
those who were not able to attend.
Petr is a Senior Quality Engineer at Red Hat. His notes were
sent to an internal QE mailing list and re-published with permission.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;As this year&amp;#39;s GUADEC happened in the same building where I have my
other office, I decided to attend. I&amp;#39;m sharing my notes from the two
sessions I consider to be especially interesting for the audience of
this mailing list:

== How to not report your UX bug ==
Speaker:    Fabiana Simões
Blog:       http://fabianapsimoes.wordpress.com/
Twitter:    https://twitter.com/fabianapsimoes

Do not do this stuff:
* Do not simply present a preferred solution, but describe a problem (a
difficulty you are having, etc.)
* Do not use &amp;quot;This sucks&amp;quot; idiom, not even hidden in false niceties like
&amp;quot;It&amp;#39;s not user friendly&amp;quot;
* Do not talk for majority, when you are not entitled to (&amp;quot;most users
would like&amp;quot;)
* Do not consider all UX issues as minor: an inability to do stuff is
not a minor issue

What is actually interesting for the designer in a report?
* What were you trying to do?
* Why did you want to do it?
* What did you do?
* What happened?
* What were your expectations?

More notes
* Write as much as needed
* Describe what you see, did and *how you felt*
* Print screen is your friend!
* *Give praise*

== Extreme containment measures: keeping bug reports under control ==
Speaker:  Jean-Francois Fortin Tam
Homepage: http://jeff.ecchi.ca
Twitter:  https://twitter.com/nekohayo

Discussed the problem lot of OS projects are having: lot of useless
(old, irrelevant, waiting for decision no one wants to make) bug/rfe
reports in their bug tracking systems. Lots of food for thought about
our own projects, internal or external. Clever applications of
principles from personal productivity systems such as GTD and Inbox Zero
for bug tracking.  

The talk was mostly an applied version of this blog post, which is worth
reading:
http://jeff.ecchi.ca/blog/2012/10/08/reducing-our-core-apps-software-inventory/
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I particularly like the UX bug reporting guide lines. Need to take those into
account when reporting UI issues. &lt;/p&gt;
&lt;p&gt;I still haven't read the second blog post which also looks interesting although 
not very applicable to me. After all I'm the person reporting bugs not the one
who decides what and when gets fixed.&lt;/p&gt;</summary><category term="QA"></category><category term="events"></category></entry><entry><title>UI Bug for OpenSource.com</title><link href="http://atodorov.org/blog/2013/07/31/ui-bug-for-opensource-dot-com/" rel="alternate"></link><updated>2013-07-31T21:39:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-07-31:blog/2013/07/31/ui-bug-for-opensource-dot-com/</id><summary type="html">&lt;p&gt;&lt;img alt="&amp;quot;UI bug&amp;quot;" src="/images/opensource.com_ui_bug.png" title="UI bug" /&gt;&lt;/p&gt;
&lt;p&gt;A simple bug with the Facebook like and share widget. Looks familiar? 
Indeed it is! &lt;a href="http://sofiavalley.com"&gt;SofiaValley&lt;/a&gt; had the
&lt;a href="/blog/2013/06/02/sofiavalley-ui-bug/"&gt;same bug&lt;/a&gt; 2 months ago.&lt;/p&gt;
&lt;p&gt;Already reported and hopefully they fix it.&lt;/p&gt;</summary><category term="QA"></category></entry><entry><title>Performance test: Amazon ElastiCache vs Amazon S3</title><link href="http://atodorov.org/blog/2013/06/26/performance-test-amazon-elasticache-vs-amazon-s3/" rel="alternate"></link><updated>2013-06-26T21:22:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-06-26:blog/2013/06/26/performance-test-amazon-elasticache-vs-amazon-s3/</id><summary type="html">&lt;p&gt;Which Django cache backend is faster? Amazon ElastiCache or Amazon S3 ?&lt;/p&gt;
&lt;p&gt;Previously I've mentioned about
&lt;a href="/blog/2013/06/19/django-tips-using-cache-for-stateful-http/"&gt;using Django's cache to keep state between HTTP requests&lt;/a&gt;.
In my demo described there I was using &lt;a href="http://github.com/atodorov/django-s3-cache"&gt;django-s3-cache&lt;/a&gt;.
It is time to move to production so I decided to measure the performance difference between the two
cache options available at Amazon Web Services.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update 2013-07-01&lt;/strong&gt;: my initial test may have been false since I had not configured
ElastiCache access properly. I saw no errors but discovered the issue today on another
system which was failing to store the cache keys but didn't show any errors either. 
I've re-run the tests and updated times are shown below.&lt;/p&gt;
&lt;h2&gt;Test infrastructure&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;One Amazon S3 bucket, located in US Standard (aka US East) region;&lt;/li&gt;
&lt;li&gt;One Amazon ElastiCache cluster with one Small Cache Node (cache.m1.small) with Moderate I/O capacity;&lt;/li&gt;
&lt;li&gt;One Amazon Elasticache cluster with one Large Cache Node (cache.m1.large) with High I/O Capacity;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Update:&lt;/strong&gt; I've tested both &lt;code&gt;python-memcached&lt;/code&gt; and &lt;code&gt;pylibmc&lt;/code&gt; client libraries for Django;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Update:&lt;/strong&gt; Test is executed from an EC2 node in the us-east-1a availability zone;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Update:&lt;/strong&gt; Cache clusters are in the us-east-1a availability zone.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Test Scenario&lt;/h2&gt;
&lt;p&gt;The test platform is Django. I've created a
&lt;a href="https://github.com/atodorov/Amazon-ElastiCache-vs-Amazon-S3-Django"&gt;skeleton project&lt;/a&gt;
with only &lt;code&gt;CACHES&lt;/code&gt; settings
defined and necessary dependencies installed. A file called &lt;code&gt;test.py&lt;/code&gt; holds the
test cases, which use the standard timeit module. The object which is stored in cache
is very small - it holds a phone/address identifiers and couple of user made selections.
The code looks like this:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;timeit&lt;/span&gt;

&lt;span class="n"&gt;s3_set&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;timeit&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Timer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;for i in range(1000):&lt;/span&gt;
&lt;span class="sd"&gt;    my_cache.set(i, MyObject)&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;from django.core import cache&lt;/span&gt;

&lt;span class="sd"&gt;my_cache = cache.get_cache(&amp;#39;default&amp;#39;)&lt;/span&gt;

&lt;span class="sd"&gt;MyObject = {&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;from&amp;#39; : &amp;#39;359123456789&amp;#39;,&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;address&amp;#39; : &amp;#39;6afce9f7-acff-49c5-9fbe-14e238f73190&amp;#39;,&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;hour&amp;#39; : &amp;#39;12:30&amp;#39;,&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;weight&amp;#39; : 5,&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;type&amp;#39; : 1,&lt;/span&gt;
&lt;span class="sd"&gt;}&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;s3_get&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;timeit&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Timer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;for i in range(1000):&lt;/span&gt;
&lt;span class="sd"&gt;    MyObject = my_cache.get(i)&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;from django.core import cache&lt;/span&gt;

&lt;span class="sd"&gt;my_cache = cache.get_cache(&amp;#39;default&amp;#39;)&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Tests were executed from the Django shell &lt;del&gt;on my laptop&lt;/del&gt;
on an EC2 instance in the us-east-1a availability zone. ElastiCache nodes
were freshly created/rebooted before test execution. S3 bucket had no objects.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="err"&gt;$&lt;/span&gt; &lt;span class="o"&gt;./&lt;/span&gt;&lt;span class="n"&gt;manage&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="n"&gt;shell&lt;/span&gt;
&lt;span class="n"&gt;Python&lt;/span&gt; &lt;span class="mf"&gt;2.6&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;unknown&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Mar&lt;/span&gt; &lt;span class="mi"&gt;14&lt;/span&gt; &lt;span class="mi"&gt;2013&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;31&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;GCC&lt;/span&gt; &lt;span class="mf"&gt;4.6&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;20111027&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Red&lt;/span&gt; &lt;span class="n"&gt;Hat&lt;/span&gt; &lt;span class="mf"&gt;4.6&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;linux2&lt;/span&gt;
&lt;span class="n"&gt;Type&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;help&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;copyright&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;credits&amp;quot;&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;license&amp;quot;&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;more&lt;/span&gt; &lt;span class="n"&gt;information&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;InteractiveConsole&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;test&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;s3_set&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;68.089607000350952&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;70.806712865829468&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;72.49261999130249&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;s3_get&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;43.778793096542358&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;43.054368019104004&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;36.19232702255249&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;pymc_set&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.40637087821960449&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.3568730354309082&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.35815882682800293&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;pymc_get&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.35759496688842773&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.35180497169494629&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.39198613166809082&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;libmc_set&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.3902890682220459&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.30157709121704102&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.30596804618835449&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;libmc_get&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.28874802589416504&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.30520200729370117&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.29050207138061523&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;libmc_large_set&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;1.0291709899902344&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.31709098815917969&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.32010698318481445&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;libmc_large_get&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.2957158088684082&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.29067802429199219&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.29692888259887695&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Results&lt;/h2&gt;
&lt;p&gt;As expected ElastiCache is much faster (10x) compared to S3. However the difference
between the two ElastiCache node types is subtle. I will stay with the smallest
possible node to minimize costs. Also as seen, pylibmc is a bit faster compared to
the pure Python implementation. &lt;/p&gt;
&lt;p&gt;Depending on your objects size or how many set/get operations you perform per
second you may need to go with the larger nodes. Just test it!&lt;/p&gt;
&lt;p&gt;&lt;del&gt;It surprised me how slow django-s3-cache is.&lt;/del&gt;
The false test showed django-s3-cache to be 100x slower but new results are better.
10x decrease in performance sounds about right for a filesystem backed cache.&lt;/p&gt;
&lt;p&gt;A quick look at the code
of the two backends shows some differences. The one I immediately see is that
for every cache key django-s3-cache creates an sha1 hash which is used as the
storage file name. This was modeled after the filesystem backend but I think the
design is wrong - the memcached backends don't do this.&lt;/p&gt;
&lt;p&gt;Another one is that django-s3-cache time-stamps all objects and uses pickle to serialize them. 
I wonder if it can't just write them as binary blobs directly. There's definitely lots
of room for improvement of django-s3-cache. I will let you know my findings once I
get to it. &lt;/p&gt;</summary><category term="Amazon"></category><category term="S3"></category><category term="ElastiCache"></category><category term="QA"></category><category term="performance testing"></category><category term="cloud"></category></entry><entry><title>Even Facebook has Bugs</title><link href="http://atodorov.org/blog/2013/06/20/even-facebook-has-bugs/" rel="alternate"></link><updated>2013-06-20T10:17:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-06-20:blog/2013/06/20/even-facebook-has-bugs/</id><summary type="html">&lt;p&gt;&lt;img src="/images/facebook_ui_bug.png" alt="Faceook bug" style="float:left; margin-right: 10px;"/&gt;&lt;/p&gt;
&lt;p&gt;Here's a small but very visible UI bug in Facebook. While selecting for which
applications to receive or not notifications there is a small progress bar image
that appears left of the checkbox element. The trouble is this image displaces the
checkbox and it appears to float right and left during the AJAX call. This is annoying.&lt;/p&gt;
&lt;p&gt;There's an easy fix - either fix the progress image and checkbox positions so they don't move
or place the image to the right.&lt;/p&gt;
&lt;p&gt;In my practice these types of bugs are common. I usually classify them with High priority,
because they tend to annoy the user and generate support calls or just look unprofessional.&lt;/p&gt;</summary><category term="QA"></category></entry><entry><title>SofiaValley UI bug</title><link href="http://atodorov.org/blog/2013/06/02/sofiavalley-ui-bug/" rel="alternate"></link><updated>2013-06-02T21:04:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-06-02:blog/2013/06/02/sofiavalley-ui-bug/</id><summary type="html">&lt;p&gt;&lt;img src="/images/bugs/sv-bug.png" alt="SV bug" style="clear:both;display:block;"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://sofiavalley.com"&gt;SofiaValley&lt;/a&gt; recently had a bug in their UI.
As seen above when clicking the Like button the widget would overlap with
other visual elements. At first this doesn't look like a big deal but it blocks
the user from sharing the page via Facebook which is important for a blog.&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/bugs/sv-bug-fixed.png" alt="SV bug fixed" style="clear:both;display:block;"/&gt;&lt;/p&gt;
&lt;p&gt;I have reported the error and it was fixed very quickly. +1 for SofiaValley.&lt;/p&gt;
&lt;p&gt;Have you spotted any other interesting bugs? Let me know and they will be published
here.&lt;/p&gt;</summary><category term="QA"></category></entry><entry><title>Linux and Python Tools To Compare Images</title><link href="http://atodorov.org/blog/2013/05/17/linux-and-python-tools-to-compare-images/" rel="alternate"></link><updated>2013-05-17T21:13:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-05-17:blog/2013/05/17/linux-and-python-tools-to-compare-images/</id><summary type="html">&lt;p&gt;How to compare two images in Python? A tricky question with quite a few answers.
Since my needs are simple, my solution is simpler!&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/difio_compare.png" alt="Difio Google +1 changes" style="clear:both;display:block"/&gt;
&lt;a href="http://www.dif.io"&gt;dif.io&lt;/a&gt; homepage before and after it got a G+1.&lt;/p&gt;
&lt;h2&gt;ImageMagic is magic&lt;/h2&gt;
&lt;p&gt;If you haven't heard of &lt;a href="http://www.imagemagick.org/"&gt;ImageMagic&lt;/a&gt; then you've been
living in a cave on a deserted island! The suite contains the &lt;code&gt;compare&lt;/code&gt; command
which mathematically and visually annotates the difference between two images.&lt;/p&gt;
&lt;p&gt;The third image above was produced with:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;compare difio_10.png difio_11.png difio_diff.png
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Differences are displayed in red (default) and the original image is seen in the
background. As shown, the Google +1 button and count has changed between the two
images. &lt;code&gt;compare&lt;/code&gt; is a nice tool for manual inspection and debugging.
It works well in this case because the images are lossless PNGs and are regions of
screen shots where most objects are the same.&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/chestnut_compare.jpg" alt="JPEG quality reduction" style="clear:both;display:block"/&gt;
Chestnuts I had in Rome. 100% to 99% quality reduction.&lt;/p&gt;
&lt;p&gt;As seen on the second image set only 1% of JPEG quality change leads to many small
differences in the image, which are invisible to the naked eye.&lt;/p&gt;
&lt;h2&gt;Python Imaging Library aka PIL&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://www.pythonware.com/products/pil/"&gt;PIL&lt;/a&gt; is another powerful tool for
image manipulation. I googled around and found some answers to my original
questions
&lt;a href="http://stackoverflow.com/questions/1927660/compare-two-images-the-python-linux-way"&gt;here&lt;/a&gt;.
The proposed solution is to calculate
&lt;a href="https://en.wikipedia.org/wiki/Root_mean_square"&gt;RMS&lt;/a&gt; of the two images
and compare that with some threshold to establish the level of certainty that
two images are identical.&lt;/p&gt;
&lt;h2&gt;Simple solution&lt;/h2&gt;
&lt;p&gt;I've been working on a script lately which needs to know what is displayed on
the screen and recognize some of the objects. Calculating image similarity is
quite complex but comparing if two images are &lt;strong&gt;exactly&lt;/strong&gt; identical is not.
Given my environment and the fact
that I'm comparing screen shots where only few areas changed
(see first image above for example) led to the following solution: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Take a screen shot;&lt;/li&gt;
&lt;li&gt;Crop a particular area of the image which needs to be examined;&lt;/li&gt;
&lt;li&gt;Compare to a baseline image of the same area created manually;&lt;/li&gt;
&lt;li&gt;Don't use RMS, use the image histogram only to speed up calculation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I've prepared the baseline images with GIMP and tested couple of scenarios
using &lt;code&gt;compare&lt;/code&gt;. Here's how it looks in code:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;PIL&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Image&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;dogtail.utils&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;screenshot&lt;/span&gt;

&lt;span class="n"&gt;baseline_histogram&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Image&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;/home/atodorov/baseline.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;histogram&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;img&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Image&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;screenshot&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;region&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;crop&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;860&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;300&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;950&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;320&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;region&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;histogram&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;baseline_histogram&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Results&lt;/h2&gt;
&lt;p&gt;The presented solution was easy to program, works fast and reliably for my use case.
In fact after several iterations I've added a second baseline image to account for some
unidentified noise which appears randomly in the first region. As far as I can tell
the two checks combined are 100% accurate. &lt;/p&gt;
&lt;h2&gt;Field of application&lt;/h2&gt;
&lt;p&gt;I'm working on QA automation where this comes handy. However you may try some
lame CAPTCHA recognition by comparing regions to a pre-defined baseline. Let me know
if you come up with a cool idea or actually used this in code. &lt;/p&gt;
&lt;p&gt;I'd love to hear
about interesting projects which didn't get too complicated because of image
recognition.&lt;/p&gt;</summary><category term="Python"></category><category term="QA"></category></entry><entry><title>Bug in the Fridge</title><link href="http://atodorov.org/blog/2013/03/29/bug-in-the-fridge/" rel="alternate"></link><updated>2013-03-29T15:09:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-03-29:blog/2013/03/29/bug-in-the-fridge/</id><summary type="html">&lt;p&gt;&lt;img src="/images/liebherr_kbgb_3864.jpg" alt="Liebherr KBGB 3864" style="float:left; margin-right: 20px;" /&gt;&lt;/p&gt;
&lt;p&gt;Once you've been into
&lt;a target="_blank" href="http://www.amazon.com/s/?_encoding=UTF8&amp;camp=1789&amp;creative=390957&amp;field-keywords=quality%20assurance&amp;linkCode=ur2&amp;rh=i%3Aaps%2Ck%3Aquality%20assurance&amp;sprefix=quality%20ass%2Caps%2C273&amp;tag=atodorovorg-20&amp;url=search-alias%3Daps"&gt;Quality Assurance&lt;/a&gt;&lt;img src="https://www.assoc-amazon.com/e/ir?t=atodorovorg-20&amp;l=ur2&amp;o=1" width="1" height="1" border="0"  style="border:none !important; margin:0px !important;" /&gt;
for 5+ years you start to notice &lt;a href="/blog/categories/qa/"&gt;bugs everywhere&lt;/a&gt;
and develop a sixth sense for it. Today I found a bug in my
&lt;a target="_blank" href="http://www.amazon.com/s/?_encoding=UTF8&amp;camp=1789&amp;creative=390957&amp;field-keywords=liebherr&amp;linkCode=ur2&amp;rh=n%3A2619525011%2Ck%3Aliebherr&amp;sprefix=Liebherr%2Caps%2C273&amp;tag=atodorovorg-20&amp;url=search-alias%3Dappliances"&gt;Liebherr&lt;/a&gt;&lt;img src="https://www.assoc-amazon.com/e/ir?t=atodorovorg-20&amp;l=ur2&amp;o=1" width="1" height="1" border="0"  style="border:none !important; margin:0px !important;" /&gt;
KBGB 3864 refrigerator, caused by what looks like a race-condition.&lt;/p&gt;
&lt;p&gt;This appliance starts beeping in case the door is left open for more than 60 seconds.
The alarm stops if door is closed or can be muted manually while the door is still open.&lt;/p&gt;
&lt;h2&gt;The Bug&lt;/h2&gt;
&lt;p&gt;It happened so that I had the door open for nearly one minute and as it was closing 
I heard a beep. This time however the beeping didn't stop after the door had closed.
The alarm continued beeping with the door closed so I tried to re-open and close it again.
It didn't stop! I had to open the door and manually mute the alarm for it to stop. &lt;/p&gt;
&lt;div style="display:block; clear:both;"&gt;&amp;nbsp;&lt;/div&gt;

&lt;h2&gt;The Root Cause&lt;/h2&gt;
&lt;p&gt;While not entirely sure, I think the reason for this malfunction
was a race-condition. The alarm went on at nearly the same time when the 
controlling timer should have gone off (when closing the door).&lt;/p&gt;
&lt;h2&gt;Steps To Reproduce&lt;/h2&gt;
&lt;p&gt;I tried reproducing several times afterwards by opening and closing the door
at the last possible moment. I used a stop-watch to time my actions. However
I wasn't able to reproduce twice. Every time I tried, there was only one single
beep as the door was closing and no more.&lt;/p&gt;
&lt;p&gt;I guess then, like we say in QE, &lt;em&gt;WORKS FOR ME&lt;/em&gt;!&lt;/p&gt;</summary><category term="QA"></category></entry><entry><title>Bug in Nokia software shows wrong caller ID</title><link href="http://atodorov.org/blog/2013/03/19/bug-in-nokia-software-shows-wrong-caller-id/" rel="alternate"></link><updated>2013-03-19T09:57:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-03-19:blog/2013/03/19/bug-in-nokia-software-shows-wrong-caller-id/</id><summary type="html">&lt;p&gt;During the past month one of my cell phones,
&lt;a target="_blank" href="http://www.amazon.com/s/?_encoding=UTF8&amp;camp=1789&amp;creative=390957&amp;field-keywords=Nokia&amp;linkCode=ur2&amp;tag=atodorovorg-20&amp;url=search-alias%3Daps"&gt;Nokia&lt;/a&gt;&lt;img src="https://www.assoc-amazon.com/e/ir?t=atodorovorg-20&amp;l=ur2&amp;o=1" width="1" height="1" border="0"  style="border:none !important; margin:0px !important;" /&gt;
&lt;a href="http://www.amazon.com/gp/product/B001SEAOC6/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=B001SEAOC6&amp;linkCode=as2&amp;tag=atodorovorg-20"&gt;5800 XpressMusic&lt;/a&gt;&lt;img src="http://www.assoc-amazon.com/e/ir?t=atodorovorg-20&amp;l=as2&amp;o=1&amp;a=B001SEAOC6" width="1" height="1" border="0"  style="border:none !important; margin:0px !important;" /&gt;
, was not showing the caller name when a friend was calling.
The number in the contacts list was correct but the name wasn't showing,
nor the custom assigned ringing tone. It turned out to be a bug!&lt;/p&gt;
&lt;p&gt;The story behind this is that accidentally the same number was saved again
in the contacts list, but without a name assigned to it.
The software was matching the later one, so no custom ringing tone,
no name shown. Removing the duplicate entry fixed the issue. Software version of this
phone is&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;v 21.0.025
RM-356
02-04-09
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I wondered what will happen with multiple duplicates and if this was fixed in a later
software version so I tested with another phone,
&lt;a href="http://www.amazon.com/gp/product/B002RXEI6U/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=B002RXEI6U&amp;linkCode=as2&amp;tag=atodorovorg-20"&gt;Nokia 6303&lt;/a&gt;&lt;img src="http://www.assoc-amazon.com/e/ir?t=atodorovorg-20&amp;l=as2&amp;o=1&amp;a=B002RXEI6U" width="1" height="1" border="0"  style="border:none !important; margin:0px !important;" /&gt;.
Software version is&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;V 07.10
25-03-10
RM-638
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Step 0 - add the number to the contacts list, with name &lt;code&gt;Buddy 1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Step 1 - add the same number to the contacts, with &lt;strong&gt;empty name&lt;/strong&gt;.
&lt;strong&gt;Result&lt;/strong&gt;: You get a warning this number is already present for &lt;code&gt;Buddy 1&lt;/code&gt;!
When receiving a call, &lt;code&gt;Buddy 1&lt;/code&gt; is displayed.&lt;/li&gt;
&lt;li&gt;Step 2 - edit the empty name contact and change the name to &lt;code&gt;Buddy 2&lt;/code&gt;.
&lt;strong&gt;Result&lt;/strong&gt;: when receiving a call &lt;code&gt;Buddy 2&lt;/code&gt; is displayed.&lt;/li&gt;
&lt;li&gt;Step 3 - add the same number again, with name &lt;code&gt;Buddy 0&lt;/code&gt;. This is the latest entry
but it is sorted before the previous two (this is important).
&lt;strong&gt;Result&lt;/strong&gt;: You get a warning that this number is already present for &lt;code&gt;Buddy 1&lt;/code&gt; and &lt;code&gt;Buddy 2&lt;/code&gt;.
When receiving a call &lt;code&gt;Buddy 0&lt;/code&gt; is displayed.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Summary&lt;/strong&gt;: so it looks like Nokia fixed the issue with empty names, by simply ignoring them
but when multiple duplicate contacts are available it displays the name of the last entered in the
contact list, independent of name sort order.&lt;/p&gt;
&lt;p&gt;&lt;del&gt;
Later today or tomorrow I will test on 
&lt;a href="http://www.amazon.com/gp/product/B005MOW7S2/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=B005MOW7S2&amp;linkCode=as2&amp;tag=atodorovorg-20"&gt;Nokia 700&lt;/a&gt;&lt;img src="http://www.assoc-amazon.com/e/ir?t=atodorovorg-20&amp;l=as2&amp;o=1&amp;a=B005MOW7S2" width="1" height="1" border="0"  style="border:none !important; margin:0px !important;" /&gt;
which runs Symbian OS and update this post with more results.
&lt;/del&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Updated on 2013-03-19 23:50&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Finally managed to test on
&lt;a href="http://www.amazon.com/gp/product/B005MOW7S2/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=B005MOW7S2&amp;linkCode=as2&amp;tag=atodorovorg-20"&gt;Nokia 700&lt;/a&gt;&lt;img src="http://www.assoc-amazon.com/e/ir?t=atodorovorg-20&amp;l=as2&amp;o=1&amp;a=B005MOW7S2" width="1" height="1" border="0"  style="border:none !important; margin:0px !important;" /&gt;.
Software version is:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;Release
Nokia Belle Feature pack 1
Software version
112.010.1404
Software version date
2012-03-30
Type
RM-670
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Result&lt;/strong&gt;: If a duplicate contact entry is present it doesn't matter if the name is empty or not.
Both times no name was displayed when receiving a call. Looks like Nokia is not paying attention to
regressions at all.&lt;/p&gt;
&lt;h2&gt;Android and iPhone&lt;/h2&gt;
&lt;p&gt;I don't own any
&lt;a target="_blank" href="http://www.amazon.com/s/?_encoding=UTF8&amp;camp=1789&amp;creative=390957&amp;field-keywords=Android&amp;linkCode=ur2&amp;tag=atodorovorg-20&amp;url=search-alias%3Delectronics"&gt;Android&lt;/a&gt;&lt;img src="https://www.assoc-amazon.com/e/ir?t=atodorovorg-20&amp;l=ur2&amp;o=1" width="1" height="1" border="0"  style="border:none !important; margin:0px !important;" /&gt;
or
&lt;a target="_blank" href="http://www.amazon.com/s/?_encoding=UTF8&amp;camp=1789&amp;creative=390957&amp;field-keywords=iPhone&amp;linkCode=ur2&amp;rh=n%3A172282%2Ck%3AiPhone&amp;tag=atodorovorg-20&amp;url=search-alias%3Delectronics"&gt;iPhone&lt;/a&gt;&lt;img src="https://www.assoc-amazon.com/e/ir?t=atodorovorg-20&amp;l=ur2&amp;o=1" width="1" height="1" border="0"  style="border:none !important; margin:0px !important;" /&gt;
devices so I'm not able to test on them. If you have one, please let me know if this bug is still present
and how does the software behave when multiple contacts share the same number or have empty names! Thanks!&lt;/p&gt;</summary><category term="Nokia"></category><category term="QA"></category></entry><entry><title>Performance Test: Amazon EBS vs. Instance Storage, Pt.1</title><link href="http://atodorov.org/blog/2013/02/26/performance-test-amazon-ebs-vs-instance-storage-pt1/" rel="alternate"></link><updated>2013-02-26T23:02:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-02-26:blog/2013/02/26/performance-test-amazon-ebs-vs-instance-storage-pt1/</id><summary type="html">&lt;p&gt;I'm exploring the possibility to speed-up my cloud database so I've run some
basic tests against storage options available to Amazon EC2 instances.
The instance was &lt;a href="http://aws.amazon.com/ec2/instance-types/"&gt;m1.large&lt;/a&gt;
with High I/O performance and two additional disks with the same size:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;/dev/xvdb - type EBS&lt;/li&gt;
&lt;li&gt;/dev/xvdc - type instance storage&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Both are Xen para-virtual disks. The difference is that EBS is persistent
across reboots while instance storage is ephemeral.&lt;/p&gt;
&lt;h2&gt;hdparm&lt;/h2&gt;
&lt;p&gt;For a quick test I used &lt;code&gt;hdparm&lt;/code&gt;. The manual says:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;-T  Perform timings of cache reads for benchmark and comparison purposes.
    This displays the speed of reading directly from the Linux buffer cache
    without disk access. This measurement is essentially an indication of
    the throughput of the processor, cache, and memory of the system under test.

-t  Perform timings of device reads for benchmark and comparison purposes.
    This displays the speed of reading through the buffer cache to the disk
    without any prior caching of data. This measurement is an indication of how
    fast the drive can sustain sequential data reads under Linux, without any
    filesystem overhead.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The results of 3 runs of hdparm are shown below:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;# hdparm -tT /dev/xvdb /dev/xvdc

/dev/xvdb:
 Timing cached reads:   11984 MB in  1.98 seconds = 6038.36 MB/sec
 Timing buffered disk reads:  158 MB in  3.01 seconds =  52.52 MB/sec

/dev/xvdc:
 Timing cached reads:   11988 MB in  1.98 seconds = 6040.01 MB/sec
 Timing buffered disk reads:  1810 MB in  3.00 seconds = 603.12 MB/sec


# hdparm -tT /dev/xvdb /dev/xvdc

/dev/xvdb:
 Timing cached reads:   11892 MB in  1.98 seconds = 5991.51 MB/sec
 Timing buffered disk reads:  172 MB in  3.00 seconds =  57.33 MB/sec

/dev/xvdc:
 Timing cached reads:   12056 MB in  1.98 seconds = 6075.29 MB/sec
 Timing buffered disk reads:  1972 MB in  3.00 seconds = 657.11 MB/sec


# hdparm -tT /dev/xvdb /dev/xvdc

/dev/xvdb:
 Timing cached reads:   11994 MB in  1.98 seconds = 6042.39 MB/sec
 Timing buffered disk reads:  254 MB in  3.02 seconds =  84.14 MB/sec

/dev/xvdc:
 Timing cached reads:   11890 MB in  1.99 seconds = 5989.70 MB/sec
 Timing buffered disk reads:  1962 MB in  3.00 seconds = 653.65 MB/sec
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Result:&lt;/strong&gt;
Sequential reads from instance storage are 10x faster compared to EBS on average.&lt;/p&gt;
&lt;h2&gt;IOzone&lt;/h2&gt;
&lt;p&gt;I'm running MySQL and sequential data reads are probably over idealistic scenario.
So I found another benchmark suite, called &lt;a href="http://iozone.org"&gt;IOzone&lt;/a&gt;.
I used the 3-414 version built from the official SRPM.&lt;/p&gt;
&lt;p&gt;IOzone performs multiple tests. I'm interested in read/re-read, random-read/write,
read-backwards and stride-read.&lt;/p&gt;
&lt;p&gt;For this round of testing I've tested with ext4 filesystem with and without journal
on both types of disks. I also experimented running Iozone inside a ramfs mounted
directory. However I didn't have the time to run the test suite multiple times.&lt;/p&gt;
&lt;p&gt;Then I used
&lt;a href="http://code.google.com/p/iozone-results-comparator/"&gt;iozone-results-comparator&lt;/a&gt; to
visualize the results. (I had to do a minor fix to the code to run inside virtualenv
and install all missing dependencies).&lt;/p&gt;
&lt;p&gt;Raw IOzone output, data visualization and the modified tools are available in the
&lt;a href="http://s3.amazonaws.com/atodorov/blog/aws_disk_benchmark_w_iozone.tar.bz2"&gt;aws_disk_benchmark_w_iozone.tar.bz2&lt;/a&gt;
file (size 51M).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Graphics&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;EBS without journal(Baseline) vs. Instance Storage without journal(Set1)
&lt;img alt="EBS vs. Instance Storage" src="/images/aws_iozone/ebs_woj_vs_is_woj.png" title="EBS vs. Instance Storage" /&gt;&lt;/p&gt;
&lt;p&gt;Instance Storage without journal(Baseline) vs. Ramfs(Set1)
&lt;img alt="IS vs. Ramfs" src="/images/aws_iozone/ebs_woj_vs_is_woj.png" title="IS vs. Ramfs" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Results&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ext4 journal has no effect on reads, causes slow down when writing to disk. This
is expected;&lt;/li&gt;
&lt;li&gt;Instance storage is faster compared to EBS but not much.
If I understand the results correctly, read performance is similar in some cases;&lt;/li&gt;
&lt;li&gt;Ramfs is definitely the fastest but read performance compared to instance storage
is not two-fold (or more) as I expected;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Instance storage appears to be faster (and this is expected) but I'm still not sure if
my application will gain any speed improvement or how much if migrated to read from
instance storage (or ramfs) instead of EBS. I will be performing more real-world
test next time, by comparing execution time for some of my largest SQL queries.&lt;/p&gt;
&lt;p&gt;If you have other ideas how to adequately measure I/O performance in the AWS cloud,
please use the comments below.&lt;/p&gt;</summary><category term="performance testing"></category><category term="QA"></category><category term="Amazon"></category><category term="EC2"></category><category term="cloud"></category></entry><entry><title>Performance test of MD5, SHA1, SHA256 and SHA512</title><link href="http://atodorov.org/blog/2013/02/05/performance-test-md5-sha1-sha256-sha512/" rel="alternate"></link><updated>2013-02-05T10:33:00+02:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2013-02-05:blog/2013/02/05/performance-test-md5-sha1-sha256-sha512/</id><summary type="html">&lt;p&gt;A few months ago I wrote
&lt;a href="https://github.com/atodorov/django-s3-cache"&gt;django-s3-cache&lt;/a&gt;.
This is Amazon Simple Storage Service (S3) cache backend for Django
which uses hashed file names.
django-s3-cache uses &lt;code&gt;sha1&lt;/code&gt; instead of &lt;code&gt;md5&lt;/code&gt; which appeared to be
faster at the time. I recall that my testing wasn't very robust so I did another
round.&lt;/p&gt;
&lt;h2&gt;Test Data&lt;/h2&gt;
&lt;p&gt;The file &lt;a href="http://s3.amazonaws.com/atodorov/blog/urls.txt.gz"&gt;urls.txt&lt;/a&gt;
contains 10000 unique paths from the &lt;a href="http://www.dif.io"&gt;dif.io&lt;/a&gt;
website and looks like this:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;/updates/Django-1.3.1/Django-1.3.4/7858/
/updates/delayed_paperclip-2.4.5.2 c23a537/delayed_paperclip-2.4.5.2/8085/
/updates/libv8-3.3.10.4 x86_64-darwin-10/libv8-3.3.10.4/8087/
/updates/Data::Compare-1.22/Data::Compare-Type/8313/
/updates/Fabric-1.4.0/Fabric-1.4.4/8652/
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Test Automation&lt;/h2&gt;
&lt;p&gt;I used the standard &lt;a href="http://docs.python.org/2/library/timeit.html"&gt;timeit&lt;/a&gt;
module in Python.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;span class="filename"&gt;test.py&lt;/span&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/usr/bin/python&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;timeit&lt;/span&gt;

&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;timeit&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Timer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;import hashlib&lt;/span&gt;
&lt;span class="sd"&gt;for line in url_paths:&lt;/span&gt;
&lt;span class="sd"&gt;    h = hashlib.md5(line).hexdigest()&lt;/span&gt;
&lt;span class="sd"&gt;#    h = hashlib.sha1(line).hexdigest()&lt;/span&gt;
&lt;span class="sd"&gt;#    h = hashlib.sha256(line).hexdigest()&lt;/span&gt;
&lt;span class="sd"&gt;#    h = hashlib.sha512(line).hexdigest()&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;url_paths = []&lt;/span&gt;
&lt;span class="sd"&gt;f = open(&amp;#39;urls.txt&amp;#39;, &amp;#39;r&amp;#39;)&lt;/span&gt;
&lt;span class="sd"&gt;for l in f.readlines():&lt;/span&gt;
&lt;span class="sd"&gt;    url_paths.append(l)&lt;/span&gt;
&lt;span class="sd"&gt;f.close()&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Test Results&lt;/h2&gt;
&lt;p&gt;The main statement hashes all 10000 entries one by one. This statement is
executed 1000 times in a loop, which is repeated 3 times. I have Python 2.6.6
on my system. After every test run the system was rebooted.
Execution time in seconds is available below.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;MD5     10.275190830230713, 10.155328989028931, 10.250311136245728
SHA1    11.985718965530396, 11.976419925689697, 11.86873197555542
SHA256  16.662450075149536, 21.551337003707886, 17.016510963439941
SHA512  18.339390993118286, 18.11187481880188,  18.085782051086426
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Looks like I was wrong the first time! MD5 is still faster but not that much.
I will stick with SHA1 for the time being.&lt;/p&gt;
&lt;p&gt;As always I’d love to hear your thoughts and feedback. Please use the comment form below.&lt;/p&gt;</summary><category term="Python"></category><category term="performance testing"></category><category term="QA"></category></entry><entry><title>Mission Impossible - ABRT Bugzilla Plugin on RHEL6</title><link href="http://atodorov.org/blog/2012/07/13/mission-impossible-abrt-bugzilla-plugin-on-rhel6/" rel="alternate"></link><updated>2012-07-13T13:21:00+03:00</updated><author><name>Alexander Todorov</name></author><id>tag:atodorov.org,2012-07-13:blog/2012/07/13/mission-impossible-abrt-bugzilla-plugin-on-rhel6/</id><summary type="html">&lt;p&gt;Some time ago Red Hat introduced Automatic Bug Reporting Tool to their Red Hat Enterprise Linux
platform. This is a nice tool which lets users report bugs easily to Red Hat.
However one of the plugins in the latest version doesn't seem usable at all.&lt;/p&gt;
&lt;p&gt;First make sure you have &lt;code&gt;libreport-plugin-bugzilla&lt;/code&gt; package installed. This is the plugin to
report bugs directly to &lt;a href="https://bugzilla.redhat.com"&gt;Bugzilla&lt;/a&gt;. It may not be installed by default
because customers are supposed to report issues to Support first - this is why they pay anyway.
If you are a tech savvy user though, you may want to skip Support and go straight to the developers.&lt;/p&gt;
&lt;p&gt;To enable Bugzilla plugin: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Edit the file &lt;code&gt;/etc/libreport/events.d/bugzilla_event.conf&lt;/code&gt; change the line&lt;div class="codehilite"&gt;&lt;pre&gt;EVENT=report_Bugzilla analyzer=libreport reporter-bugzilla -b
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;to&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;    EVENT=report_Bugzilla reporter-bugzilla -b
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Make sure ABRT will collect meaningful backtrace. If debuginfo is missing it will not let you continue.
Edit the file &lt;code&gt;/etc/libreport/events.d/ccpp_event.conf&lt;/code&gt;. There should be something like this:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="x"&gt;EVENT=analyze_LocalGDB analyzer=CCpp&lt;/span&gt;
&lt;span class="x"&gt;        abrt-action-analyze-core --core=coredump -o build_ids &amp;amp;&amp;amp;&lt;/span&gt;
&lt;span class="x"&gt;        abrt-action-generate-backtrace &amp;amp;&amp;amp;&lt;/span&gt;
&lt;span class="x"&gt;        abrt-action-analyze-backtrace&lt;/span&gt;
&lt;span class="x"&gt;        (&lt;/span&gt;
&lt;span class="x"&gt;            bug_id=&lt;/span&gt;&lt;span class="p"&gt;$(&lt;/span&gt;&lt;span class="err"&gt;reporter-bugzilla&lt;/span&gt; &lt;span class="err"&gt;-h&lt;/span&gt; &lt;span class="err"&gt;`cat&lt;/span&gt; &lt;span class="err"&gt;duphash`&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; &amp;amp;&amp;amp;&lt;/span&gt;
&lt;span class="x"&gt;            if test -n &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;bug_id&lt;/span&gt;&lt;span class="x"&gt;&amp;quot;; then&lt;/span&gt;
&lt;span class="x"&gt;                abrt-bodhi -r -b &lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;bug_id&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;            fi&lt;/span&gt;
&lt;span class="x"&gt;        )&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Change it to look like this - i.e. add the missing &lt;code&gt;/usr/libexec/&lt;/code&gt; line:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="x"&gt;EVENT=analyze_LocalGDB analyzer=CCpp&lt;/span&gt;
&lt;span class="x"&gt;        abrt-action-analyze-core --core=coredump -o build_ids &amp;amp;&amp;amp;&lt;/span&gt;
&lt;span class="x"&gt;        /usr/libexec/abrt-action-install-debuginfo-to-abrt-cache --size_mb=4096 &amp;amp;&amp;amp;&lt;/span&gt;
&lt;span class="x"&gt;        abrt-action-generate-backtrace &amp;amp;&amp;amp;&lt;/span&gt;
&lt;span class="x"&gt;        abrt-action-analyze-backtrace &amp;amp;&amp;amp;&lt;/span&gt;
&lt;span class="x"&gt;        (&lt;/span&gt;
&lt;span class="x"&gt;            bug_id=&lt;/span&gt;&lt;span class="p"&gt;$(&lt;/span&gt;&lt;span class="err"&gt;reporter-bugzilla&lt;/span&gt; &lt;span class="err"&gt;-h&lt;/span&gt; &lt;span class="err"&gt;`cat&lt;/span&gt; &lt;span class="err"&gt;duphash`&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; &amp;amp;&amp;amp;&lt;/span&gt;
&lt;span class="x"&gt;            if test -n &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;bug_id&lt;/span&gt;&lt;span class="x"&gt;&amp;quot;; then&lt;/span&gt;
&lt;span class="x"&gt;                abrt-bodhi -r -b &lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;bug_id&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;            fi&lt;/span&gt;
&lt;span class="x"&gt;        )&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Supposedly after everything is configured properly ABRT will install missing debuginfo packages,
generate the backtrace and let you report it to Bugzilla. Because of
&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=759443"&gt;bug 759443&lt;/a&gt; this will not happen.&lt;/p&gt;
&lt;p&gt;To work around the problem you can try to manually install the missing debuginfo packages.
Go to your system profile in RHN and subscribe the system to all appropriate debuginfo channels.
Then install the packages. In my case:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;    # debuginfo-install firefox
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And finally - &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=800754"&gt;bug 800754&lt;/a&gt; which was already reported!&lt;/p&gt;</summary><category term="QA"></category><category term="RHEL"></category></entry></feed>