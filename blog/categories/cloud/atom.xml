<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: cloud | atodorov.org - you can logoff, but you can never leave]]></title>
  <link href="http://atodorov.org/blog/categories/cloud/atom.xml" rel="self"/>
  <link href="http://atodorov.org/"/>
  <updated>2014-01-24T22:12:52+02:00</updated>
  <id>http://atodorov.org/</id>
  <author>
    <name><![CDATA[Alexander Todorov]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Idempotent Django Email Sender with Amazon SQS and Memcache]]></title>
    <link href="http://atodorov.org/blog/2013/12/11/idempotent-django-email-sender-with-amazon-sqs-and-memcache/"/>
    <updated>2013-12-11T23:29:00+02:00</updated>
    <id>http://atodorov.org/blog/2013/12/11/idempotent-django-email-sender-with-amazon-sqs-and-memcache</id>
    <content type="html"><![CDATA[<p>Recently I wrote about my problem with
<a href="/blog/2013/12/06/duplicate-amazon-sqs-messages-cause-multiple-emails/">duplicate Amazon SQS messages causing multiple emails</a>
for <a href="http://www.dif.io">Difio</a>. After considering several options and
feedback from
<a href="https://twitter.com/atodorov_/status/409429840820199424">@Answers4AWS</a>
I wrote a small decorator to fix this.</p>

<p>It uses the cache backend to prevent the task from executing twice
during the specified time frame. The code is available at
<a href="https://djangosnippets.org/snippets/3010/">https://djangosnippets.org/snippets/3010/</a>.</p>

<p>As stated on Twitter you should use Memcache (or ElastiCache) for this.
If using Amazon S3 with my
<a href="https://github.com/atodorov/django-s3-cache">django-s3-cache</a> don't use the
<code>us-east-1</code> region because it is eventually consistent.</p>

<p>The solution is fast and simple on the development side and uses my existing
cache infrastructure so it doesn't cost anything more!</p>

<p>There is still a race condition between marking the message as processed
and the second check but nevertheless this should minimize the possibility of
receiving duplicate emails to an accepted level. Only time will tell though!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Duplicate Amazon SQS Messages Cause Multiple Emails]]></title>
    <link href="http://atodorov.org/blog/2013/12/06/duplicate-amazon-sqs-messages-cause-multiple-emails/"/>
    <updated>2013-12-06T22:47:00+02:00</updated>
    <id>http://atodorov.org/blog/2013/12/06/duplicate-amazon-sqs-messages-cause-multiple-emails</id>
    <content type="html"><![CDATA[<p>Beware if using Amazon Simple Queue Service to send email messages!
Sometime SQS messages are duplicated which results in multiple copies of
the messages being sent. This happened today at <a href="http://www.dif.io">Difio</a>
and is really annoying to users. In this post I will explain why there is no easy
way of fixing it.</p>

<p>{% blockquote Amazon FAQ %}
Q: Can a deleted message be received again?</p>

<p>Yes, under rare circumstances you might receive a previously deleted message again.
This can occur in the rare situation in which a DeleteMessage operation doesn't
delete all copies of a message because one of the servers in the distributed
Amazon SQS system isn't available at the time of the deletion. That message copy
can then be delivered again. You should design your application so that no errors
or inconsistencies occur if you receive a deleted message again.
{% endblockquote %}</p>

<p>In my case the cron scheduler logs say:</p>

<pre><code>&gt;&gt;&gt; &lt;AsyncResult: a9e5a73a-4d4a-4995-a91c-90295e27100a&gt;
</code></pre>

<p>While on the worker nodes the logs say:</p>

<pre><code>[2013-12-06 10:13:06,229: INFO/MainProcess] Got task from broker: tasks.cron_monthly_email_reminder[a9e5a73a-4d4a-4995-a91c-90295e27100a]
[2013-12-06 10:18:09,456: INFO/MainProcess] Got task from broker: tasks.cron_monthly_email_reminder[a9e5a73a-4d4a-4995-a91c-90295e27100a]
</code></pre>

<p>This clearly shows the same message (see the UUID) has been processed twice!
This resulted in hundreds of duplicate emails :(.</p>

<h2>Why This Is Hard To Fix</h2>

<p>There are two basic approaches to solve this issue:</p>

<ul>
<li>Check some log files or database for previous record of the message having
been processed;</li>
<li>Use idempotent operations that if you process the message again, you
get the same results, and that those results don't create duplicate files/records.</li>
</ul>


<p>The problem with checking for duplicate messages is:</p>

<ul>
<li>There is a race condition between marking the message as processed and the
second check;</li>
<li>You need to use some sort of locking mechanism to safe-guard against the race condition;</li>
<li>In the event of an eventual consistency of the log/DB you can't guarantee that
the previous attempt will show up and so can't guarantee that you won't process
the message twice.</li>
</ul>


<p>All of the above don't seem to work well for distributed applications not to mention
Difio processes millions of messages per month, per node and the logs are quite big.</p>

<p>The second option is to have control of the Message-Id or some other email header
so that the second message will be discarded either at the server (Amazon SES in my case)
or at the receiving MUA. I like this better but I don't think it is technically possible
with the current environment. Need to check though.</p>

<p>I've asked AWS support to look into
<a href="https://forums.aws.amazon.com/thread.jspa?threadID=140782">this thread</a> and hopefully
they will have some more hints. If you have any other ideas please post in the comments!
Thanks!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bug in Python URLGrabber/cURL on Fedora and Amazon Linux]]></title>
    <link href="http://atodorov.org/blog/2013/11/29/bug-python-urlgrabber-curl-fedora-amazon-linux/"/>
    <updated>2013-11-29T14:05:00+02:00</updated>
    <id>http://atodorov.org/blog/2013/11/29/bug-python-urlgrabber-curl-fedora-amazon-linux</id>
    <content type="html"><![CDATA[<p>Accidentally I have discovered a bug for Python's
URLGrabber module which has to do with change in behavior in libcurl.</p>

<p>{% codeblock lang:python %}</p>

<blockquote><blockquote><blockquote><p>from urlgrabber.grabber import URLGrabber
g = URLGrabber(reget=None)
g.urlgrab('https://s3.amazonaws.com/production.s3.rubygems.org/gems/columnize-0.3.6.gem', '/tmp/columnize.gem')
Traceback (most recent call last):
  File "<console>", line 1, in <module>
  File "/home/celeryd/.virtualenvs/difio/lib/python2.6/site-packages/urlgrabber/grabber.py", line 976, in urlgrab</p>

<pre><code>return self._retry(opts, retryfunc, url, filename)
</code></pre>

<p>  File "/home/celeryd/.virtualenvs/difio/lib/python2.6/site-packages/urlgrabber/grabber.py", line 880, in _retry</p>

<pre><code>r = apply(func, (opts,) + args, {})
</code></pre>

<p>  File "/home/celeryd/.virtualenvs/difio/lib/python2.6/site-packages/urlgrabber/grabber.py", line 962, in retryfunc</p>

<pre><code>fo = PyCurlFileObject(url, filename, opts)
</code></pre>

<p>  File "/home/celeryd/.virtualenvs/difio/lib/python2.6/site-packages/urlgrabber/grabber.py", line 1056, in <strong>init</strong></p>

<pre><code>self._do_open()
</code></pre>

<p>  File "/home/celeryd/.virtualenvs/difio/lib/python2.6/site-packages/urlgrabber/grabber.py", line 1307, in _do_open</p>

<pre><code>self._set_opts()
</code></pre>

<p>  File "/home/celeryd/.virtualenvs/difio/lib/python2.6/site-packages/urlgrabber/grabber.py", line 1161, in _set_opts</p>

<pre><code>self.curl_obj.setopt(pycurl.SSL_VERIFYHOST, opts.ssl_verify_host)
</code></pre>

<p>error: (43, '')</p>

<p>{% endcodeblock %}</p></blockquote></blockquote></blockquote>

<p>The code above works fine with curl-7.27 or older while it breaks with curl-7.29 and
newer. As explained by
<a href="http://lists.baseurl.org/pipermail/yum-devel/2013-November/010428.html">Zdenek Pavlas</a>
the reason is an internal change in libcurl which doesn't accept a value of 1 anymore!</p>

<p>The bug is reproducible with a newer libcurl version and a vanilla urlgrabber==3.9.1
from PyPI (e.g. inside a virtualenv). The latest python-urlgrabber RPM packages in both
Fedora and Amazon Linux already have the fix.</p>

<p>I have tested the patch proposed by Zdenek and it works for me. I still have no idea why
there aren't any updates released on PyPI though!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[This Week: Python Testing, Chris DiBona on Open Source and OpenShift ENV Variables]]></title>
    <link href="http://atodorov.org/blog/2013/10/11/this-week-python-chris-dibona-openshift/"/>
    <updated>2013-10-11T10:45:00+03:00</updated>
    <id>http://atodorov.org/blog/2013/10/11/this-week-python-chris-dibona-openshift</id>
    <content type="html"><![CDATA[<p>Here is a random collection of links I came across this week which
appear interesting to me but I don't have time to blog about in details.</p>

<h2>Making a Multi-branch Test Server for Python Apps</h2>

<p>If you are wondering how to test different feature branches of your Python
application but don't have the resources to create separate test servers this
is for you:
<a href="http://depressedoptimism.com/blog/2013/10/8/making-a-multi-branch-test-server">http://depressedoptimism.com/blog/2013/10/8/making-a-multi-branch-test-server</a>!</p>

<p><em>Kudos to the python-django-bulgaria Google group for finding this link!</em></p>

<h2>OpenSource.com Interview with Chris DiBona</h2>

<p>Just read it at
<a href="http://opensource.com/business/13/10/interview-chris-dibona">http://opensource.com/business/13/10/interview-chris-dibona</a>.</p>

<p>I particularly like the part where he called open source "brutal".</p>

<p>{% blockquote %}
You once called open source “brutal”. What did you mean by that?</p>

<p>...</p>

<p>I think that it is because open source projects are able to only work with the
productive people and ignore everyone else. That behavior can come across as
very harsh or exclusionary, and that's because it is that: brutally harsh and
exclusionary of anyone who isn't contributing.</p>

<p>...</p>

<p>So, I guess what I'm saying is that survival of the fittest as practiced in the
open source world is a pretty brutal mechanism, but it works very very well for
producing quality software. Boy is it hard on newcomers though...
{% endblockquote %}</p>

<h2>OpenShift Finally Introduces Environment Variables</h2>

<p>Yes! Finally!</p>

<pre><code>    rhc set-env VARIABLE1=VALUE1 -a myapp
</code></pre>

<p>No need for
<a href="/blog/2013/07/08/tip-setting-secure-env-variables-on-red-hat-openshift/">my work around</a>
anymore! I will give the new feature a go very soon.</p>

<p>Read more about it at the OpenShift blog:
<a href="https://www.openshift.com/blogs/taking-advantage-of-environment-variables-in-openshift-php-apps">https://www.openshift.com/blogs/taking-advantage-of-environment-variables-in-openshift-php-apps</a>.</p>

<p>Have you found anything interesting this week? Please share in the comments below! Thanks!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tip: Setting Secure ENV variables on Red Hat OpenShift]]></title>
    <link href="http://atodorov.org/blog/2013/07/08/tip-setting-secure-env-variables-on-red-hat-openshift/"/>
    <updated>2013-07-08T21:39:00+03:00</updated>
    <id>http://atodorov.org/blog/2013/07/08/tip-setting-secure-env-variables-on-red-hat-openshift</id>
    <content type="html"><![CDATA[<p>OpenShift is
<a href="https://www.openshift.com/content/custom-environment-variables">still missing</a>
the client side tools to set environment variables without exposing the values
in source code but there is a way to do it. Here is how.</p>

<p>First ssh into your application and navigate to the <code>$OPENSHIFT_DATA_DIR</code>.
Create a file to define your environment.</p>

<p>{% codeblock lang:bash %}
$ rhc ssh -a difio
Password: ***</p>

<p>[difio-otb.rhcloud.com 51d32a854382ecf7a9000116]> cd $OPENSHIFT_DATA_DIR
[difio-otb.rhcloud.com data]> vi myenv.sh
[difio-otb.rhcloud.com data]> cat myenv.sh</p>

<h1>!/bin/bash</h1>

<p>export MYENV="hello"</p>

<p>[difio-otb.rhcloud.com data]> chmod a+x myenv.sh
[difio-otb.rhcloud.com data]> exit
Connection to difio-otb.rhcloud.com closed.
{% endcodeblock %}</p>

<p>Now modify your code and git push to OpenShift. Then ssh into the app once
again to verify that your configuration is still in place.</p>

<p>{% codeblock lang:bash %}
[atodorov@redbull difio]$ rhc ssh -a difio
Password: ***</p>

<p>[difio-otb.rhcloud.com 51d32a854382ecf7a9000116]> cd $OPENSHIFT_DATA_DIR
[difio-otb.rhcloud.com data]> ls -l
total 4
-rwxr-xr-x. 1 51d32a854382ecf7a9000116 51d32a854382ecf7a9000116 34  8 jul 14,33 myenv.sh
[difio-otb.rhcloud.com data]></p>

<p>{% endcodeblock %}</p>

<p>Use the defined variables as you wish.</p>
]]></content>
  </entry>
  
</feed>
