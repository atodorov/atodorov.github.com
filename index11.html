<!DOCTYPE html>
<html lang="en">

<head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="description" content="">
        <meta name="author" content="">

        <title>atodorov.org - you can logoff, but you can never leave</title>

            <link href="http://feeds.feedburner.com/atodorov" type="application/atom+xml" rel="alternate" title="atodorov.org Full Atom Feed" />

        <!-- Bootstrap Core CSS -->
        <link href="http://atodorov.org/theme/css/bootstrap.min.css" rel="stylesheet">

        <!-- Custom CSS -->
        <link href="http://atodorov.org/theme/css/clean-blog.min.css" rel="stylesheet">
        <link href="http://atodorov.org/override.css" rel="stylesheet">

        <!-- Code highlight color scheme -->
            <link href="http://atodorov.org/theme/css/code_blocks/github.css" rel="stylesheet">

        <!-- Custom Fonts -->
        <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
        <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
        <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

        <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
        <![endif]-->

		<meta property="og:locale" content="en">
		<meta property="og:site_name" content="atodorov.org">
</head>

<body>

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-custom navbar-fixed-top">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="http://atodorov.org/">atodorov.org</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">

                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
        <header class="intro-header" style="background-image: url('/images/header_02.jpg')">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <div class="page-heading">
                        <h1>atodorov.org</h1>
                            <hr class="small">
                            <span class="subheading">you can logoff, but you can never leave</span>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- Main Content -->
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2013/01/25/about-me/" rel="bookmark" title="Permalink to About Me">
                <h2 class="post-title">
                    About Me
                </h2>
            </a>
            <p><img style="float:left; margin-right: 25px;" src="/images/aboutme2.jpg" alt="This is how I look" title="This is how I look"/></p>
<p>My name is Alexander Todorov and this is how I look. It's pretty close!</p>
<p>I'm currently a contractor operating in the field of open source software and
quality engineering and a start-up owner with many ideas.
I also have some hard-earned certificates including:</p>
<ul>
<li>RHCE - Red Hat Certified Engineer - Oct 2008</li>
<li>RHCI - Red Hat Certified Instructor - Oct 2009</li>
<li>RHCVA - Red Hat Certified Virtualization Administrator - Sep 2010</li>
<li>Red Hat Partner Platform Certified Salesperson - Oct 2011</li>
<li>Red Hat Partner Virtualization Certified Salesperson - Oct 2011</li>
<li>Red Hat Partner Middleware Certified Salesperson - Oct 2011</li>
</ul>
<p>My professional interests cover vast amount of topics including but not limited
to Linux and open source, quality engineering, DevOps, cloud and
platform-as-a-service, programming with Python and Django.</p>
<p>I used to teach to students at Technical University Of Sofia with my friends
<a href="http://batsov.com">Bozhidar Batsov</a> and <a href="http://uk.linkedin.com/in/kirilkamburov">Kiril Kamburov</a>
but I don't have the time for this anymore. </p>
<p>You can always ping me if you'd like to chat or have a beer. See <a href="http://about.me/atodorov">http://about.me/atodorov</a>
or execute this command to see my email:</p>
<div class="codehilite"><pre><span class="n">echo</span> <span class="mi">17535658</span><span class="mf">@572.24</span> <span class="o">|</span> <span class="n">tr</span> <span class="p">[</span><span class="mi">12345678</span><span class="p">]</span> <span class="p">[</span><span class="n">abdgortv</span><span class="p">]</span>
</pre></div>


<p>I am usually working on several things at a time or affiliated with more than one
organization. This list contains current ventures and some of the more interesting
previous ones.</p>
<p><img style="float: left; margin-right: 10px;" src="/images/logos/obuvki41plus.png" alt="obuvki41plus" /></p>
<p><a href="http://obuvki41plus.com">Shoes 41 Plus</a> is niche oriented business selling ladies shoes with
sizes EU 41 and up, which are very hard to find in Bulgaria. We're also not shy to sell to men
who prefer ladies shoes!
<br /></p>
<p><img alt="&quot;OTB&quot;" src="/images/logos/otb.png" title="OTB" /></p>
<p><a href="http://otb.bg">Open Technologies Bulgaria, Ltd</a> is a company I founded in 2009 which
mainly does open source consulting for some local clients and QA services to Red Hat, Inc. It's
also an authorized
<a href="http://redhat.force.com/finder/PFPartnerDetail?id=0016000000LxykhAAB">Red Hat re-seller in Bulgaria</a>.</p>
<p><img style="float: left; margin-right: 10px;" src="/images/logos/redhat.png" alt="RedHat" /></p>
<p><a href="http://redhat.com">Red Hat, Inc.</a> is the largest enterprise Linux vendor as you probably know.
I used to work for them as an employee and still continue to do so as a contractor. My main responsibility
is making sure Red Hat Enterprise Linux (and some other products) get to customers without too
many bugs and behave as quality software. I'm highly biased towards all Red Hat products but
a) they didn't fail me once and b) I know how much hard work is done into making these products
kick ass.</p>
<p><img style="float: left; margin-right: 10px;" src="/images/logos/difio.png" alt="Difio" /></p>
<p><a href="http://www.dif.io">Difio</a> was a service targeted at developers
who use open source packages and libraries. It shut down on Sept 10th 2014.
<br /><br /></p>
<p><img style="float: left; margin-right: 10px;" src="/images/logos/olpcbg.png" alt="OLPC.bg" /></p>
<p><a href="http://laptop.org">OLPC</a> was a project to build an entirely new laptop device and software for the children
in developing countries. I was a co-founder of the Bulgarian chapter of this project.
While the upstream project delivered a hardware and a software platform it failed rather miserably.
Our local chapter didn't get much support and gradually ceased operations.</p>
<p>I also own some domains. If you are interested just ask!</p>
<ul>
<li><a href="http://atodorov.org">atodorov.org</a></li>
<li><a href="http://www.dif.io">dif.io</a> - not in use anymore</li>
<li><a href="http://obuvki41plus.com">obuvki41plus.com</a></li>
<li><a href="http://otb.bg">otb.bg</a></li>
<li>redhat.tips</li>
<li>rhca.guru</li>
<li>rhca.tips</li>
<li>rhce.guru</li>
<li>rhce.tips</li>
<li>rhel.tips</li>
<li>qecloud.com</li>
<li>qecloud.net</li>
<li>qecloud.org</li>
</ul>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Fri 25 January 2013
<p>There are <a href="http://atodorov.org/blog/2013/01/25/about-me/#disqus_thread">comments</a>.</p>            </p>
        </div>
        <hr>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2012/07/13/mission-impossible-abrt-bugzilla-plugin-on-rhel6/" rel="bookmark" title="Permalink to Mission Impossible - ABRT Bugzilla Plugin on RHEL6">
                <h2 class="post-title">
                    Mission Impossible - ABRT Bugzilla Plugin on RHEL6
                </h2>
            </a>
            <p>Some time ago Red Hat introduced Automatic Bug Reporting Tool to their Red Hat Enterprise Linux
platform. This is a nice tool which lets users report bugs easily to Red Hat.
However one of the plugins in the latest version doesn't seem usable at all.</p>
<p>First make sure you have <code>libreport-plugin-bugzilla</code> package installed. This is the plugin to
report bugs directly to <a href="https://bugzilla.redhat.com">Bugzilla</a>. It may not be installed by default
because customers are supposed to report issues to Support first - this is why they pay anyway.
If you are a tech savvy user though, you may want to skip Support and go straight to the developers.</p>
<p>To enable Bugzilla plugin: </p>
<ul>
<li>Edit the file <code>/etc/libreport/events.d/bugzilla_event.conf</code> change the line<div class="codehilite"><pre>EVENT=report_Bugzilla analyzer=libreport reporter-bugzilla -b
</pre></div>


</li>
</ul>
<p>to</p>
<div class="codehilite"><pre>    EVENT=report_Bugzilla reporter-bugzilla -b
</pre></div>


<ul>
<li>
<p>Make sure ABRT will collect meaningful backtrace. If debuginfo is missing it will not let you continue.
Edit the file <code>/etc/libreport/events.d/ccpp_event.conf</code>. There should be something like this:</p>
<div class="codehilite"><pre><span class="x">EVENT=analyze_LocalGDB analyzer=CCpp</span>
<span class="x">        abrt-action-analyze-core --core=coredump -o build_ids &amp;&amp;</span>
<span class="x">        abrt-action-generate-backtrace &amp;&amp;</span>
<span class="x">        abrt-action-analyze-backtrace</span>
<span class="x">        (</span>
<span class="x">            bug_id=</span><span class="p">$(</span><span class="err">reporter-bugzilla</span> <span class="err">-h</span> <span class="err">`cat</span> <span class="err">duphash`</span><span class="p">)</span><span class="x"> &amp;&amp;</span>
<span class="x">            if test -n &quot;</span><span class="p">$</span><span class="nv">bug_id</span><span class="x">&quot;; then</span>
<span class="x">                abrt-bodhi -r -b </span><span class="p">$</span><span class="nv">bug_id</span><span class="x"></span>
<span class="x">            fi</span>
<span class="x">        )</span>
</pre></div>


</li>
<li>
<p>Change it to look like this - i.e. add the missing <code>/usr/libexec/</code> line:</p>
<div class="codehilite"><pre><span class="x">EVENT=analyze_LocalGDB analyzer=CCpp</span>
<span class="x">        abrt-action-analyze-core --core=coredump -o build_ids &amp;&amp;</span>
<span class="x">        /usr/libexec/abrt-action-install-debuginfo-to-abrt-cache --size_mb=4096 &amp;&amp;</span>
<span class="x">        abrt-action-generate-backtrace &amp;&amp;</span>
<span class="x">        abrt-action-analyze-backtrace &amp;&amp;</span>
<span class="x">        (</span>
<span class="x">            bug_id=</span><span class="p">$(</span><span class="err">reporter-bugzilla</span> <span class="err">-h</span> <span class="err">`cat</span> <span class="err">duphash`</span><span class="p">)</span><span class="x"> &amp;&amp;</span>
<span class="x">            if test -n &quot;</span><span class="p">$</span><span class="nv">bug_id</span><span class="x">&quot;; then</span>
<span class="x">                abrt-bodhi -r -b </span><span class="p">$</span><span class="nv">bug_id</span><span class="x"></span>
<span class="x">            fi</span>
<span class="x">        )</span>
</pre></div>


</li>
</ul>
<p>Supposedly after everything is configured properly ABRT will install missing debuginfo packages,
generate the backtrace and let you report it to Bugzilla. Because of
<a href="https://bugzilla.redhat.com/show_bug.cgi?id=759443">bug 759443</a> this will not happen.</p>
<p>To work around the problem you can try to manually install the missing debuginfo packages.
Go to your system profile in RHN and subscribe the system to all appropriate debuginfo channels.
Then install the packages. In my case:</p>
<div class="codehilite"><pre>    # debuginfo-install firefox
</pre></div>


<p>And finally - <a href="https://bugzilla.redhat.com/show_bug.cgi?id=800754">bug 800754</a> which was already reported!</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Fri 13 July 2012
<p>There are <a href="http://atodorov.org/blog/2012/07/13/mission-impossible-abrt-bugzilla-plugin-on-rhel6/#disqus_thread">comments</a>.</p>            </p>
        </div>
        <hr>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2012/07/12/combining-pdf-files-on-the-command-line/" rel="bookmark" title="Permalink to Combining PDF Files On The Command Line">
                <h2 class="post-title">
                    Combining PDF Files On The Command Line
                </h2>
            </a>
            <p><strong>VERSION</strong></p>
<p>Red Hat Enterprise Linux 6</p>
<p><strong>PROBLEM</strong></p>
<p>You have to create a single PDF file by combining multiple files -
for example individually scanned pages.</p>
<p><strong>ASSUMPTIONS</strong></p>
<p>You know how to start a shell and havigate to the directory containing the files.</p>
<p><strong>SOLUTION</strong></p>
<p>If individual PDF files are named, for example, <code>doc_01.pdf</code>, <code>doc_02.pdf</code>, <code>doc_03.pdf</code>,
<code>doc_04.pdf</code>, then you can combine them with the <code>gs</code> command:</p>
<div class="codehilite"><pre>    $ gs -dBATCH -dNOPAUSE -sDEVICE=pdfwrite -sOutputFile=mydocument.pdf doc_*.pdf
</pre></div>


<p>The resulting PDF file will contain all pages from the individual files.</p>
<p><strong>MORE INFO</strong></p>
<p>The <code>gs</code> command is part of the <a href="http://www.ghostscript.com/">ghostscript</a> rpm package.
You can find more about it using <code>man gs</code>, the documentation file <code>/usr/share/doc/ghostscript-*/index.html</code>
or <a href="http://www.ghostscript.com">http://www.ghostscript.com</a>.</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Thu 12 July 2012
<p>There are <a href="http://atodorov.org/blog/2012/07/12/combining-pdf-files-on-the-command-line/#disqus_thread">comments</a>.</p>            </p>
        </div>
        <hr>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2012/05/19/cross-domain-ajax-served-from-cdn/" rel="bookmark" title="Permalink to Cross-domain AJAX Served From CDN">
                <h2 class="post-title">
                    Cross-domain AJAX Served From CDN
                </h2>
            </a>
            <p>This week Amazon <a href="http://aws.typepad.com/aws/2012/05/amazon-cloudfront-support-for-dynamic-content.html">announced</a>
support for dynamic content in their CDN solution <a href="http://aws.amazon.com/cloudfront/"><em>Amazon CloudFront</em></a>.
The announce coincided with my efforts to migrate more pieces of <em>Difio</em>'s <a href="http://www.dif.io">website</a> to <em>CloudFront</em>.</p>
<p>In this article I will not talk about hosting static files on CDN. This is easy and I've already written
about it <a href="/blog/2012/04/17/using-openshift-as-amazon-cloudfront-origin-server/">here</a>. I will show how to
cache AJAX(JSONP actually) responses and serve them directly from <em>Amazon CloudFront</em>.</p>
<h2>Background</h2>
<p>For those of you who may not be familiar (are there any) CDN stands for
<a href="https://en.wikipedia.org/wiki/Content_delivery_network">Content Delivery Network</a>. In short
this employs numerous servers with identical content. The requests from the browser are served
from the location which gives best performance for the user. This is used by all major websites
to speed-up static content like images, video, CSS and JavaScript files.</p>
<p>AJAX means <a href="https://en.wikipedia.org/wiki/Ajax_%28programming%29">Asynchronous JavaScript and XML</a>.
This is what Google uses to create dynamic user interface which doesn't require to reload the page.</p>
<h2>Architecture</h2>
<p><em>Difio</em> has two web interfaces. The primary one is a static HTML website
which employs JavaScript for the dynamic areas. It is hosted on the dif.io domain.
The other one is powered by Django and provides the same interface plus the
<a href="https://difio-otb.rhcloud.com/dashboard/">applications dashboard</a> and several API functions
which don't have a visible user interface. This is under the *.rhcloud.com domain b/c it is hosted on
<a href="http://openshift.redhat.com"><em>OpenShift</em></a>.</p>
<p>The present state of the website is the result of rapid development using conventional methods - 
HTML templates and server-side processing. This is migrating to modern web technology like static HTML
and JavaScript while the server side will remain pure API service.</p>
<p>For this migration to happen I need the HTML pages at dif.io to execute JavaScript and load information
which comes from the rhcloud.com domain. Unfortunately this is not easily doable with AJAX because
of the <a href="https://en.wikipedia.org/wiki/Same_origin_policy">Same origin policy</a> in browsers.</p>
<p>I'm using the <a href="http://dojotoolkit.org/"><em>Dojo Toolkit</em></a> JavaScript framework which has a solution.
It's called <a href="https://en.wikipedia.org/wiki/JSONP">JSONP</a>. Here's how it works:</p>
<div class="codehilite"><pre>     dif.io ------ JSONP request --&gt; abc.rhcloud.com --v
        ^                                              |
        |                                              |
    JavaScript processing                              |
        |                                              |
        +------------------ JSONP response ------------+
</pre></div>


<p>This is pretty standard configuration for a web service.</p>
<h2>Going to the clouds</h2>
<p>The way <em>Dojo</em> implements JSONP is through the
<a href="http://dojotoolkit.org/reference-guide/1.7/dojo/io/script.html">dojo.io.script</a> module.
It works by appending a query string parameter of the form <em>?callback=funcName</em> which the server uses
to generate the JSONP response. This callback name is dynamically generated by <em>Dojo</em> based on the order
in which your call to <em>dojo.io.script</em> is executed.</p>
<p>Until recently <em>Amazon CloudFront</em> ignored all query string parameters when requesting the content from
the origin server. Without the query string it was not possible to generate the JSONP response.
Luckily Amazon resolved the issue only one day after I asked about it on their forums.</p>
<p>Now <em>Amazon CloudFront</em> will use the URL path and the query string parameters to identify the objects in cache.
To enable this edit the CloudFront distribution <em>behavior(s)</em> and set <em>Forward Query Strings</em> to Yes.</p>
<p>When a visitor of the website requests the data <em>Amazon CloudFront</em> will use exactly the same url path and query strings
to fetch the content from the origin server. All that I had to do is switch the domain of the JSONP service
to point to the cloudfront.net domain. It became like this:</p>
<div class="codehilite"><pre>                                                        | Everything on this side is handled by Amazon.
                                                        | No code required!
                                                        |
     dif.io ------ JSONP request --&gt; xyz.cloudfront.net -- JSONP request if cache miss --&gt; abc.rhcloud.com --v
        ^                              |                ^                                                    |
        |                              |                |                                                    |
    JavaScript processing              |                +---------- JSONP response --------------------------+
        |                              |
        +---- cached JSONP response ---+
</pre></div>


<p>As you can see the website structure and code didn't change at all. All that changed was a single domain name.</p>
<h2>Controlling the cache</h2>
<p><em>Amazon CloudFront</em> will keep the contents in cache based on the origin headers if present or the manual configuration
from the AWS Console. To work around frequent requests to the origin server it is considered best practice to set the
Expires header to a value far in the future, like 1 year.
However if the content changes you need some way to tell <em>CloudFront</em> about it. The most commonly used method is through
using different URLs to access the same content. This will cause <em>CloudFront</em> to cache the content under the new location
while keeping the old content until it expires.</p>
<p><em>Dojo</em> makes this very easy:</p>
<div class="codehilite"><pre><span class="nx">require</span><span class="p">([</span><span class="s2">&quot;dojo/io/script&quot;</span><span class="p">],</span>
    <span class="kd">function</span><span class="p">(</span><span class="nx">script</span><span class="p">)</span> <span class="p">{</span>
            <span class="nx">script</span><span class="p">.</span><span class="nx">get</span><span class="p">({</span>
                <span class="nx">url</span><span class="o">:</span> <span class="s2">&quot;https://xyz.cloudfront.net/api/json/updates/1234&quot;</span><span class="p">,</span>
                <span class="nx">callbackParamName</span><span class="o">:</span> <span class="s2">&quot;callback&quot;</span><span class="p">,</span>
                <span class="nx">content</span><span class="o">:</span> <span class="p">{</span><span class="nx">t</span><span class="o">:</span> <span class="nx">timeStamp</span><span class="p">},</span>
                <span class="nx">load</span><span class="o">:</span> <span class="kd">function</span><span class="p">(</span><span class="nx">jsonData</span><span class="p">)</span> <span class="p">{</span>
                    <span class="p">....</span>
                <span class="p">},</span>
</pre></div>


<p>The <em>content</em> property allows additional key/value pairs to be sent in the query string. The
<em>timeStamp</em> parameter serves only to control <em>Amazon CloudFront</em> cache. It's not processed server side.</p>
<p>On the server-side we have:</p>
<div class="codehilite"><pre><span class="n">response</span><span class="p">[</span><span class="s">&#39;Cache-Control&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s">&#39;max-age=31536000&#39;</span>
<span class="n">response</span><span class="p">[</span><span class="s">&#39;Expires&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">+</span><span class="n">timedelta</span><span class="p">(</span><span class="n">seconds</span><span class="o">=</span><span class="mi">31536000</span><span class="p">))</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s">&#39;%a, </span><span class="si">%d</span><span class="s"> %b %Y %H:%M:%S GMT&#39;</span><span class="p">)</span>
</pre></div>


<h2>Benefits</h2>
<p>There were two immediate benefits:</p>
<ul>
<li>Reduced page load time. Combined with serving static files from CDN this greatly improves the user experience;</li>
<li>Reduced server load. Content is requested only once if it is missing from the cache and then served from CloudFront.
The server isn't so busy serving content so it can be used to do more computations or simply reduce the bill.</li>
</ul>
<p>The presented method works well for <em>Difio</em> because of two things:</p>
<ul>
<li>The content which <em>Difio</em> serves usually doesn't change at all once made public. In rare occasions, for example an error
has been published, we have to regenerate new content and publish it under the same URL.</li>
<li>Before content is made public it is inspected for errors and this also preseeds the cache.</li>
</ul>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Sat 19 May 2012
<p>There are <a href="http://atodorov.org/blog/2012/05/19/cross-domain-ajax-served-from-cdn/#disqus_thread">comments</a>.</p>            </p>
        </div>
        <hr>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2012/04/17/using-openshift-as-amazon-cloudfront-origin-server/" rel="bookmark" title="Permalink to Using OpenShift as Amazon CloudFront Origin Server">
                <h2 class="post-title">
                    Using OpenShift as Amazon CloudFront Origin Server
                </h2>
            </a>
            <p>It's been several months after the start of <a href="http://www.dif.io"><em>Difio</em></a> and I started
migrating various parts of the platform to CDN. The first to go are static files like
CSS, JavaScript, images and such. In this article I will show you how to get started with 
<em>Amazon CloudFront</em> and <em>OpenShift</em>. It is very easy once you understand how it works.</p>
<h2>Why CloudFront and OpenShift</h2>
<p><em>Amazon CloudFront</em> is cheap and easy to setup with virtually no maintenance.
The most important feature is that it can fetch content from any public website.
Integrating it together with <em>OpenShift</em> gives some nice benefits:</p>
<ul>
<li>All static assets are managed with Git and stored in the same place where the application
code and HTML is - easy to develop and deploy;</li>
<li>No need for external service to host the static files;</li>
<li><em>CloudFront</em> will be serving the files so network load on <em>OpenShift</em> is minimal;</li>
<li>Easy to manage versioned URLs because HTML and static assets are in the same repo - more on this later;</li>
</ul>
<h2>Object expiration</h2>
<p><em>CloudFront</em> will cache your objects for a certain period and then expire them. Frequently
used objects are expired less often. Depending on the content you may want to update the cache
more or less frequently. In my case CSS and JavaScript files change rarely so I wanted to tell
CloudFront to not expire the files quickly. I did this by telling <em>Apache</em> to send a custom value for
the Expires header.</p>
<div class="codehilite"><pre>    $ curl http://d71ktrt2emu2j.cloudfront.net/static/v1/css/style.css -D headers.txt
    $ cat headers.txt 
    HTTP/1.0 200 OK
    Date: Mon, 16 Apr 2012 19:02:16 GMT
    Server: Apache/2.2.15 (Red Hat)
    Last-Modified: Mon, 16 Apr 2012 19:00:33 GMT
    ETag: &quot;120577-1b2d-4bdd06fc6f640&quot;
    Accept-Ranges: bytes
    Content-Length: 6957
    Cache-Control: max-age=31536000
    Expires: Tue, 16 Apr 2013 19:02:16 GMT
    Content-Type: text/css
    Strict-Transport-Security: max-age=15768000, includeSubDomains
    Age: 73090
    X-Cache: Hit from cloudfront
    X-Amz-Cf-Id: X558vcEOsQkVQn5V9fbrWNTdo543v8VStxdb7LXIcUWAIbLKuIvp-w==,e8Dipk5FSNej3e0Y7c5ro-9mmn7OK8kWfbaRGwi1ww8ihwVzSab24A==
    Via: 1.0 d6343f267c91f2f0e78ef0a7d0b7921d.cloudfront.net (CloudFront)
    Connection: close
</pre></div>


<p>All headers before Strict-Transport-Security come from the origin server.</p>
<h2>Versioning</h2>
<p>Sometimes however you need to update the files and force <em>CloudFront</em> to update the content. 
The recommended way to do this is to use URL versioning and update the path to the files
which changed. This will force <em>CloudFront</em> to cache and serve the content under the new path
while keeping the old content available until it expires. This way your visitors will not be
viewing your site with the new CSS and old JavaScript. </p>
<p>There are many ways to do this and there are some nice frameworks as well. For Python there is <em>webassets</em>.
I don't have many static files so I opted for no additional dependencies. Instead I will be updating the
versions by hand.</p>
<p>What comes to mind is using <em>mod_rewrite</em> to redirect the versioned URLs back to non versioned ones.
However there's a catch. If you do this <em>CloudFront</em> will cache the redirect itself, not the content.
The next time visitors hit <em>CloudFront</em> they will receive the cached redirect and follow it back to your
origin server, which is defeating the purpose of having CDN.</p>
<p>To do it properly you have to rewrite the URLs but still return a 200 response code and the
content which needs to be cached. This is done with <em>mod_proxy</em>: </p>
<div class="codehilite"><pre>    RewriteEngine on
    RewriteRule ^VERSION-(\d+)/(.*)$ http://%{ENV:OPENSHIFT_INTERNAL_IP}:%{ENV:OPENSHIFT_INTERNAL_PORT}/static/$2 [P,L]
</pre></div>


<p>This .htaccess trick doesn't work on <em>OpenShift</em> though. <em>mod_proxy</em> is not enabled at the moment.
See <a href="https://bugzilla.redhat.com/show_bug.cgi?id=812389">bug 812389</a> for more info.</p>
<p>Luckily I was able to use symlinks to point to the content. Here's how it looks:</p>
<div class="codehilite"><pre><span class="x">    $ pwd</span>
<span class="x">    /home/atodorov/difio/wsgi/static</span>
<span class="x">    </span>
<span class="x">    $ cat .htaccess</span>
<span class="x">    ExpiresActive On</span>
<span class="x">    ExpiresDefault &quot;access plus 1 year&quot;</span>
<span class="x">    </span>
<span class="x">    $ ls -l</span>
<span class="x">    drwxrwxr-x. 6 atodorov atodorov 4096 16 Apr 21,31 o</span>
<span class="x">    lrwxrwxrwx. 1 atodorov atodorov    1 16 Apr 21,47 v1 -&gt; o</span>
<span class="x">    </span>
<span class="x">    settings.py:</span>
<span class="x">    STATIC_URL = &#39;//d71ktrt2emu2j.cloudfront.net/static/v1/&#39;</span>
<span class="x">    </span>
<span class="x">    HTML template:</span>
<span class="x">    &lt;link type=&quot;text/css&quot; rel=&quot;stylesheet&quot; media=&quot;screen&quot; href=&quot;</span><span class="cp">{{</span> <span class="nv">STATIC_URL</span> <span class="cp">}}</span><span class="x">css/style.css&quot; /&gt;</span>
</pre></div>


<h2>How to implement it</h2>
<p>First you need to split all CSS and JavaScript from your HTML if you haven't done so already. </p>
<p>Then place everything under your git repo so that <em>OpenShift</em> will serve the files. For Python applications
place the files under wsgi/static/ directory in your git repo.</p>
<p>Point all of your HTML templates to the static location on <em>OpenShift</em> and test if everything works as expected. 
This is best done if you're using some sort of template language and store the location
in a single variable which you can change later.
<em>Difio</em> uses <em>Django</em> and the <em>STATIC_URL</em> variable of course.</p>
<p>Create your <em>CloudFront</em> distribution - don't use <em>Amazon S3</em>, instead configure a custom origin server. Write down
your <em>CloudFront</em> URL. It will be something like <strong>1234xyz.cludfront.net</strong>.</p>
<p>Every time a request hits <em>CloudFront</em> it will check if the object is present in the cache. If not present
<em>CloudFront</em> will fetch the object from the origin server and populate the cache. Then the object is sent
to the user.</p>
<p>Update your templates to point to the new cloudfront.net URL and redeploy your website!</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Tue 17 April 2012
<p>There are <a href="http://atodorov.org/blog/2012/04/17/using-openshift-as-amazon-cloudfront-origin-server/#disqus_thread">comments</a>.</p>            </p>
        </div>
        <hr>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2012/03/14/openshift-cron-takes-over-celerybeat/" rel="bookmark" title="Permalink to OpenShift Cron Takes Over Celerybeat">
                <h2 class="post-title">
                    OpenShift Cron Takes Over Celerybeat
                </h2>
            </a>
            <p><a href="http://celeryproject.org/"><em>Celery</em></a> is an asynchronous task queue/job queue
based on distributed message passing. You can define tasks as Python functions,
execute them in the background and in a periodic fashion.
<a href="http://www.dif.io"><em>Difio</em></a> uses <em>Celery</em> for virtually everything.
Some of the tasks are scheduled after some event takes place (like user pressed a button)
or scheduled periodically.</p>
<p><em>Celery</em> provides several components of which <em>celerybeat</em> is the periodic task scheduler.
When combined with <a href="http://djangoproject.com"><em>Django</em></a> it gives you a very nice admin interface
which allows periodic tasks to be added to the scheduler.</p>
<h2>Why change</h2>
<p><em>Difio</em> has relied on <em>celerybeat</em> for a couple of months. Back then, when <em>Difio</em> launched,
there was no cron support for OpenShift so running <em>celerybeat</em> sounded reasonable.
It used to run on a dedicated virtual server and for most of the time that was fine. </p>
<p>There were a number of issues which <em>Difio</em> faced during its first months:</p>
<ul>
<li>
<p><em>celerybeat</em> would sometime die due to no free memory on the virtual instance.
When that happened no new tasks were scheduled and data was left unprocessed.
Let alone that higher memory instance and the processing power which comes with it
cost extra money.</p>
</li>
<li>
<p><em>Difio</em> is split into several components which need to have the same code base
locally - the most important are database settings and the periodic tasks
code. At least in one occasion <em>celerybeat</em> failed to start because of a buggy 
task code. The offending code was fixed in the application server on OpenShift but
not properly synced to the <em>celerybeat</em> instance. Keeping code in sync is a priority
for distributed projects which rely on <em>Celery</em>.</p>
</li>
<li>
<p><em>Celery</em> and <em>django-celery</em> seem to be updated quite often. This poses a significant risk
of ending up with different versions on the scheduler, worker nodes and the app server. This will
bring the whole application to a halt if at some point a backward incompatible change is introduced
and not properly tested and updated. Keeping infrastructure components in sync can be a big challenge
and I try to minimize this effort as much as possible.</p>
</li>
<li>
<p>Having to navigate to the admin pages every time I add a new task or want to change the execution
frequency doesn't feel very natural for a console user like myself and IMHO is less productive.
For the record I primarily use <em>mcedit</em>. I wanted to have something more close to the
write, commit and push work-flow.</p>
</li>
</ul>
<h2>The take over</h2>
<p>It's been some time since OpenShift
<a href="https://www.redhat.com/openshift/community/blogs/getting-started-with-cron-jobs-on-openshift">introduced</a>
the cron cartridge and I decided to give it a try.</p>
<p>The first thing I did is to write a simple script which can execute any task from the difio.tasks module
by piping it to the Django shell (a Python shell actually).</p>
<div class="codehilite"><span class="filename">run_celery_task</span><pre><span class="c">#!/bin/bash</span>
<span class="c">#</span>
<span class="c"># Copyright (c) 2012, Alexander Todorov &lt;atodorov@nospam.otb.bg&gt;</span>
<span class="c">#</span>
<span class="c"># This script is symlinked to from the hourly/minutely, etc. directories</span>
<span class="c">#</span>
<span class="c"># SYNOPSIS</span>
<span class="c">#</span>
<span class="c"># ./run_celery_task cron_search_dates</span>
<span class="c">#</span>
<span class="c"># OR</span>
<span class="c">#</span>
<span class="c"># ln -s run_celery_task cron_search_dates</span>
<span class="c"># ./cron_search_dates</span>
<span class="c">#</span>

<span class="nv">TASK_NAME</span><span class="o">=</span><span class="nv">$1</span>
<span class="o">[</span> -z <span class="s2">&quot;</span><span class="nv">$TASK_NAME</span><span class="s2">&quot;</span> <span class="o">]</span> <span class="o">&amp;&amp;</span> <span class="nv">TASK_NAME</span><span class="o">=</span><span class="k">$(</span>basename <span class="nv">$0</span><span class="k">)</span>

<span class="k">if</span> <span class="o">[</span> -n <span class="s2">&quot;</span><span class="nv">$OPENSHIFT_APP_DIR</span><span class="s2">&quot;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
    <span class="nb">source</span> <span class="nv">$OPENSHIFT_APP_DIR</span>/virtenv/bin/activate
    <span class="nb">export </span><span class="nv">PYTHON_EGG_CACHE</span><span class="o">=</span><span class="nv">$OPENSHIFT_DATA_DIR</span>/.python-eggs
    <span class="nv">REPO_DIR</span><span class="o">=</span><span class="nv">$OPENSHIFT_REPO_DIR</span>
<span class="k">else</span>
    <span class="nv">REPO_DIR</span><span class="o">=</span><span class="k">$(</span>dirname <span class="nv">$0</span><span class="k">)</span><span class="s2">&quot;/../../..&quot;</span>
<span class="k">fi</span>

<span class="nb">echo</span> <span class="s2">&quot;import difio.tasks; difio.tasks.</span><span class="nv">$TASK_NAME</span><span class="s2">.delay()&quot;</span> <span class="p">|</span> <span class="nv">$REPO_DIR</span>/wsgi/difio/manage.py shell
</pre></div>


<p>This is a multicall script which allows symlinks with different names to point to it. 
Thus to add a new task to cron I just need to make a symlink to the script from one of the
hourly/, minutely/, daily/, etc. directories under cron/.</p>
<p>The script accepts a parameter as well which allows me to execute it locally for debugging purposes
or to schedule some tasks out of band.
This is how it looks like on the file system:</p>
<div class="codehilite"><pre><span class="nv">$ </span>ls -l .openshift/cron/hourly/
some_task_name -&gt; ../tasks/run_celery_task
another_task -&gt; ../tasks/run_celery_task
</pre></div>


<p>After having done these preparations I only had to embed the cron cartridge and git push to OpenShift:</p>
<div class="codehilite"><pre>rhc-ctl-app -a difio -e add-cron-1.4 &amp;&amp; git push
</pre></div>


<h2>What's next</h2>
<p>At present OpenShift can schedule your jobs every minute, hour, day, week or month and does so using the
<em>run-parts</em> script. You can't schedule a script to execute at 4:30 every Monday or every 45 minutes for example.
See <a href="https://bugzilla.redhat.com/show_bug.cgi?id=803485">rhbz #803485</a> if you want to follow the
progress. Luckily <em>Difio</em> doesn't use this sort of job scheduling for the moment.</p>
<p><em>Difio</em> is scheduling periodic tasks from OpenShift cron for a few days already. 
It seems to work reliably and with no issues. One less component to maintain and worry about.
More time to write code.</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Wed 14 March 2012
<p>There are <a href="http://atodorov.org/blog/2012/03/14/openshift-cron-takes-over-celerybeat/#disqus_thread">comments</a>.</p>            </p>
        </div>
        <hr>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2012/03/09/how-to-get-to-the-openshift-shell/" rel="bookmark" title="Permalink to Tip: How to Get to the OpenShift Shell">
                <h2 class="post-title">
                    Tip: How to Get to the OpenShift Shell
                </h2>
            </a>
            <p>I wanted to examine the Perl environment on OpenShift and got tired of making snapshots,
unzipping the archive and poking through the files. I wanted a shell. Here's how to get one.</p>
<ol>
<li>
<p>Get the application info first</p>
<div class="codehilite"><pre><span class="nv">$ </span>rhc-domain-info 
Password: 
Application <span class="nv">Info</span>
<span class="o">================</span>
myapp
    Framework: perl-5.10
     Creation: 2012-03-08T13:34:46-04:00
         UUID: 8946b976ad284cf5b2401caf736186bd
      Git URL: ssh://8946b976ad284cf5b2401caf736186bd@myapp-mydomain.rhcloud.com/~/git/myapp.git/
   Public URL: http://myapp-mydomain.rhcloud.com/

 Embedded: 
      None
</pre></div>


</li>
<li>
<p>The Git URL has your username and host</p>
</li>
<li>
<p>Now just ssh into the application</p>
<div class="codehilite"><pre><span class="nv">$ </span>ssh 8946b976ad284cf5b2401caf736186bd@myapp-mydomain.rhcloud.com

    Welcome to OpenShift shell

    This shell will assist you in managing OpenShift applications.

    !!! IMPORTANT !!! IMPORTANT !!! IMPORTANT !!!
    Shell access is quite powerful and it is possible <span class="k">for</span> you to
    accidentally damage your application.  Proceed with care!
    If worse comes to worst, destroy your application with <span class="s1">&#39;rhc app destroy&#39;</span>
    and recreate it
    !!! IMPORTANT !!! IMPORTANT !!! IMPORTANT !!!

    Type <span class="s2">&quot;help&quot;</span> <span class="k">for</span> more info.

<span class="o">[</span>myapp-mydomain.rhcloud.com ~<span class="o">]</span><span class="se">\&gt;</span>
</pre></div>


</li>
</ol>
<p><strong>Voila!</strong></p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Fri 09 March 2012
<p>There are <a href="http://atodorov.org/blog/2012/03/09/how-to-get-to-the-openshift-shell/#disqus_thread">comments</a>.</p>            </p>
        </div>
        <hr>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2012/02/18/how-to-update-dependencies-on-openshift/" rel="bookmark" title="Permalink to How to Update Dependencies on OpenShift">
                <h2 class="post-title">
                    How to Update Dependencies on OpenShift
                </h2>
            </a>
            <p>If you are already running some cool application on <a href="http://openshift.redhat.com">OpenShift</a>
it could be the case that you have to update some of the packages installed as dependencies.
Here is an example for an application using the python-2.6 cartridge.</p>
<h2>Pull latest upstream packages</h2>
<p>The most simple method is to update everything to the latest upstream versions. </p>
<ol>
<li>
<p>Backup! Backup! Backup!</p>
<div class="codehilite"><pre>rhc-snapshot -a mycoolapp
mv mycoolapp.tar.gz mycoolapp-backup-before-update.tar.gz
</pre></div>


</li>
<li>
<p>If you haven't specified any particular version in <code>setup.py</code> it will
look like this:</p>
<div class="codehilite"><pre><span class="o">...</span>
<span class="n">install_requires</span><span class="o">=</span><span class="p">[</span>
                <span class="s">&#39;difio-openshift-python&#39;</span><span class="p">,</span>
                <span class="s">&#39;MySQL-python&#39;</span><span class="p">,</span>
                <span class="s">&#39;Markdown&#39;</span><span class="p">,</span>
               <span class="p">],</span>
<span class="o">...</span>
</pre></div>


</li>
<li>
<p>To update simply push to OpenShift instructing it to rebuild your virtualenv:</p>
<div class="codehilite"><pre>cd mycoolapp/
touch .openshift/markers/force_clean_build
git add .openshift/markers/force_clean_build
git commit -m &quot;update to latest upstream&quot;
git push
</pre></div>


</li>
</ol>
<p>Voila! The environment hosting your application is rebuilt from scratch.</p>
<h2>Keeping some packages unchanged</h2>
<p>Suppose that before the update you have <code>Markdown-2.0.1</code> and you want to keep it!
This is easily solved by adding versioned dependency to <code>setup.py</code></p>
<div class="codehilite"><pre><span class="gd">-       &#39;Markdown&#39;,</span>
<span class="gi">+       &#39;Markdown==2.0.1&#39;,</span>
</pre></div>


<p>If you do that OpenShift will install the same <code>Markdown</code> version when rebuilding your
application. Everything else will use the latest available versions.</p>
<p><strong>Note:</strong> after the update it's recommended that you remove the 
<code>.openshift/markers/force_clean_build</code> file. This will speed up the push/build process
and will not surprise you with unwanted changes.</p>
<h2>Update only selected packages</h2>
<p>Unless your application is really simple or you have tested the updates, I suspect that
you want to update only selected packages. This can be done without rebuilding the whole
virtualenv. Use versioned dependencies in <code>setup.py</code> :</p>
<div class="codehilite"><pre><span class="gd">-       &#39;Markdown==2.0.1&#39;,</span>
<span class="gd">-       &#39;django-countries&#39;,</span>
<span class="gi">+       &#39;Markdown&gt;=2.1&#39;,</span>
<span class="gi">+       &#39;django-countries&gt;=1.1.2&#39;,</span>
</pre></div>


<p>No need for <code>force_clean_build</code> this time. Just</p>
<div class="codehilite"><pre>    git commit &amp;&amp; git push
</pre></div>


<p>At the time of writing my application was using <code>Markdown-2.0.1</code> and <code>django-countries-1.0.5</code>.
Then it updated to <code>Markdown-2.1.1</code> and <code>django-countires-1.1.2</code> which also happened to be
the latest versions.</p>
<p><strong>Note:</strong> this will not work without <code>force_clean_build</code></p>
<div class="codehilite"><pre><span class="gd">-       &#39;django-countries==1.0.5&#39;,</span>
<span class="gi">+       &#39;django-countries&#39;,</span>
</pre></div>


<h2>Warning</h2>
<p>OpenShift uses a local mirror of <a href="http://pypi.python.org">Python Package Index</a>.
It seems to be updated every 24 hours or so. Have this in mind if you want to update
to a package that was just released. It will not work! See
<a href="/blog/2013/04/24/how-to-deploy-python-hotfix-on-redhat-openshift-cloud/">How to Deploy Python Hotfix on OpenShift</a>
if you wish to work around this limitation.</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Sat 18 February 2012
<p>There are <a href="http://atodorov.org/blog/2012/02/18/how-to-update-dependencies-on-openshift/#disqus_thread">comments</a>.</p>            </p>
        </div>
        <hr>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2012/02/10/spinning-up-a-development-instance-on-openshift/" rel="bookmark" title="Permalink to Spinning-up a Development Instance on OpenShift">
                <h2 class="post-title">
                    Spinning-up a Development Instance on OpenShift
                </h2>
            </a>
            <p><a href="http://www.dif.io">Difio</a> is hosted on <a href="http://openshift.redhat.com">OpenShift</a>.
During development I often need to spin-up another copy of Difio to use for testing and development.
With OpenShift this is easy and fast. Here's how:</p>
<ol>
<li>
<p>Create another application on OpenShift. This will be your development instance.</p>
<div class="codehilite"><pre>rhc-create-app -a myappdevel -t python-2.6
</pre></div>


</li>
<li>
<p>Find out the git URL for the production application:</p>
<div class="codehilite"><pre><span class="nv">$ </span>rhc-user-info
Application <span class="nv">Info</span>
<span class="o">================</span>
myapp
    Framework: python-2.6
     Creation: 2012-02-10T12:39:53-05:00
         UUID: 723f0331e17041e8b34228f87a6cf1f5
      Git URL: ssh://723f0331e17041e8b34228f87a6cf1f5@myapp-mydomain.rhcloud.com/~/git/myapp.git/
   Public URL: http://myapp-mydomain.rhcloud.com/
</pre></div>


</li>
<li>
<p>Push the current code base from the production instance to devel instance:</p>
<div class="codehilite"><pre>cd myappdevel
git remote add production -m master ssh://723f0331e17041e8b34228f87a6cf1f5@myapp-mydomain.rhcloud.com/~/git/myapp.git/
git pull -s recursive -X theirs production master
git push
</pre></div>


</li>
<li>
<p>Now your <code>myappdevel</code> is the same as your production instance. You will probably want to
modify your database connection settings at this point and start adding new features.</p>
</li>
</ol>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Fri 10 February 2012
<p>There are <a href="http://atodorov.org/blog/2012/02/10/spinning-up-a-development-instance-on-openshift/#disqus_thread">comments</a>.</p>            </p>
        </div>
        <hr>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2011/09/15/protected-rpm-repositories-with-yum-and-ssl/" rel="bookmark" title="Permalink to Protected RPM repositories with yum and SSL">
                <h2 class="post-title">
                    Protected RPM repositories with yum and SSL
                </h2>
            </a>
            <p>In this article I'm going to describe a simple way to set-up RPM repositories with access control using only standard tools such as yum, SSL and Apache.
I've been talking about this at one of the monthly conferences of Linux for Bulgarians!</p>
<p><strong>Objective:</strong><br />
Create RPM repository with access control. Access is allowed only for some systems and forbidden for the rest. This is a similar to what Red Hat Network does. </p>
<p><strong>Solution:</strong><br />
We're going to use yum and Apache capabilities to work with SSL certificates. The client side (yum) will identify itself using SSL certificate and the server (Apache) will use this information to control the access.</p>
<p><strong>Client side set-up:</strong><br />
<ol>
  <li>
Yum version 3.2.27 or newer supports SSL certificates for client authentication. This version is available in Red Hat Enterprise Linux 6. 
  </li></p>
<p><li>
First you need to generate a private key and certificate using OpenSSL:</p>
<div class="codehilite"><pre><span class="cp"># openssl genrsa -out /var/lib/yum/client.key 1024</span>
<span class="n">Generating</span> <span class="n">RSA</span> <span class="n">private</span> <span class="n">key</span><span class="p">,</span> <span class="mi">1024</span> <span class="n">bit</span> <span class="kt">long</span> <span class="n">modulus</span>
<span class="p">....</span><span class="o">++++++</span>
<span class="p">.......</span><span class="o">++++++</span>
<span class="n">e</span> <span class="n">is</span> <span class="mi">65537</span> <span class="p">(</span><span class="mh">0x10001</span><span class="p">)</span>

<span class="cp"># openssl req -new -x509 -text -key /var/lib/yum/client.key -out /var/lib/yum/client.cert</span>
<span class="n">You</span> <span class="n">are</span> <span class="n">about</span> <span class="n">to</span> <span class="n">be</span> <span class="n">asked</span> <span class="n">to</span> <span class="n">enter</span> <span class="n">information</span> <span class="n">that</span> <span class="n">will</span> <span class="n">be</span> <span class="n">incorporated</span>
<span class="n">into</span> <span class="n">your</span> <span class="n">certificate</span> <span class="n">request</span><span class="p">.</span>
<span class="n">What</span> <span class="n">you</span> <span class="n">are</span> <span class="n">about</span> <span class="n">to</span> <span class="n">enter</span> <span class="n">is</span> <span class="n">what</span> <span class="n">is</span> <span class="n">called</span> <span class="n">a</span> <span class="n">Distinguished</span> <span class="n">Name</span> <span class="n">or</span> <span class="n">a</span> <span class="n">DN</span><span class="p">.</span>
<span class="n">There</span> <span class="n">are</span> <span class="n">quite</span> <span class="n">a</span> <span class="n">few</span> <span class="n">fields</span> <span class="n">but</span> <span class="n">you</span> <span class="n">can</span> <span class="n">leave</span> <span class="n">some</span> <span class="n">blank</span>
<span class="n">For</span> <span class="n">some</span> <span class="n">fields</span> <span class="n">there</span> <span class="n">will</span> <span class="n">be</span> <span class="n">a</span> <span class="k">default</span> <span class="n">value</span><span class="p">,</span>
<span class="n">If</span> <span class="n">you</span> <span class="n">enter</span> <span class="sc">&#39;.&#39;</span><span class="p">,</span> <span class="n">the</span> <span class="n">field</span> <span class="n">will</span> <span class="n">be</span> <span class="n">left</span> <span class="n">blank</span><span class="p">.</span>
<span class="o">-----</span>
<span class="n">Country</span> <span class="n">Name</span> <span class="p">(</span><span class="mi">2</span> <span class="n">letter</span> <span class="n">code</span><span class="p">)</span> <span class="p">[</span><span class="n">XX</span><span class="p">]</span><span class="o">:</span><span class="n">BG</span>
<span class="n">State</span> <span class="n">or</span> <span class="n">Province</span> <span class="n">Name</span> <span class="p">(</span><span class="n">full</span> <span class="n">name</span><span class="p">)</span> <span class="p">[]</span><span class="o">:</span><span class="n">Sofia</span>
<span class="n">Locality</span> <span class="n">Name</span> <span class="p">(</span><span class="n">eg</span><span class="p">,</span> <span class="n">city</span><span class="p">)</span> <span class="p">[</span><span class="n">Default</span> <span class="n">City</span><span class="p">]</span><span class="o">:</span><span class="n">Sofia</span>
<span class="n">Organization</span> <span class="n">Name</span> <span class="p">(</span><span class="n">eg</span><span class="p">,</span> <span class="n">company</span><span class="p">)</span> <span class="p">[</span><span class="n">Default</span> <span class="n">Company</span> <span class="n">Ltd</span><span class="p">]</span><span class="o">:</span><span class="n">Open</span> <span class="n">Technologies</span> <span class="n">Bulgaria</span>
<span class="n">Organizational</span> <span class="n">Unit</span> <span class="n">Name</span> <span class="p">(</span><span class="n">eg</span><span class="p">,</span> <span class="n">section</span><span class="p">)</span> <span class="p">[]</span><span class="o">:</span><span class="n">IT</span>
<span class="n">Common</span> <span class="n">Name</span> <span class="p">(</span><span class="n">eg</span><span class="p">,</span> <span class="n">your</span> <span class="n">name</span> <span class="n">or</span> <span class="n">your</span> <span class="n">server</span><span class="err">&#39;</span><span class="n">s</span> <span class="n">hostname</span><span class="p">)</span> <span class="p">[]</span><span class="o">:</span>
<span class="n">Email</span> <span class="n">Address</span> <span class="p">[]</span><span class="o">:</span><span class="n">no</span><span class="o">-</span><span class="n">spam</span><span class="p">@</span><span class="n">otb</span><span class="p">.</span><span class="n">bg</span>
</pre></div>


</li>

<p><li>
For better security you can change file permissions of <em>client.key</em>:</p>
<div class="codehilite"><pre># chmod 600 /var/lib/yum/client.key
</pre></div>


</li>

<p><li>
You need to define the protected repository in a .repo file. It needs to look something like this:</p>
<div class="codehilite"><pre># cat /etc/yum.repos.d/protected.repo
[protected]
name=SSL protected repository
baseurl=https://repos.example.com/protected
enabled=1
gpgcheck=1
gpgkey=https://repos.example.com/RPM-GPG-KEY

sslverify=1
sslclientcert=/var/lib/yum/client.cert
sslclientkey=/var/lib/yum/client.key
</pre></div>


</li>

<p><li>
If you use self-signed server certificate you can specify  <em>sslverify=0</em>, but this is not recommended.
  </li>
</ol></p>
<p>Whenever yum tries to reach the URL of the repository it will identify itself using the specified certificate.</p>
<p><strong>Server side set-up:</strong><br />
<ol>
  <li>
Install and configure the <em>mod_ssl</em> module for Apache.
  </li></p>
<p><li>
Create a directory for the repository which will be available over HTTPS.
  </li></p>
<p><li>
In the repository directory add <em>.htaccess</em>, which looks something like this:</p>
<div class="codehilite"><pre>Action rpm-protected /cgi-bin/rpm.cgi
AddHandler rpm-protected .rpm .drpm
SSLVerifyClient optional_no_ca
</pre></div>


</li>

<p><li>
The <em>Action</em> and <em>AddHandler</em> directives instruct Apache to run the <em>rpm.cgi</em> CGI script every time someone tries to access files with extension .rpm and .drpm.
  </li></p>
<p><li>
The <em>SSLVerifyClient</em> directive tells Apache that the http client may present a valid certificate but it has not to be (successfully) verifyable.
For more information on this configuration please see
<a href="http://www.modssl.org/docs/2.1/ssl_reference.html#ToC13">http://www.modssl.org/docs/2.1/ssl_reference.html#ToC13</a>.
  </li></p>
<p><li>
The simplest form of <em>rpm.cgi</em> script may look like this:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12</pre></div></td><td class="code"><div class="codehilite"><pre><span class="c">#!/bin/bash</span>

<span class="k">if</span> <span class="o">[</span> <span class="s2">&quot;</span><span class="nv">$SSL_CLIENT_M_SERIAL</span><span class="s2">&quot;</span> <span class="o">==</span> <span class="s2">&quot;9F938211B53B4F44&quot;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
    <span class="nb">echo</span> <span class="s2">&quot;Content-type: application/x-rpm&quot;</span>
    <span class="nb">echo</span> <span class="s2">&quot;Content-length: </span><span class="k">$(</span>stat --printf<span class="o">=</span><span class="s1">&#39;%s&#39;</span> <span class="nv">$PATH_TRANSLATED</span><span class="k">)</span><span class="s2">&quot;</span>
    <span class="nb">echo</span>

<span class="nb">    </span>cat <span class="nv">$PATH_TRANSLATED</span>
<span class="k">else</span>
    <span class="nb">echo</span> <span class="s2">&quot;Status: 403&quot;</span>
    <span class="nb">echo</span>
<span class="k">fi</span>
</pre></div>
</td></tr></table>

</li>

<p><li>
The script will allow access to a client which uses a certificate with serial number <em>9F938211B53B4F44</em>. Other clients will be denied access and the server will return standard 403 error code.
  </li>
</ol></p>
<p><strong>In practice:</strong><br />
The above set-up is very basic and only demonstrates the technology behind this. In a real world configuration you will need some more tools to make this really usable. </p>
<p>My company <a href="http://otb.bg">Open Technologies Bulgaria, Ltd.</a> has developed a custom solution for our customers based on the above example called Voyager. It features a Drupal module, a CGI script and a client side yum plugin. </p>
<p>The Drupal module acts as web interface to the system and allows some basic tasks. Administrators can define software channels and subscription expiration. Customers can register and entitle their systems to particular channels. The functionality is similar to Red Hat Network but without all the extra features which we don't need.</p>
<p>The CGI script acts as a glue between the client side and the Drupal backend. It will read information about client credentials and act as first line of defence against non-authorized access. Then it will communicate with the Drupal database and get more information about this customer. If everything is OK then access will be allowed. </p>
<p>The yum plugin has the task to communicate with the Drupal backend and dynamically update repository definitions based on available subscriptions. Then it will send a request for the RPM file back to the Apache server where the CGI script will handle it.</p>
<p>The client side also features a tool to generate the client certificate and register the system to the server. </p>
<p>All communications are entirely over HTTPS. </p>
<p>This custom solution has the advantage that it is simple and easy to maintain as well as easy to use. It integrates well with other plugins (e.g. yum-presto for delta rpm support and yum-rhnplugin) and can be used via yum or PackageKit which are the standard package management tools on Red Hat Enterprise Linux 6.</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Thu 15 September 2011
<p>There are <a href="http://atodorov.org/blog/2011/09/15/protected-rpm-repositories-with-yum-and-ssl/#disqus_thread">comments</a>.</p>            </p>
        </div>
        <hr>
        <div class="post-preview">
            <a href="http://atodorov.org/blog/2011/03/14/usb-multi-seat-on-red-hat-enterprise-linux-6/" rel="bookmark" title="Permalink to USB multi-seat on Red Hat Enterprise Linux 6">
                <h2 class="post-title">
                    USB multi-seat on Red Hat Enterprise Linux 6
                </h2>
            </a>
            <p>Multiseat configurations are well known in the Linux community and have been used for a number of years now. In the last few years USB docking stations emerged on the market and are becoming popular among multiseat enthusiasts. </p>
<p>My company <a href="http://otb.bg">Open Technologies Bulgaria, Ltd.</a> offers full support of USB multiseat for Red Hat Enterprise Linux 6 as a downstream vendor. We use the name SUMU (simple usb multi user) to refer to the entire multiseat bundle and in this article I'm going to describe the current state of technologies surrounding multiseat, how that works on RHEL 6 and some practical observations.</p>
<h2>COMPONENTS</h2>
<p>To build a multiseat system you need a number of individual components:</p>
<p><img src="/images/plugable_docking_station.png" alt="UD-160-A" style="float: right;"/></p>
<ul>
  <li>
    USB docking station like Plugable's <a href="http://plugable.com/products/UD-160-A">UD-160-A</a> or a combination of <a href="http://plugable.com/products/">USB video card</a> and stand alone USB hub. It is also possible to use USB docking stations from other vendors but I'm not aware of anyone who did it.
  </li>

  <li>
<em>udlfb</em> - a kernel driver for USB graphics adapters which use DisplayLink based chips. As of January 2011 udlfb.c is part of the mainline kernel tree and is on track for 2.6.38. On RHEL6 this can easily be built as a stand alone module. There are no issues with this package.

We also use a custom patch that will draw the string "fbX" onto the green screen. This is useful for easier identification of the display. The patch can be found <a href="http://otb-sources.googlecode.com/svn/trunk/sumu/udlfb-kmod/fbX-numbering.patch">here</a>.
  </li>

  <li>
<em>Xorg</em> - this is the standard graphics server on Linux. In RHEL 6 we have xorg-x11-server-Xorg-1.7.7-26 which works perfectly in a multiseat environment.
  </li>

  <li>
<em>xorg-x11-drv-fbdev</em> with extensions - Xorg driver based on the <em>fbdev</em> driver. The extensions add support for the X DAMAGE protocol. This is a temporary solution until Xorg adds support for the damage protocol. Our package is called <em>xorg-x11-drv-fbdev-displaylink</em> to avoid conflict with the stock package provided by the distribution and it installs the files in <em>/usr/local</em>. You can also change the compiler flags and produce a binary under a different name (say <em>displaylink_drv.so</em> instead of <em>fbdev_drv.so</em>).
  </li>

  <li>
<em>GDM</em> with multiseat support - GDM will manage multiple local displays and has the ability to add/remove displays dynamically. This functionality is present in versions up to 2.20 and since RHEL6 includes gdm-2.30.4-21.el6 this is a tough choice. There are several possibilities:
<ol>
  <li>
Use older <em>GDM</em>, preferably from a previous RHEL release. This gives you a tested piece of software and as long as the previous release is maintained you have (at least some) opportunity of fixing bugs in this code base. However this conflicts with current <em>GDM</em> in the distro which is also integrated with <em>ConsoleKit</em>, <em>Plymouth</em> and <em>PulseAudio</em>.
  </li>

  <li>
Use <em>GDM</em> and <em>ConsoleKit</em> that are available in RHEL6 and apply the multiseat patches available at
https://bugs.freedesktop.org/show_bug.cgi?id=19333 and http://bugzilla.gnome.org/show_bug.cgi?id=536355.

Those patches are quite big (around 3000 lines each) and are not yet fully integrated upstream. They also conflict with custom patches that Red Hat is shipping into these packages. Your patched packages will also conflict with the stock distro packages and you will not receive any support for that. Since <em>ConsoleKit</em> seems like fairly important application I'd not recommend modifying it.
  </li>

  <li>
Use another display manager that can handle multiple displays. https://help.ubuntu.com/community/MultiseatX suggests to use <em>KDM</em> instead of <em>GDM</em>. As far as I can tell the configuration is only static and this can break any time due to the fact that USB device discovery is unpredictable and unreliable. It also lacks an alternative for <em>gdmdynamic</em> according to http://lists.kde.org/?l=kde-devel&m=129898381127854&w=2 which makes it a no-go for plug-and-play multiseat support.

There are other less popular display managers but I haven't spend much time in research.
  </li>

  <li>
Just for the record it is also possible that one writes a custom display manager for multiseat operations. This sounds like an overkill and there are many factors which need to be taken into account. If you have enough resources and knowledge to write a display manager you'd better give upstream a hand instead of reinventing the wheel. 
  </li>
</ol>

We've decided to use <em>GDM 2.16</em> from RHEL5 due to the above factors. In practice it turns out that there aren't many issues with this version.
  </li>

  <li>
<em>A GDM theme</em> - since the GDM version we're using requires a theme which is missing in RHEL6 this is also provided as a separate package. A GDM theme is an XML file plus some images.
  </li>

  <li>
<em>udev rules, scripts and config files</em> - this is the glue between all the other components. Their primary job is to group the display-mouse-keyboard pairs for a given seat and start the display with the appropriate configuration settings. We also have support for <em>PulseAudio</em>.
  </li>
</ul>

<h2>RHEL6 SPECIFICS</h2>
<p>For detailed description of multiseat configuration take a look at http://plugable.com/2009/11/16/setting-up-usb-multiseat-with-displaylink-on-linux-gdm-up-to-2-20/ or at our <a href="http://otb-sources.googlecode.com/svn/trunk/sumu/">source code</a>. I'm going to describe only the differences in RHEL6.</p>
<p><em>GDM</em>, <em>udlfb</em> and <em>xorg-x11-drv-fbdev-displaylink</em> need to be compiled and installed on the system. </p>
<p>To build an older <em>GDM</em> on RHEL6 you will need to adjust some of the patches in the src.rpm package to apply cleanly and tweak the .spec file to your needs. This also includes using the appropriate version of <em>ltmain.sh</em> from the distro.</p>
<p>The udev rules and scripts are slightly different due to the different device paths in RHEL6:</p>
<div class="codehilite"><pre>SYSFS<span class="o">{</span>idVendor<span class="o">}==</span><span class="s2">&quot;17e9&quot;</span>, SYSFS<span class="o">{</span>bConfigurationValue<span class="o">}==</span><span class="s2">&quot;2&quot;</span>, <span class="nv">RUN</span><span class="o">=</span><span class="s2">&quot;/bin/echo 1 &gt; /sys%p/bConfigurationValue&quot;</span>

<span class="nv">ACTION</span><span class="o">==</span><span class="s2">&quot;add&quot;</span>,    <span class="nv">KERNEL</span><span class="o">==</span><span class="s2">&quot;fb*&quot;</span>, <span class="nv">SUBSYSTEM</span><span class="o">==</span><span class="s2">&quot;graphics&quot;</span>, <span class="nv">SUBSYSTEMS</span><span class="o">==</span><span class="s2">&quot;usb&quot;</span>, <span class="nv">PROGRAM</span><span class="o">=</span><span class="s2">&quot;/usr/bin/sumu-hub-id /sys/%p/device/../&quot;</span>, SYMLINK+<span class="o">=</span><span class="s2">&quot;usbseat/%c/display&quot;</span>,  RUN+<span class="o">=</span><span class="s2">&quot;/etc/udev/scripts/start-seat %c&quot;</span>
<span class="nv">ACTION</span><span class="o">==</span><span class="s2">&quot;remove&quot;</span>, <span class="nv">KERNEL</span><span class="o">==</span><span class="s2">&quot;fb*&quot;</span>, <span class="nv">SUBSYSTEM</span><span class="o">==</span><span class="s2">&quot;graphics&quot;</span>, RUN+<span class="o">=</span><span class="s2">&quot;/etc/udev/scripts/stop-seat %k&quot;</span>

<span class="nv">KERNEL</span><span class="o">==</span><span class="s2">&quot;control*&quot;</span>, <span class="nv">SUBSYSTEM</span><span class="o">==</span><span class="s2">&quot;sound&quot;</span>, <span class="nv">BUS</span><span class="o">==</span><span class="s2">&quot;usb&quot;</span>, <span class="nv">PROGRAM</span><span class="o">=</span><span class="s2">&quot;/usr/bin/sumu-hub-id /sys/%p/device/../../../../&quot;</span>, SYMLINK+<span class="o">=</span><span class="s2">&quot;usbseat/%c/sound&quot;</span>
<span class="nv">KERNEL</span><span class="o">==</span><span class="s2">&quot;event*&quot;</span>, <span class="nv">SUBSYSTEM</span><span class="o">==</span><span class="s2">&quot;input&quot;</span>, <span class="nv">BUS</span><span class="o">==</span><span class="s2">&quot;usb&quot;</span>, SYSFS<span class="o">{</span>bInterfaceClass<span class="o">}==</span><span class="s2">&quot;03&quot;</span>, SYSFS<span class="o">{</span>bInterfaceProtocol<span class="o">}==</span><span class="s2">&quot;01&quot;</span>, <span class="nv">PROGRAM</span><span class="o">=</span><span class="s2">&quot;/usr/bin/sumu-hub-id /sys/%p/device/../../../../&quot;</span>, SYMLINK+<span class="o">=</span><span class="s2">&quot;usbseat/%c/keyboard&quot;</span>, RUN+<span class="o">=</span><span class="s2">&quot;/etc/udev/scripts/start-seat %c&quot;</span>
<span class="nv">KERNEL</span><span class="o">==</span><span class="s2">&quot;event*&quot;</span>, <span class="nv">SUBSYSTEM</span><span class="o">==</span><span class="s2">&quot;input&quot;</span>, <span class="nv">BUS</span><span class="o">==</span><span class="s2">&quot;usb&quot;</span>, SYSFS<span class="o">{</span>bInterfaceClass<span class="o">}==</span><span class="s2">&quot;03&quot;</span>, SYSFS<span class="o">{</span>bInterfaceProtocol<span class="o">}==</span><span class="s2">&quot;02&quot;</span>, <span class="nv">PROGRAM</span><span class="o">=</span><span class="s2">&quot;/usr/bin/sumu-hub-id /sys/%p/device/../../../../&quot;</span>, SYMLINK+<span class="o">=</span><span class="s2">&quot;usbseat/%c/mouse&quot;</span>,    RUN+<span class="o">=</span><span class="s2">&quot;/etc/udev/scripts/start-seat %c&quot;</span>
</pre></div>


<p>We also use only <em>/dev/event*</em> devices for both mouse and keyboard.</p>
<p>The <em>sumu-hub-id</em> script returns the string busX-devY indicating the location of the device:</p>
<div class="codehilite"><pre><span class="c">#!/bin/bash</span>
<span class="k">if</span> <span class="o">[</span> -d <span class="s2">&quot;</span><span class="nv">$1</span><span class="s2">&quot;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
    <span class="nb">echo</span> <span class="s2">&quot;bus</span><span class="k">$(</span>cat <span class="nv">$1</span>/busnum<span class="k">)</span><span class="s2">-dev</span><span class="k">$(</span>cat <span class="nv">$1</span>/devnum<span class="k">)</span><span class="s2">&quot;</span>
    <span class="nb">exit </span>0
<span class="k">else</span>
    <span class="nb">exit </span>1
<span class="k">fi</span>
</pre></div>


<p>USB device numbering is unique per bus and there isn't a global device identifier as far as I know. On systems with 2 or more USB buses this can lead to mismatch between devices/seats.</p>
<p>For seat/display numbering we use the number of the framebuffer device associated with the seat. This is unique, numbers start from 1 (<em>fb0</em> is the text console) and are sequential unlike USB device numbers. This also ensures easy match between <em>$DISPLAY</em> and <em>/dev/fbX</em> for debugging purposes.</p>
<p>Our <em>xorg.conf.sed</em> template uses evdev as the input driver. This driver is the default in RHEL6:</p>
<div class="codehilite"><pre>Section &quot;InputDevice&quot;
    Identifier &quot;keyboard&quot;
    Driver      &quot;evdev&quot;
    Option      &quot;CoreKeyboard&quot;
    Option      &quot;Device&quot;        &quot;/dev/usbseat/%SEAT_PATH%/keyboard&quot;
    Option      &quot;XkbModel&quot;      &quot;evdev&quot;
EndSection

Section &quot;InputDevice&quot;
    Identifier &quot;mouse&quot;
    Driver      &quot;evdev&quot;
    Option      &quot;CorePointer&quot;
    Option      &quot;Protocol&quot; &quot;auto&quot;
    Option      &quot;Device&quot;   &quot;/dev/usbseat/%SEAT_PATH%/mouse&quot;
    Option      &quot;Buttons&quot; &quot;5&quot;
    Option      &quot;ZAxisMapping&quot; &quot;4 5&quot;
EndSection
</pre></div>


<p>We also use a custom <em>gdm.conf</em> file to avoid conflicts with stock packages. Only the important settings are shown:</p>
<div class="codehilite"><pre><span class="k">[daemon]</span>
<span class="na">AlwaysRestartServer</span><span class="o">=</span><span class="s">false</span>
<span class="na">DynamicXServers</span><span class="o">=</span><span class="s">true</span>
<span class="na">FlexibleXServers</span><span class="o">=</span><span class="s">0</span>
<span class="na">VTAllocation</span><span class="o">=</span><span class="s">false</span>

<span class="k">[servers]</span>
<span class="na">0</span><span class="o">=</span><span class="s">inactive</span>
</pre></div>


<p>AlwaysRestartServer=false is necessary to avoid a bug in <em>Xorg</em>. See below for issues description.</p>
<p>Audio is supported by setting $PULSE_SINK/$PULSE_SOURCE environment variables using a script in <em>/etc/profile.d</em> which executes after login.</p>
<h2>SCALABILITY AND PERFORMANCE</h2>
<p><strong>Maximum seats</strong>:<br />
The USB standard specifies a maximum of 127 USB devices connected to a single host controller. This means around 30 seats per USB controller depending on the number of devices connected to a USB hub. In practice you will have hard time finding a system which has that many port available. I've used Fujitsu's <a href="http://ts.fujitsu.com/products/standard_servers/tower/primergy_tx100s1.html">TX100 S1</a> and <a href="http://ts.fujitsu.com/products/standard_servers/tower/primergy_tx100s2.html">TX100 S2</a> which can be expanded to 15 or 16 USB ports using all external and internal ports and additional PCI-USB extension card.</p>
<p>While larger configuration are possible by using more PCI cards or intermediate hubs those are limited by the USB 2.0 transfer speed (more devices on a single hub, slower graphics) and a <a href="https://bugzilla.kernel.org/show_bug.cgi?id=28682">bug</a> in the Linux kernel.</p>
<p><strong>Space and cable length</strong>:<br />
USB 2.0 limits the cable length to 5 meters. On the market I've found good quality cables running 4.5 meters. This means that your multiseat system needs to be confined is small physical space due to these limitations. In practice using medium sized multiseat system in a 30 square meters space is doable and fits into these limits. This is roughly the size of a class-room in a school.</p>
<p>You can of course use daisy chaining (up to 5 hubs) and active USB extension cords (11 meters) or USB over CAT5 cables (up to 45 meters) but all of these interfere with USB signal strength and can lead to unpredictable behavior. For example I've see errors opening USB devices when power is not sufficient or too high. Modern computer systems have built in hardware protection and shut off USB ports or randomly reboot when the current on the wire is too strong. I've seen this on a number of occasions and the fix was to completely power off and unplug the system then power it on again.</p>
<p>Also don't forget that USB video consumes a great deal of the limited USB 2.0 bandwidth. Depending on the workload of the system (e.g. office applications vs. multimedia) you could experience slow graphical response if using extension cords and daisy chaining.</p>
<p><strong>Performance</strong>:<br />
For regular desktop use (i.e. nothing in particular) I'd recommend using 32bit operating system. On 64bit systems objects take a lot more memory and you'll need 3-4 times more for the same workload as on 32bit. For example 16 users running Eclipse, gnome-terminal and Firefox will need less that 8GB of memory on 32bit and more than 16GB on 64bit. Python and Java are particularly known to use much more memory on 64bit.</p>
<p>Regular desktop usage is not CPU intensive and a modern Xeon CPU has no issues with it. One exception is Flash which always causes your CPU to choke. On multiseat that becomes even a bigger problem. If possible disable/remove Flash from the system.</p>
<p>Multiseat doesn't make any difference when browsing, sending e-mail, etc. You shouldn't experience issues with networking unless your workload doesn't require hi-speed connection or your bandwidth is too low. If this is the case you'd better use the USB NICs available in the docking stations and bond them together, add external PCI NICs or upgrade your networking infrastructure.</p>
<p>Disk performance is critical in multiseat especially because it affects the look and feel of the system and is visible by the end users. It is usually good practice to place /home on a separate partition and even on a separate disk. Also consider disabling unnecessary caching in user space applications such as Firefox and Nautilus (thumbnails and cache). </p>
<p>On a system with 2 x 7,2K RPM disks in BIOS RAID1 configuration and a standard RHEL6 installation (i.e. no optimizations configured) where /, swap and /home are on the same RAID array we have 15 users using GNOME, gedit, Firefox, gnome-terminal and gcc. The performance is comparable to stand alone desktop with occasional spikes which cause GNOME to freeze for a second or two. It is expected that disabling unnecessary caching will make things better.</p>
<p>Depending on the workload (reads vs. writes) you should consider different RAID levels, file system types and settings and changing disk parameters. A good place to start is the "Storage Administration Guide" and "I/O Tuning Guide" at http://docs.redhat.com.</p>
<h2>KNOWN ISSUES</h2>
<ul>
 <li>
<a href="https://bugzilla.kernel.org/show_bug.cgi?id=28682">Bug 28682 - input drivers support limited device numbers (EVDEV_MINORS is 32)</a> - this bug will block you from adding more than 32 input devices of the same type. For multiseat that means 32 devices which are handled by the event driver which includes mice, keyboards, joystick and special platform events such as the Reboot/Poweroff buttons. This limits the available seats to around 15.
 </li>

 <li>
<a href="https://bugzilla.redhat.com/show_bug.cgi?id=679122">Bug 679122 - gnome-volume-control: Sound at 100% and no sound output</a> - upon first login the user will not hear any sound regardless of the fact that the volume control application shows volume is at 100%.
 </li>

 <li>
<a href="https://bugzilla.redhat.com/show_bug.cgi?id=682562">Bug 682562 - gnome-volume-control doesn't respect PULSE_SINK/PULSE_SOURCE</a> - the volume control application will not behave correctly and may confuse users.
 </li>

 <li>
Xorg will cause 100% CPU usage after logout - this is due to several factors. The <a href="http://plugable.com/2009/11/16/setting-up-usb-multiseat-with-displaylink-on-linux-gdm-up-to-2-20/">initial multiseat configuration</a> had a problem with input duplication. This was fixed by removing "-sharevts -novtswitch" from the X start line and substituting a specific VT - "vt07". 

This works fine unless one of the users logs out of their GNOME session. After that GDM will kill and restart it's process and new Xorg process will be spawned. The restarted instance will loop endlessly executing the following code:


wzxhzdk:4


If you search on the Internet you will find plenty of bug reports related to this code block. The problem is in <em>Xorg</em> which doesn't properly handle the situation where it can't take control over the terminal. The solution is to not restart <em>Xorg</em> after user session ends. This is done by setting AlwaysRestartServer=false in <em>gdm.conf</em>.
 </li>

 <li>
No integration with <em>SELinux</em> and <em>ConsoleKit</em> - while configuring <em>SELinux</em> in Permissive mode is easy workaround there's no easy workaround for <em>ConsoleKit</em>. 

Newer <em>GDM</em> versions register the user session with <em>ConsoleKit</em> and integrate that into the desktop. Missing integration means that some things will fail. For example <em>NetworkManager</em> will not allow the user to connect to a VPN connection because it thinks this user is not logged in:


wzxhzdk:5

</li>

 <li>
No ACLs for external USB flash drives - this is missing upstream and is supposed to land in <em>ConsoleKit</em>. When a user plugs their USB flash drive on a multiseat system GNOME will try to mount it automatically. If there are multiple users logged in this will either fail or all of them will be able to access the flash drive. 
 </li>
</ul>

<h2>PICTURES AND VIDEO</h2>
<p>Pictures from one of our deployments can be found on Facebook (no login required):
<a href="http://www.facebook.com/album.php?aid=54571&amp;id=180150925328433">http://www.facebook.com/album.php?aid=54571&amp;id=180150925328433</a>.
A demonstration video from the same deployment can be found at <a href="http://www.youtube.com/watch?v=7GYbCDGTz-4">http://www.youtube.com/watch?v=7GYbCDGTz-4</a></p>
<p>If you are interested in commercial support please contact me!</p>
<h2>FUTURE</h2>
<p>In the open source world everything is changing and multiseat is no exception. While <em>GDM</em> and <em>ConsoleKit</em> patches are not yet integrated upstream there's a new project called <a href="http://www.freedesktop.org/wiki/Software/systemd">systemd</a> which aims at replacing the SysV init scripts system. It already has several configuration files for multiseat and I expect it will influence multiseat deployments in the future. Systemd will be available in Fedora 15.</p>
            <p class="post-meta">Posted by
                    <a href="http://atodorov.org/author/alexander-todorov.html">Alexander Todorov</a>
                 on Mon 14 March 2011
<p>There are <a href="http://atodorov.org/blog/2011/03/14/usb-multi-seat-on-red-hat-enterprise-linux-6/#disqus_thread">comments</a>.</p>            </p>
        </div>
        <hr>

    <!-- Pager -->
    <ul class="pager">
        <li class="next">
                <a href="http://atodorov.org/index10.html">Newest Posts &rarr;</a>
        </li>
    </ul>
    Page 11 / 11
    <hr>
            </div>
        </div>
    </div>

    <hr>

    <!-- Footer -->
    <footer>
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <ul class="list-inline text-center">
                        <li>
                            <a href="https://twitter.com/atodorov_">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/atodorov">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                    </ul>


                    <section>
                        <p>
                            I am a QA contractor at Red Hat responsible for over
                            <a href="/blog/2014/02/19/7-years-1400-bugs-red-hat-qa/">1500 bugs</a>,
                            a general purpose open source developer, Red Hat Certified professional,
                            cloud hacker and an entrepreneur!
                        </p>

                        <p>
                            I am living in the <a href="http://planet.sofiavalley.com">Sofia Valley</a>
                            which is emerging as a busy place for start-up founders and tech enthusiasts
                            in Eastern Europe! You can find more about me <a href="/blog/2013/01/25/about-me/">here</a>.
                          </p>
                    </section>

                    <form action="http://google.com/search" method="get" style="width:300px;margin:0 auto;">
                        <fieldset role="search">
                            <input type="hidden" name="sitesearch" value="http://atodorov.org" />
                            <input class="search" type="text" name="q" results="0" placeholder="Search" style="width:100%"/>
                        </fieldset>
                    </form>

                    <p class="copyright text-muted">
                        <a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/deed.en_US">CC-BY-SA</a> &amp;
                        <a rel="license" href="http://opensource.org/licenses/MIT">MIT</a>
                        2011-2015 &diams; Alexander Todorov &diams;
                        <a href="http://planet.sofiavalley.com">SofiaValley Blog</a>
                    </p>
                </div>
            </div>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="http://atodorov.org/theme/js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="http://atodorov.org/theme/js/bootstrap.min.js"></script>


    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37979549-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>
<script type="text/javascript">
    var disqus_shortname = 'atodorov';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
</body>

</html>